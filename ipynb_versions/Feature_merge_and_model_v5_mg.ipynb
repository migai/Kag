{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Feature_merge_and_model_v5_mg.ipynb","provenance":[{"file_id":"12KA-rL8-rk29NOHJN8-DbZ8fGUESsfgV","timestamp":1589287670669},{"file_id":"1nzPRIdf4UB-3biwx8fCJlTnx8bL126aO","timestamp":1588242465890},{"file_id":"https://github.com/migai/Kag/blob/master/template_Kaggle_Coursera_Final_Assignment.ipynb","timestamp":1587141076973}],"collapsed_sections":["YPp_Nesy2yxn","LyLQLqBcOnLt","RHbcGFx1sp-g","RKFDOiOwtJPg","hoz_AWn9XXG1","_Ldvqgyw0_Hw","Isean25B9FjA","dYgR5n3W9XTO","oqC_Y9nHrNmy","kiRO8mgIk7nR","-yaXpG71QxcW","V_kNfg6lCCHv","eMUj_QJP1Vur","au82dd3m59n0","HNJknAGqN1K9","X-qeKYp1j5aQ","BlpasBnrxWI4","GnRD9aQF-aMp","pCyzZ8jskoW8","oS1-vtg2mHQ2"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ufy-J0xC2efV","colab_type":"text"},"source":["## First things first\n","* Click **File -> Save a copy in Drive** and click **Open in new tab** in the pop-up window to save your progress in Google Drive.\n","* Click **Runtime -> Change runtime type** and select **GPU** in Hardware accelerator box to enable faster GPU training."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MY4tx3FwtVq7"},"source":["###Mount Google Drive for access to Google Drive local repo"]},{"cell_type":"code","metadata":{"id":"CUIE1PVjSAmg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1593865850802,"user_tz":240,"elapsed":21734,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"2a8215fd-678f-4f18-f915-137a17e86b72"},"source":["from google.colab import drive  \n","import os\n","from time import strftime, tzset\n","os.environ['TZ'] = 'EST+05EDT,M4.1.0,M10.5.0'   # allows user to simply print a formatted version of the local date and time; helps keep track of what cells were run, and when\n","tzset()   # set the time zone\n","\n","\n","# click on the URL link presented to you by this command, get your authorization code from Google, then paste it into the input box and hit 'enter' to complete mounting of the drive\n","\n","drive.mount('/content/drive')\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","Done: Sat 08:30:49 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZA5YyPKB7QAt","colab_type":"text"},"source":["##**Define Various 'Constants' that Determine Feature Creation, Model Params, etc.**"]},{"cell_type":"code","metadata":{"id":"zLChKkFHC30j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593865850804,"user_tz":240,"elapsed":21728,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"50afdbc8-74d3-4080-93cd-b672f6812d50"},"source":["# Name of file model substring to save data submission to (= False if user to input it below)\n","# model_name = 'LGBMv1p4mg_30'\n","model_name = False\n","\n","\n","# Optional list of shops to delete from training data (possibly harmful or irrelevant during training); set to False if no extra deletions:\n","SHOPS_TO_DELETE = False\n","# SHOPS_TO_DELETE = [8, 13, 23, 32, 33, 40]  # these are early-termination shops;  also, perhaps can delete [9, 20] 'online' shops\n","\n","# Optional list of item_category_ids to delete from training data (possibly harmful or irrelevant during training); set to False if no extra deletions:\n","ITEM_CATS_TO_DELETE = False\n","# ITEM_CATS_TO_DELETE = [8, 80, 81, 82]  # untested, and not closely related to other item categories;  8, 80 (= 'tickets') and probably 81,82 (= 'net carriers')\n","\n","# Optional multiplier to scale sales/month for unequal days per month, weekends per month, Russia depression; set to False if no scaling\n","SCALE_MONTH = False\n","# # SCALE_MONTH = 30/date_adjustments.days_in_M\n","#SCALE_MONTH = 'week_retail_weight'\n","\n","# Define various constants that drive the attributes of the various features\n","SALES_TRAIN_CLIP_H = 20                   # will also clip item_cnt_month predictions to 20 after the model runs\n","SALES_TRAIN_CLIP_L = -20                   \n","SALES_PREDICT_CLIP_H = 20                   # will also clip item_cnt_month predictions to 20 after the model runs\n","SALES_PREDICT_CLIP_L = -20                   \n","CARTESIAN_FILL_MONTH_START = 8             # month number + max lag to start adding Cartesian product rows (i.e., maxlag=6mo and start=10 will cartesian fill from 4 to 33)\n","TRAIN_START_MONTH = CARTESIAN_FILL_MONTH_START # == 24 ==> less than a year of data, but avoids December 'outlier' of 2014\n","TRAIN_FINAL_MONTH = 32   # validation data is all months after this, up to and including month 33\n","TARGET_SALES_CLIP = 20   # prediction is clipped prior to submission, per instructions\n","STATS_COLS = ['shop_id','shop_typeA','shop_typeB','shop_fd','item_id','item_cat0','item_catA','item_cat3','item_cluster']\n","LAGS = [1,2,3,6] #,3,4,5,6]  # month lags to include in model \n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Done: Sat 08:30:49 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C-FF20AVBgih","colab_type":"text"},"source":["####**Selection of Initial Features, Enhanced Readability of DataFrames**"]},{"cell_type":"code","metadata":{"id":"1c8M1ONK7txo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593865850805,"user_tz":240,"elapsed":21721,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"b1c3302e-707b-4603-a8af-d133329b8771"},"source":["# Reduce size of DF a bit; remove features I think may not be as helpful as others\n","#    (saves memory, and makes it make it easier to read the DF when printing)\n","\n","# # column names of the loaded dataframes:\n","# items_enc_cols = ['item_id', 'item_tested', 'item_cluster', 'item_category_id', 'item_cat_tested', 'item_group', 'item_category1', 'item_category2', 'item_category3', 'item_category4']\n","# shops_enc_cols = ['shop_id', 'shop_tested', 'shop_group', 'shop_type', 's_type_broad', 'shop_federal_district', 'fd_popdens', 'fd_gdp', 'shop_city']\n","# date_adj_cols =  ['month', 'year', 'season', 'MoY', 'days_in_M', 'weekday_weight', 'retail_sales', 'week_retail_weight']\n","# train_test_base_cols = ['day', 'week', 'qtr', 'season', 'month', 'price', 'sales', 'shop_id', 'item_id']\n","# test_cols =      ['ID', 'shop_id', 'item_id']\n","\n","# columns to keep for this round of modeling (dropping some of the less important features to save memory):\n","ITEMS_KEEP_LIST = ['item_id', 'item_cluster', 'item_category_id', 'item_group', 'item_category3']   # 'item_cat_tested', 'item_tested', \n","SHOPS_KEEP_LIST = ['shop_id', 'shop_group', 's_type_broad', 'shop_federal_district']                # , 'shop_tested'\n","DATE_KEEP_LIST =  ['month', 'days_in_M', 'weekday_weight', 'retail_sales', 'week_retail_weight']\n","STT_KEEP_LIST = ['month', 'price', 'sales', 'shop_id', 'item_id']  # sales-train-test dataset\n","\n","# rename columns for readability in the various dataframes\n","ITEMS_COLUMN_RENAME = { #'item_tested':'item_test', \n","                        'item_category_id':'item_cat0',\n","                        #'item_cat_tested':'item_cat_test',\n","                        'item_group':'item_catA',\n","                        'item_category3':'item_cat3'}\n","SHOPS_COLUMN_RENAME = { #'shop_tested':'shop_test',\n","                        'shop_group':'shop_typeA',\n","                        's_type_broad':'shop_typeB',\n","                        'shop_federal_district':'shop_fd'}\n","\n","# re-order columns for organized readability, for the (to be created) combined sales-train-test (stt) dataset\n","#    note extra column for shop_item_test will need to be created\n","STT_COLUMN_ORDER = ['month', 'shop_id', 'item_id', 'sales', 'shop_typeA', 'shop_typeB', 'shop_fd',\n","                'item_cat0', 'item_catA', 'item_cat3', 'item_cluster'] #, 'shop_test', 'item_test','shop_item_test']\n","\n","# these columns are merged with time-lagged statistics columns\n","PRE_LAG_COLUMNS = ['month','shop_id','item_id','shop_typeA', 'shop_typeB', 'shop_fd', 'item_cat0', 'item_catA', 'item_cat3', 'item_cluster'] #, 'shop_test', 'item_test', 'shop_item_test']\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Done: Sat 08:30:49 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YPp_Nesy2yxn","colab_type":"text"},"source":["#**Final Project for Coursera's 'How to Win a Data Science Competition'**\n","April, 2020\n","\n","Andreas Theodoulou and Michael Gaidis\n","\n","(Competition Info last updated:  3 years ago)"]},{"cell_type":"markdown","metadata":{"id":"r_Oe76PW3aoN","colab_type":"text"},"source":["##**About this Competition**\n","\n","You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.\n","\n","Evaluation: root mean squared error (RMSE). True target values are clipped into [0,20] range.\n","\n",".\n","\n","##**File descriptions**\n","\n","***sales_train.csv*** - the training set. Daily historical data from January 2013 to October 2015.\n","\n","***test.csv*** - the test set. You need to forecast the sales for these shops and products for November 2015.\n","\n","***sample_submission.csv*** - a sample submission file in the correct format.\n","\n","***items.csv*** - supplemental information about the items/products.\n","\n","***item_categories.csv***  - supplemental information about the items categories.\n","\n","***shops.csv***- supplemental information about the shops.\n","\n",".\n","\n","##**Data fields**\n","\n","***ID*** - an Id that represents a (Shop, Item) tuple within the test set\n","\n","***shop_id*** - unique identifier of a shop\n","\n","***item_id*** - unique identifier of a product\n","\n","***item_category_id*** - unique identifier of item category\n","\n","***item_cnt_day*** - number of products sold. You are predicting a monthly amount of this measure\n","\n","***item_price*** - current price of an item\n","\n","***date*** - date in format dd/mm/yyyy\n","\n","***month*** - a consecutive month number. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n","\n","***item_name*** - name of item\n","\n","***shop_name*** - name of shop\n","\n","***item_category_name*** - name of item category"]},{"cell_type":"markdown","metadata":{"id":"LyLQLqBcOnLt","colab_type":"text"},"source":["#**Set Up Environment and Load Files**\n","Load competition data files, import python modules, and set up pandas environment options"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RHbcGFx1sp-g"},"source":["###Name the files you wish to load"]},{"cell_type":"code","metadata":{"id":"dy5i7jl00oX-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593865850805,"user_tz":240,"elapsed":21718,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}}},"source":["# List of the *data* files (path relative to GitHub branch), to be loaded into pandas DataFrames\n","data_files = [  \n","                \"data_output/items_enc.csv\",\n","                \"data_output/shops_enc.csv\",\n","                \"data_output/date_adjustments.csv\",\n","                \"data_output/train_test_base.csv.gz\",\n","                \"readonly/final_project_data/test.csv.gz\"\n","             ]\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RKFDOiOwtJPg"},"source":["###Import Modules, Set Up Environment"]},{"cell_type":"code","metadata":{"id":"naC94KtXOnLt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865852521,"user_tz":240,"elapsed":23424,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"2c5666ab-2488-4655-e67d-469ce278f6ef"},"source":["# General python libraries/modules used throughout the notebook\n","import os\n","import feather   # this is 3x to 8x faster than pd.read_csv and pd.to_hdf, but file size is 2x hdf and 10x csv.gz\n","from itertools import product\n","from collections import OrderedDict\n","import re\n","import time\n","import datetime\n","from time import sleep, localtime, strftime, tzset, strptime\n","os.environ['TZ'] = 'EST+05EDT,M4.1.0,M10.5.0'   # allows user to simply print a formatted version of the local date and time; helps keep track of what cells were run, and when\n","tzset()   # set the time zone\n","\n","# Helpful packages for EDA, cleaning, data manipulation\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from numba import jit      # speedup for appropriate functions and datatypes (no sets, lists, dictionaries, string functions; use np arrays rather than pandas)\n","from numba import vectorize  # speed up row-wise operations like .apply() --> https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html\n","\n","# ML packages\n","from lightgbm import LGBMRegressor\n","import sklearn\n","\n","# Pandas additional enhancements / formatting\n","pd.set_option('compute.use_bottleneck', False)  # speed up operation when using NaNs\n","pd.set_option('compute.use_numexpr', False)     # speed up boolean operations, large dataframes; DataFrame.query() and pandas.eval() will evaluate the subexpressions that can be evaluated by numexpr\n","pd.set_option(\"display.max_rows\",100)     # Override pandas choice of how many rows to show, so we can see the full 84-row item_category df instead of '...' in the middle\n","pd.set_option(\"display.max_columns\",30)   # Similar to row code above, we can show more columns than default\n","pd.set_option(\"display.width\", 220)       # Tune this to our monitor window size to avoid horiz scroll bars in output windows (but, will get output text wrapping)\n","pd.set_option(\"max_colwidth\", None)       # This is done, for example, so we can see full item name and not '...' in the middle\n","# Tell pandas to print without decimal places if a number is actually an integer, and use 3 decimals if a float (helps keep column width down, and highlights data types)\n","pd.options.display.float_format = lambda x : '{:.0f}'.format(x) if round(x,0) == x else '{:,.3f}'.format(x)\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Done: Sat 08:30:51 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hoz_AWn9XXG1"},"source":["###Load the files into pandas dataframes, from Google Drive local repo"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KD_yNYM2AE3Q","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865856980,"user_tz":240,"elapsed":27875,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"942c1bde-172b-4469-c2d2-981b115fdc1d"},"source":["'''\n","############################################################\n","############################################################\n","'''\n","# Replace this path with the path on *your* Google Drive where the repo master branch is stored\n","#   (on GitHub, the remote repo is located at github.com/migai/Kag --> below is my cloned repo location)\n","GDRIVE_REPO_PATH = \"/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final/Kag\"\n","'''\n","############################################################\n","############################################################\n","'''\n","\n","%cd \"{GDRIVE_REPO_PATH}\"\n","\n","print(\"Loading Files from Google Drive repo into Colab...\\n\")\n","\n","# Loop to load the data files into appropriately-named pandas DataFrames\n","for path_name in data_files:\n","    filename = path_name.rsplit(\"/\")[-1]\n","    data_frame_name = filename.split(\".\")[0]\n","    exec(data_frame_name + \" = pd.read_csv(path_name)\")\n","    print(f'Data Frame: {data_frame_name}; n_rows = {len(eval(data_frame_name))}, n_cols = ',end=\"\")\n","    print(f'{len(eval(data_frame_name).columns)}') #\\nData Types: {eval(data_frame_name).dtypes}\\n')\n","    print(f'Column Names: {eval(data_frame_name).columns.to_list()}')\n","    print(eval(data_frame_name).head(2))\n","    print(\"\\n\")\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final/Kag\n","Loading Files from Google Drive repo into Colab...\n","\n","Data Frame: items_enc; n_rows = 22170, n_cols = 10\n","Column Names: ['item_id', 'item_tested', 'item_cluster', 'item_category_id', 'item_cat_tested', 'item_group', 'item_category1', 'item_category2', 'item_category3', 'item_category4']\n","   item_id  item_tested  item_cluster  item_category_id  item_cat_tested  item_group  item_category1  item_category2  item_category3  item_category4\n","0        0            0           100                40                1           6               8               3               7               3\n","1        1            0           105                76                1           6              11               6              10               5\n","\n","\n","Data Frame: shops_enc; n_rows = 60, n_cols = 9\n","Column Names: ['shop_id', 'shop_tested', 'shop_group', 'shop_type', 's_type_broad', 'shop_federal_district', 'fd_popdens', 'fd_gdp', 'shop_city']\n","   shop_id  shop_tested  shop_group  shop_type  s_type_broad  shop_federal_district  fd_popdens  fd_gdp  shop_city\n","0        0            0           7          5             2                      1           3       1         26\n","1        1            0           7          1             0                      1           3       1         26\n","\n","\n","Data Frame: date_adjustments; n_rows = 35, n_cols = 8\n","Column Names: ['month', 'year', 'season', 'MoY', 'days_in_M', 'weekday_weight', 'retail_sales', 'week_retail_weight']\n","   month  year  season  MoY  days_in_M  weekday_weight  retail_sales  week_retail_weight\n","0      0  2013       2    1         31           0.979         1.052               1.030\n","1      1  2013       3    2         28           1.069         1.072               1.146\n","\n","\n","Data Frame: train_test_base; n_rows = 3150043, n_cols = 9\n","Column Names: ['day', 'week', 'qtr', 'season', 'month', 'price', 'sales', 'shop_id', 'item_id']\n","   day  week  qtr  season  month  price  sales  shop_id  item_id\n","0    0     0    0       2      0     99      1        2      991\n","1    0     0    0       2      0   2599      1        2     1472\n","\n","\n","Data Frame: test; n_rows = 214200, n_cols = 3\n","Column Names: ['ID', 'shop_id', 'item_id']\n","   ID  shop_id  item_id\n","0   0        5     5037\n","1   1        5     5320\n","\n","\n","Done: Sat 08:30:55 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_Ldvqgyw0_Hw","colab_type":"text"},"source":["#**Data Preparation, Including Feature Merging and Feature Generation**"]},{"cell_type":"markdown","metadata":{"id":"Isean25B9FjA","colab_type":"text"},"source":["###**Helper Functions**"]},{"cell_type":"code","metadata":{"id":"tCWGzR4vl8TW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865856981,"user_tz":240,"elapsed":27867,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"552892ef-4a37-4e48-9d26-11a5d0bad9d6"},"source":["# helper function to print out column datatypes and memory usage, using multiple columns so we don't have to scroll so much\n","def print_col_info(df,nrows=5):\n","    \"\"\"\n","    instead of the usual single column (plus index) series printout of dtypes and memory use in a dataframe,\n","    this function combines dtypes and memory use so they use the same index,\n","    and then prints out multiple columns of length \"nrows\", where each column is like: \"column_dtype \\t column_memory_use(MB) \\t column_name\"\n","        df = dataframe of interest\n","            col_dtypes = pd.Series, type obj, index = column_name, values = dtype  (e.g., from the command \"df.dtypes\")\n","            col_mem = pd.Series, type int64, index = column_name, values = column memory use (bytes) (e.g., from the command \"df.memory_usage(deep=True)\")\n","        nrows = int, tells how many rows of (type/mem/name) to print before moving to a new printout column for the next triplet (type/mem/name)\n","                if nrows == 0, print all triplets in just one column, with no \"wrapping\"\n","    finishes with a printout of total df memory usage\n","    \"\"\"\n","    col_mem = df.memory_usage(deep=True)\n","    col_mem = col_mem/1e6  #change to MB\n","    total_mem = col_mem.sum()\n","\n","    col_dtypes = pd.Series([df.index.dtype], index = ['Index'])  # df.memory_usage includes Index, but df.dtypes does not include Index, so we have to add it\n","    col_dtypes = pd.concat([col_dtypes,df.dtypes], axis=0)\n","\n","    col_info_df = pd.concat([col_dtypes, col_mem], axis=1).reset_index().rename(columns={'index':'Column Name', 0:'DType', 1:'MBytes'})\n","\n","\n","    if nrows == 0:\n","        print(col_info_df)\n","    else:\n","        col_info_df.MBytes = col_info_df.MBytes.apply(lambda x: str(f'{x:.1f}'))\n","        #col_info_df.DType = col_info_df.DType.apply(lambda x: str(x))\n","        info_df_len = len(col_info_df)\n","        cnames = col_info_df.columns\n","        n_info_cols = len(cnames)\n","        between_cols = 6  # spaces separating the info-group columns (e.g., between \"ColName Dtype Mem\" and next column \"ColName Dtype Mem\")\n","\n","        # adjust number of rows such that we don't have nasty column with just one or a few rows\n","        stragglers = info_df_len % nrows\n","        n_print_cols = info_df_len // nrows\n","        if (stragglers > nrows/2):\n","            n_print_cols += 1\n","        elif (stragglers > 0):\n","            nrows = info_df_len // n_print_cols\n","            if info_df_len % n_print_cols > 0:\n","                nrows += 1\n","\n","        df_list = []\n","        for pc in range(n_print_cols):\n","            df_list.append(col_info_df.shift(periods = -nrows*pc))\n","        df_print = pd.concat(df_list, axis = 1)\n","        df_print = df_print.iloc[:nrows][:].fillna(\" \")\n","        col_headers = df_print.columns\n","        n_df_cols = len(col_headers)\n","        \n","        # find max string length in each column\n","        columnLengths = np.vectorize(len)\n","        maxColumnLengths = columnLengths(df_print.values.astype(str)).max(axis=0)\n","        col_widths = np.add(maxColumnLengths,3)\n","\n","        for r in range(nrows+1):\n","            if r==0:\n","                string_list = col_headers\n","            else:\n","                string_list = df_print.iloc[r-1][:]\n","            print_row = ''\n","            c_count = 0\n","            for c in range(n_df_cols):\n","                print_row = print_row + f'{str(string_list[c]):>{col_widths[c]}} '\n","                c_count += 1\n","                if c_count == n_info_cols:\n","                    c_count = 0\n","                    print_row += \" \" * between_cols  # extra space between columns of common data\n","\n","            print(print_row)\n","\n","    print(f'\\nNumber of rows in DataFrame: {len(df):,d}')\n","    print(f'DataFrame total memory usage: {total_mem:.0f} MB')\n","    \n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Done: Sat 08:30:55 07/04/20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NnitDghzH7ni","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865856981,"user_tz":240,"elapsed":27859,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"f64d86d8-e2f9-4a08-e035-6237c8b4ffbe"},"source":["print_col_info(train_test_base,8)  #example use of the above helper function"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Column Name      DType  MBytes       \n","     Index      int64     0.0       \n","       day      int64    25.2       \n","      week      int64    25.2       \n","       qtr      int64    25.2       \n","    season      int64    25.2       \n","     month      int64    25.2       \n","     price    float64    25.2       \n","     sales    float64    25.2       \n","   shop_id      int64    25.2       \n","   item_id      int64    25.2       \n","\n","Number of rows in DataFrame: 3,150,043\n","DataFrame total memory usage: 227 MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fz81jlrrjz55","colab_type":"text"},"source":["##**Initial data prep, formatting**"]},{"cell_type":"markdown","metadata":{"id":"W7uoRFv-uSC2","colab_type":"text"},"source":["###**Clean up the data, drop undesirable columns, merge shops and items info into train/test dataframe**"]},{"cell_type":"code","metadata":{"id":"seucVyaI90Mt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1593865857147,"user_tz":240,"elapsed":28016,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"1edc24cb-ad61-49c0-b9fb-44c8f9a9aa21"},"source":["# Clean up the shops and items dataframes\n","#    1) remove columns with features that we don't use at this time\n","#    2) rename columns to be shorter, for easier printing\n","\n","shops_purged = shops_enc[SHOPS_KEEP_LIST].rename(columns = SHOPS_COLUMN_RENAME)\n","items_purged = items_enc[ITEMS_KEEP_LIST].rename(columns = ITEMS_COLUMN_RENAME)\n","date_adj_purged = date_adjustments[DATE_KEEP_LIST].copy(deep=True)\n","stt = train_test_base[STT_KEEP_LIST].copy(deep=True)\n","\n","print(f'shops_purged dataframe length: {len(shops_purged)}\\n{shops_purged.head(2)}\\n')\n","print(f'items_purged dataframe length: {len(items_purged)}\\n{items_purged.head(2)}\\n')\n","print(f'date_adj_purged dataframe length: {len(date_adj_purged)}\\n{date_adj_purged.head(2)}\\n')\n","print(f'stt dataframe length: {len(stt)}\\n{stt.head(2)}\\n')\n","\n","try: del shops_enc\n","except: pass\n","try: del items_enc\n","except: pass\n","try: del date_adjustments\n","except: pass\n","try: del train_test_base\n","except: pass\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["shops_purged dataframe length: 60\n","   shop_id  shop_typeA  shop_typeB  shop_fd\n","0        0           7           2        1\n","1        1           7           0        1\n","\n","items_purged dataframe length: 22170\n","   item_id  item_cluster  item_cat0  item_catA  item_cat3\n","0        0           100         40          6          7\n","1        1           105         76          6         10\n","\n","date_adj_purged dataframe length: 35\n","   month  days_in_M  weekday_weight  retail_sales  week_retail_weight\n","0      0         31           0.979         1.052               1.030\n","1      1         28           1.069         1.072               1.146\n","\n","stt dataframe length: 3150043\n","   month  price  sales  shop_id  item_id\n","0      0     99      1        2      991\n","1      0   2599      1        2     1472\n","\n","Done: Sat 08:30:55 07/04/20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XA00nAC7IfWl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1593865859110,"user_tz":240,"elapsed":29970,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"6dfbcec5-fb77-4901-b6ee-ea0e6d872336"},"source":["# 'stt' will be the dataframe for (S)ales of (T)rain appended with (T)est\n","\n","# Merge shops and items into stt\n","stt = stt.merge(shops_purged, on='shop_id', how='left')\n","stt = stt.merge(items_purged, on='item_id', how='left')\n","\n","# drop undesirable shops and item categories\n","# abc\n","\n","# scale by date_adjustments as desired\n","if SCALE_MONTH:\n","    stt = stt.merge(date_adj_purged[['month',SCALE_MONTH]], on='month', how='left')\n","    stt.sales = round(stt.sales * stt[SCALE_MONTH])\n","    stt.drop(SCALE_MONTH, axis=1, inplace=True) \n","\n","# # Add shop_item_test column to train data\n","# stt['shop_item_test'] = stt.item_test * stt.shop_test\n","\n","# Clip the values of item sales per day (will clip again after grouping by month, and then clip at 20 just before submission of results for grading)\n","#stt.sales = stt.sales.clip(0, ITEM_CNT_TRAIN_CLIP)\n","stt.sales = stt.sales.clip(SALES_TRAIN_CLIP_L, SALES_TRAIN_CLIP_H)\n","\n","stt = stt[STT_COLUMN_ORDER]\n","\n","# downcast to reduce memory footprint; use helper function to print the memory usage info\n","stt = stt.reset_index(drop=True).apply(pd.to_numeric, downcast='integer') #'float') # use float so fractional date_adj weight is more accurate 'integer')  #reset index saves 25MB\n","print('stt dataframe:')\n","print_col_info(stt,5)\n","display(stt.head(2))\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["stt dataframe:\n","  Column Name    DType MBytes           Column Name    DType MBytes       \n","        Index    int64    0.0            shop_typeB     int8    3.2       \n","        month     int8    3.2               shop_fd     int8    3.2       \n","      shop_id     int8    3.2             item_cat0     int8    3.2       \n","      item_id    int16    6.3             item_catA     int8    3.2       \n","        sales     int8    3.2             item_cat3     int8    3.2       \n","   shop_typeA     int8    3.2          item_cluster    int16    6.3       \n","\n","Number of rows in DataFrame: 3,150,043\n","DataFrame total memory usage: 41 MB\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>month</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>sales</th>\n","      <th>shop_typeA</th>\n","      <th>shop_typeB</th>\n","      <th>shop_fd</th>\n","      <th>item_cat0</th>\n","      <th>item_catA</th>\n","      <th>item_cat3</th>\n","      <th>item_cluster</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>991</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>67</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>463</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1472</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>23</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>585</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   month  shop_id  item_id  sales  shop_typeA  shop_typeB  shop_fd  item_cat0  item_catA  item_cat3  item_cluster\n","0      0        2      991      1           9           0        5         67          5          5           463\n","1      0        2     1472      1           9           0        5         23          7          4           585"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Done: Sat 08:30:57 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dYgR5n3W9XTO"},"source":["###**Make Adjustments to Feature Encoding**"]},{"cell_type":"code","metadata":{"id":"9AouAv5GMRwy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865859111,"user_tz":240,"elapsed":29964,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"6ca9b7c0-9baf-48c1-a393-287beeff8f67"},"source":["'''\n","# Clip the values of item sales per day (will clip again after grouping by month, and then clip at 20 just before submission of results for grading)\n","# going to compress instead of clip at this time (see below)\n","#stt.sales = stt.sales.clip(0, ITEM_CNT_TRAIN_CLIP)  # eventually want to clip sales/month at 20, but it probably makes sense to let it go higher during feature generation to better separate the categories\n","stt.sales = stt.sales.clip(-ITEM_CNT_TRAIN_CLIP, ITEM_CNT_TRAIN_CLIP)\n","\n","print(stt.describe())\n","# Let's compress \"sales\" before entering the \"group-by-month\" to bring it more in line with the final clip value\n","# basically, sales<=20 will stay the same... sales > 20 will become 20+sqrt(sales-20)\n","stt['sales'] = stt['sales'].apply(lambda x: x if x<21 else round(20+np.sqrt(x-20))).astype(np.int16)\n","print('\\n')\n","print(stt.describe())\n","'''\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Done: Sat 08:30:57 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1GXED3-jyQC7"},"source":["##**Compute and Merge Statistics-Based Features on Grouped-by-Month training data**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Jhj7bbgCceh8"},"source":["###Create monthly_stt dataframe, grouping by month the (s)ales_(t)rain_(t)est dataframe"]},{"cell_type":"code","metadata":{"id":"AghbBFHC_ljc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865867921,"user_tz":240,"elapsed":38766,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"3bdd3319-8619-43be-aa36-f9ca0d83adf7"},"source":["# Compute values in real time, then in a later code cell we will compute shifted versions\n","#   With feature aggregations of sales, only using the 'sum' aggregate function (without mean or std, for example) helps to minimize memory requirements, keeping things as integers\n","\n","monthly_stt = pd.DataFrame()\n","def compute_stats(df=stt, monthly_df=monthly_stt, no_merge=True, group=['month','item_id'], aggstats={'sales':['sum']}, aggcolnames=['sales_by_item']):\n","    \"\"\"\n","    function for computing statistics-based features, in an attempt to be flexible if\n","    we wish to add in extra statistics or extra group-by categories\n","    \"\"\"\n","    group_df = df.groupby(group).agg(aggstats)\n","    group_df.columns = aggcolnames\n","    group_df.reset_index(inplace=True)\n","    if no_merge:  # this creates the initial monthly-grouped dataframe into which we will merge all other grouped statistics\n","        monthly_df = group_df.copy(deep=True)\n","    else:\n","        monthly_df = monthly_df.merge(group_df, on = group, how = 'left')\n","    return monthly_df           # original monthly_df merged with aggregated and suitably named stats columns created from ungrouped dataframe (stt)\n","\n","# basic_stats are aggregate functions computed for the typical feature grouping\n","basic_stats = OrderedDict({'sales':['sum']})\n","# initial_stats is for first pass through the feature calculations (group by 'shop_item')... 7/1 changed from 'median' to 'first' for speed(?)\n","initial_stats = OrderedDict({'shop_typeA':['first'], 'shop_typeB':['first'], 'shop_fd':['first'], 'item_cat0':['first'],\n","                             'item_catA':['first'], 'item_cat3':['first'], 'item_cluster':['first'], 'sales':['sum']})\n","stats = OrderedDict()\n","# important: do 'shop_item' first, as it sets up configuration for all other categories to hold their values as needed\n","stats['shop_item'] = {'group':['shop_id','item_id'], 'aggstats':initial_stats,'aggnames':['_sales']}\n","# these stats below will get merged into the monthly dataframe created in the line above\n","for f in STATS_COLS:\n","    stats[f] = {'group':[f], 'aggstats':basic_stats, 'aggnames':['_sales']}\n","\n","no_merge = True\n","print('Completed: ',end='')\n","for k,v in stats.items():\n","    group = ['month'] + v['group']\n","    aggstats = v['aggstats']\n","    if k=='shop_item':\n","        aggnames = ['shop_typeA','shop_typeB','shop_fd','item_cat0','item_catA','item_cat3','item_cluster','y_sales']\n","        stats_col_names = ['y_sales']\n","    else:\n","        aggnames = [k+x for x in v['aggnames']]\n","        stats_col_names += aggnames\n","    monthly_stt = compute_stats(df=stt, monthly_df=monthly_stt, no_merge=no_merge, group=group, aggstats=aggstats, aggcolnames=aggnames).copy(deep=True)\n","    no_merge = False\n","    print(f'{k}, ',end='')\n","print('done')\n","\n","monthly_stt.y_sales = monthly_stt.y_sales.clip(SALES_TRAIN_CLIP_L, SALES_TRAIN_CLIP_H)\n","\n","print(f'\\nmonthly_stt all aggregate column names: {stats_col_names}')\n","print(f'\\nmonthly_stt fully grouped and merged: memory usage before downcast = {monthly_stt.memory_usage(deep=True).sum()/1e6:.0f} MBytes')\n","\n","monthly_stt = monthly_stt.reset_index(drop=True).apply(pd.to_numeric, downcast='integer')\n","print('\\nmonthly_stt (after reset_index: and downcast):')\n","print_col_info(monthly_stt,6)\n","print('\\n')\n","print(monthly_stt.head())\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Completed: shop_item, shop_id, shop_typeA, shop_typeB, shop_fd, item_id, item_cat0, item_catA, item_cat3, item_cluster, done\n","\n","monthly_stt all aggregate column names: ['y_sales', 'shop_id_sales', 'shop_typeA_sales', 'shop_typeB_sales', 'shop_fd_sales', 'item_id_sales', 'item_cat0_sales', 'item_catA_sales', 'item_cat3_sales', 'item_cluster_sales']\n","\n","monthly_stt fully grouped and merged: memory usage before downcast = 219 MBytes\n","\n","monthly_stt (after reset_index: and downcast):\n","  Column Name    DType MBytes               Column Name    DType MBytes                 Column Name    DType MBytes       \n","        Index    int64    0.0                 item_cat0     int8    1.8            shop_typeB_sales    int32    7.3       \n","        month     int8    1.8                 item_catA     int8    1.8               shop_fd_sales    int32    7.3       \n","      shop_id     int8    1.8                 item_cat3     int8    1.8               item_id_sales    int16    3.6       \n","      item_id    int16    3.6              item_cluster    int16    3.6             item_cat0_sales    int32    7.3       \n","   shop_typeA     int8    1.8                   y_sales     int8    1.8             item_catA_sales    int32    7.3       \n","   shop_typeB     int8    1.8             shop_id_sales    int16    3.6             item_cat3_sales    int32    7.3       \n","      shop_fd     int8    1.8          shop_typeA_sales    int32    7.3          item_cluster_sales    int16    3.6       \n","\n","Number of rows in DataFrame: 1,823,320\n","DataFrame total memory usage: 78 MB\n","\n","\n","   month  shop_id  item_id  shop_typeA  shop_typeB  shop_fd  item_cat0  item_catA  item_cat3  item_cluster  y_sales  shop_id_sales  shop_typeA_sales  shop_typeB_sales  shop_fd_sales  item_id_sales  item_cat0_sales  \\\n","0      0        2       27           9           0        5         19          5          4           158        1           1146              5258            118426           5258              7             8983   \n","1      0        2       33           9           0        5         37         18          7           167        1           1146              5258            118426           5258             61             6094   \n","2      0        2      317           9           0        5         45          6          1           114        1           1146              5258            118426           5258              3              333   \n","3      0        2      438           9           0        5         45          6          1           114        1           1146              5258            118426           5258              5              333   \n","4      0        2      471           9           0        5         49         19          1           318        2           1146              5258            118426           5258             31              939   \n","\n","   item_catA_sales  item_cat3_sales  item_cluster_sales  \n","0            14677            46493                  66  \n","1             7724            43002                 360  \n","2            62565             2625                 255  \n","3            62565             2625                 255  \n","4              940             2625                 387  \n","Done: Sat 08:31:06 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nLmjmqw1oihf"},"source":["##**Add Cartesian Product rows to the training data:**\n","Idea is to help the model by informing it that we explicitly have no information about certain relevant shop_item pairs in certain months."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b5sECVIITIlK"},"source":["###*Use numpy to create Cartesian Product:*\n","Each month in train data will have additional rows such that the Cartesian Product of all shops and items ALREADY PRESENT IN THAT MONTH will be included.</br>\n","\n","When we merge lagged features below, we will only forward-shift the shop-item pairs that are present in the later month.</br>\n","*(Might revisit later, if memory requirements not too big, can forward-shift all shop-item pairs.)*"]},{"cell_type":"code","metadata":{"id":"YW5giGxfrv5-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865878885,"user_tz":240,"elapsed":49722,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"7d313741-3262-45da-fe57-d03e1e47bc83"},"source":["try: del stt\n","except: pass\n","\n","# Create cartesian product so model has info to look at for every relevant shop-item-month combination in the months desired\n","# add enough months of cartesian product that after time-LAGS, we end up with CartProds in months CARTESIAN_FILL_MONTH_START through 33 (don't need to fill month 34)\n","matrix = []\n","cols = ['month','shop_id','item_id']\n","for i in range(max(CARTESIAN_FILL_MONTH_START-max(LAGS),0),34):\n","    sales = monthly_stt[monthly_stt.month == i]\n","    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))    \n","\n","df = pd.DataFrame(np.vstack(matrix), columns=cols)\n","\n","# merge in the rows from training set with month < (CART_FILL_MO_START-max(LAGS))\n","if CARTESIAN_FILL_MONTH_START > max(LAGS):\n","    df = monthly_stt[monthly_stt.month < (CARTESIAN_FILL_MONTH_START-max(LAGS))][['month','shop_id','item_id']].append(df, ignore_index=True)\n","# now merge in the rows for the test set, month 34\n","df = df.append(monthly_stt[monthly_stt.month ==34][['month','shop_id','item_id']], ignore_index=True)\n","df.sort_values(cols,inplace=True)\n","df = df.reset_index(drop=True)\n","df = df.apply(pd.to_numeric, downcast='integer') # Downcast to save memory\n","\n","print(f'Column Data Types: \\n{df.dtypes}\\n')\n","print(f'Number of months: {df.month.nunique():,d}')\n","print(f'Number of shops: {df.shop_id.nunique():,d}')\n","print(f'Number of items: {df.item_id.nunique():,d}')\n","print(f'DataFrame length: {len(df):,d}\\n')\n","print(f'df memory usage: {df.memory_usage(deep=True).sum()/1e6:.0f} MBytes')\n","\n","print(f'\\nDone: {strftime(\"%a %X %x\")}')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Column Data Types: \n","month       int8\n","shop_id     int8\n","item_id    int16\n","dtype: object\n","\n","Number of months: 35\n","Number of shops: 57\n","Number of items: 22,169\n","DataFrame length: 10,510,260\n","\n","df memory usage: 42 MBytes\n","\n","Done: Sat 08:31:17 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xce3Fw4tU3P9"},"source":["###*Merge feature info into Cartesian Product dataframe:*"]},{"cell_type":"code","metadata":{"id":"9m4TV9gY0BvP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865883647,"user_tz":240,"elapsed":54477,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"f2fb73c3-b9c3-4136-8677-394ebcfdcebd"},"source":["# First, merge the shops_purged dataframe: (can't just merge with monthly_stt, because cartesian product df has more shop-item pairs)\n","df = df.merge(shops_purged, how='left', on='shop_id')\n","# Next, merge the items_purged dataframe to be sure we cover all items in the cartesian product df\n","df = df.merge(items_purged, how='left', on='item_id')\n","#df['shop_item_test'] = df.shop_test * df.item_test\n","\n","df = df.reset_index(drop=True)\n","df = df.apply(pd.to_numeric, downcast='integer')\n","\n","print('Cartesian-product df:') # (after downcast):')\n","print_col_info(df,6)\n","print(f'\\nDone: {strftime(\"%a %X %x\")}')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Cartesian-product df:\n","  Column Name    DType  MBytes           Column Name    DType  MBytes       \n","        Index    int64     0.0               shop_fd     int8    10.5       \n","        month     int8    10.5          item_cluster    int16    21.0       \n","      shop_id     int8    10.5             item_cat0     int8    10.5       \n","      item_id    int16    21.0             item_catA     int8    10.5       \n","   shop_typeA     int8    10.5             item_cat3     int8    10.5       \n","   shop_typeB     int8    10.5                                              \n","\n","Number of rows in DataFrame: 10,510,260\n","DataFrame total memory usage: 126 MB\n","\n","Done: Sat 08:31:22 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aWEbp9hBVIqd"},"source":["###*Merge real-time statistics info into Cartesian Product dataframe:*"]},{"cell_type":"code","metadata":{"id":"Sv1FtGXOIhgY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865897871,"user_tz":240,"elapsed":68695,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"5efaa38a-fc5a-4465-8b68-53df57b220a2"},"source":["# Now we merge in the real-time block-month data and see if memory requirements aren't overloading Colab:\n","\n","# df = df.merge(monthly_stt, how='left',on=PRE_LAG_COLUMNS).fillna(0).reset_index(drop=True) \n","df = df.merge(monthly_stt, how='left',on=PRE_LAG_COLUMNS).reset_index(drop=True)   # leave cartesian product row unknowns as N/A\n","\n","#df = df.apply(pd.to_numeric, downcast='integer')\n","#df = df.apply(pd.to_numeric, downcast='float')  # if not using fillna(0), need to use float rather than integer\n","\n","print('Cartesian-product df:') # (after downcast):')\n","print_col_info(df,6)\n","print(f'\\ndf.head:\\n{df.head()}')\n","print(f'\\ndf.tail:\\n{df.tail()}\\n')\n","display(df.describe())\n","\n","print(f'\\nDone: {strftime(\"%a %X %x\")}')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Cartesian-product df:\n","  Column Name    DType  MBytes               Column Name      DType  MBytes                 Column Name      DType  MBytes       \n","        Index    int64     0.0              item_cluster      int16    21.0            shop_typeB_sales    float64    84.1       \n","        month     int8    10.5                 item_cat0       int8    10.5               shop_fd_sales    float64    84.1       \n","      shop_id     int8    10.5                 item_catA       int8    10.5               item_id_sales    float64    84.1       \n","      item_id    int16    21.0                 item_cat3       int8    10.5             item_cat0_sales    float64    84.1       \n","   shop_typeA     int8    10.5                   y_sales    float64    84.1             item_catA_sales    float64    84.1       \n","   shop_typeB     int8    10.5             shop_id_sales    float64    84.1             item_cat3_sales    float64    84.1       \n","      shop_fd     int8    10.5          shop_typeA_sales    float64    84.1          item_cluster_sales    float64    84.1       \n","\n","Number of rows in DataFrame: 10,510,260\n","DataFrame total memory usage: 967 MB\n","\n","df.head:\n","   month  shop_id  item_id  shop_typeA  shop_typeB  shop_fd  item_cluster  item_cat0  item_catA  item_cat3  y_sales  shop_id_sales  shop_typeA_sales  shop_typeB_sales  shop_fd_sales  item_id_sales  item_cat0_sales  \\\n","0      0        2       27           9           0        5           158         19          5          4        1           1146              5258            118426           5258              7             8983   \n","1      0        2       33           9           0        5           167         37         18          7        1           1146              5258            118426           5258             61             6094   \n","2      0        2      317           9           0        5           114         45          6          1        1           1146              5258            118426           5258              3              333   \n","3      0        2      438           9           0        5           114         45          6          1        1           1146              5258            118426           5258              5              333   \n","4      0        2      471           9           0        5           318         49         19          1        2           1146              5258            118426           5258             31              939   \n","\n","   item_catA_sales  item_cat3_sales  item_cluster_sales  \n","0            14677            46493                  66  \n","1             7724            43002                 360  \n","2            62565             2625                 255  \n","3            62565             2625                 255  \n","4              940             2625                 387  \n","\n","df.tail:\n","          month  shop_id  item_id  shop_typeA  shop_typeB  shop_fd  item_cluster  item_cat0  item_catA  item_cat3  y_sales  shop_id_sales  shop_typeA_sales  shop_typeB_sales  shop_fd_sales  item_id_sales  \\\n","10510255     34       59    22162           6           0        0           737         40          6          7        0              0                 0                 0              0              0   \n","10510256     34       59    22163           6           0        0           737         40          6          7        0              0                 0                 0              0              0   \n","10510257     34       59    22164           6           0        0           737         37         18          7        0              0                 0                 0              0              0   \n","10510258     34       59    22166           6           0        0           215         54          6          1        0              0                 0                 0              0              0   \n","10510259     34       59    22167           6           0        0           218         49         19          1        0              0                 0                 0              0              0   \n","\n","          item_cat0_sales  item_catA_sales  item_cat3_sales  item_cluster_sales  \n","10510255                0                0                0                   0  \n","10510256                0                0                0                   0  \n","10510257                0                0                0                   0  \n","10510258                0                0                0                   0  \n","10510259                0                0                0                   0  \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>month</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>shop_typeA</th>\n","      <th>shop_typeB</th>\n","      <th>shop_fd</th>\n","      <th>item_cluster</th>\n","      <th>item_cat0</th>\n","      <th>item_catA</th>\n","      <th>item_cat3</th>\n","      <th>y_sales</th>\n","      <th>shop_id_sales</th>\n","      <th>shop_typeA_sales</th>\n","      <th>shop_typeB_sales</th>\n","      <th>shop_fd_sales</th>\n","      <th>item_id_sales</th>\n","      <th>item_cat0_sales</th>\n","      <th>item_catA_sales</th>\n","      <th>item_cat3_sales</th>\n","      <th>item_cluster_sales</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>10510260</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","      <td>1823320</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>16.211</td>\n","      <td>31.457</td>\n","      <td>11,295.066</td>\n","      <td>6.277</td>\n","      <td>0.223</td>\n","      <td>2.585</td>\n","      <td>396.850</td>\n","      <td>44.911</td>\n","      <td>10.185</td>\n","      <td>6.070</td>\n","      <td>1.785</td>\n","      <td>2,914.758</td>\n","      <td>23,238.476</td>\n","      <td>76,108.498</td>\n","      <td>34,607.651</td>\n","      <td>50.881</td>\n","      <td>8,190.894</td>\n","      <td>16,903.223</td>\n","      <td>22,607.627</td>\n","      <td>895.903</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9.336</td>\n","      <td>17.335</td>\n","      <td>6,221.919</td>\n","      <td>3.277</td>\n","      <td>0.587</td>\n","      <td>2.761</td>\n","      <td>324.941</td>\n","      <td>15.232</td>\n","      <td>7.064</td>\n","      <td>2.120</td>\n","      <td>2.508</td>\n","      <td>2,625.280</td>\n","      <td>22,516.130</td>\n","      <td>44,326.220</td>\n","      <td>32,341.632</td>\n","      <td>194.229</td>\n","      <td>8,668.298</td>\n","      <td>18,113.316</td>\n","      <td>16,135.482</td>\n","      <td>1,471.282</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-20</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-20</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-2</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>5903</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>152</td>\n","      <td>37</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1251</td>\n","      <td>5258</td>\n","      <td>54314</td>\n","      <td>6024</td>\n","      <td>5</td>\n","      <td>1016</td>\n","      <td>4597</td>\n","      <td>11228</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>16</td>\n","      <td>31</td>\n","      <td>11381</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>285</td>\n","      <td>40</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>2060</td>\n","      <td>11743</td>\n","      <td>91056</td>\n","      <td>13283</td>\n","      <td>16</td>\n","      <td>5855</td>\n","      <td>9461</td>\n","      <td>19843</td>\n","      <td>234</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>24</td>\n","      <td>47</td>\n","      <td>16582</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>521</td>\n","      <td>55</td>\n","      <td>18</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>3800</td>\n","      <td>42932</td>\n","      <td>108540</td>\n","      <td>64747</td>\n","      <td>44</td>\n","      <td>12208</td>\n","      <td>26343</td>\n","      <td>35710</td>\n","      <td>921</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>34</td>\n","      <td>59</td>\n","      <td>22169</td>\n","      <td>13</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>1502</td>\n","      <td>83</td>\n","      <td>26</td>\n","      <td>11</td>\n","      <td>20</td>\n","      <td>15587</td>\n","      <td>81429</td>\n","      <td>157742</td>\n","      <td>105219</td>\n","      <td>9619</td>\n","      <td>36253</td>\n","      <td>69617</td>\n","      <td>64237</td>\n","      <td>9619</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         month  shop_id    item_id  shop_typeA  shop_typeB  shop_fd  item_cluster  item_cat0  item_catA  item_cat3  y_sales  shop_id_sales  shop_typeA_sales  shop_typeB_sales  shop_fd_sales  item_id_sales  \\\n","count 10510260 10510260   10510260    10510260    10510260 10510260      10510260   10510260   10510260   10510260  1823320        1823320           1823320           1823320        1823320        1823320   \n","mean    16.211   31.457 11,295.066       6.277       0.223    2.585       396.850     44.911     10.185      6.070    1.785      2,914.758        23,238.476        76,108.498     34,607.651         50.881   \n","std      9.336   17.335  6,221.919       3.277       0.587    2.761       324.941     15.232      7.064      2.120    2.508      2,625.280        22,516.130        44,326.220     32,341.632        194.229   \n","min          0        2          0           0           0        0            37          0          0          0      -20             -1                -1                 0              0            -20   \n","25%          8       16       5903           4           0        0           152         37          6          5        1           1251              5258             54314           6024              5   \n","50%         16       31      11381           6           0        2           285         40          6          7        1           2060             11743             91056          13283             16   \n","75%         24       47      16582           9           0        5           521         55         18          7        2           3800             42932            108540          64747             44   \n","max         34       59      22169          13           2        7          1502         83         26         11       20          15587             81429            157742         105219           9619   \n","\n","       item_cat0_sales  item_catA_sales  item_cat3_sales  item_cluster_sales  \n","count          1823320          1823320          1823320             1823320  \n","mean         8,190.894       16,903.223       22,607.627             895.903  \n","std          8,668.298       18,113.316       16,135.482           1,471.282  \n","min                 -1                0               -1                  -2  \n","25%               1016             4597            11228                  51  \n","50%               5855             9461            19843                 234  \n","75%              12208            26343            35710                 921  \n","max              36253            69617            64237                9619  "]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Done: Sat 08:31:36 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4kjKndgDM8Wi","colab_type":"text"},"source":["##**Compute and Merge the Time-Lag Features into Train + Test data sets**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PYrRXBR7S27q"},"source":["###*Set up lag options before merging:*"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3bdpJsWZW04v","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865897872,"user_tz":240,"elapsed":68690,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"8c16a60a-c7f3-447a-d3b0-9ab68880d66f"},"source":["try: del monthly_stt\n","except: pass\n","\n","#############################################################################\n","# This code cell determines which time-lag features we will use for each of the lags we choose (e.g., month 1 lag might use all stats, and month 6 lag might use only shop_item_sales stats)\n","#\n","# Actual choices of what month lags to use is defined above with other \"constants\" in the variable list LAGS\n","#############################################################################\n","\n","columns_to_lag = {}\n","lagged_col_names = OrderedDict()\n","lag_merge_on_cols = ['month','shop_id','item_id']\n","\n","for i in range(1,13):  # for now, just set up for possible lags from 1 month to 12 months\n","    columns_to_lag[i] = stats_col_names  # include all stats columns in all lag months for simplicity now; can in future reduce this list for longer delays, e.g., to reduce memory requirements\n","    suffix = '_L'+str(i)\n","    lagged_col_names[i] = lag_merge_on_cols + [x + suffix for x in columns_to_lag[i]]\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Done: Sat 08:31:36 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nVew2KThVzWw"},"source":["###*Merge lag stats and check dataframe memory requirements:*"]},{"cell_type":"code","metadata":{"id":"i4SxT9QYbkWK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593865940117,"user_tz":240,"elapsed":110928,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"04d42145-cd37-4632-8a0f-bec32c2a571b"},"source":["%%time\n","# shift the stuff and merge into df\n","#   drop any rows in t-lag that don't have matching shop-item pair at time t\n","print(f'Unlagged DataFrame length: {len(df):,d}\\n')\n","dfL = df.copy(deep=True)\n","dfL['y_target'] = df.y_sales.copy(deep=True)  # keep an unlagged version of shop_item sales per month as our training / test target value\n","for L in LAGS:\n","    cols_to_shift = lag_merge_on_cols + columns_to_lag[L]\n","    lag_df = df[cols_to_shift].copy(deep=True)  \n","    lag_df.eval('month = month + @L', inplace=True)\n","    lag_df.columns = lagged_col_names[L]\n","    print(f'Column names for lag = {L}: {lag_df.columns}')\n","    dfL = dfL.merge(lag_df, on = lag_merge_on_cols, how = 'left')  # 'left' serves to discard rows from earlier month if there is no match with later month\n","\n","print(f'Lagged {L} DataFrame length: {len(dfL):,d}\\n')\n","dfL.drop(stats_col_names, axis=1, inplace=True) # remove real-time stats, as we won't have this while doing predictions\n","dfL = dfL[dfL.month >= CARTESIAN_FILL_MONTH_START]      # remove early months that don't have full complement of lagged cartesian product info\n","dfL = dfL.reset_index(drop=True)\n","dfL = dfL.apply(pd.to_numeric, downcast='float') #'integer')  #'unsigned')\n","print('Cartesian-product with lagged features dfL (after downcast):')\n","print_col_info(dfL,8)\n","print(f'\\ndfL.head():\\n{dfL.head()}')\n","\n","print(f'\\nDone: {strftime(\"%a %X %x\")}\\n')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Unlagged DataFrame length: 10,510,260\n","\n","Column names for lag = 1: Index(['month', 'shop_id', 'item_id', 'y_sales_L1', 'shop_id_sales_L1', 'shop_typeA_sales_L1', 'shop_typeB_sales_L1', 'shop_fd_sales_L1', 'item_id_sales_L1', 'item_cat0_sales_L1', 'item_catA_sales_L1',\n","       'item_cat3_sales_L1', 'item_cluster_sales_L1'],\n","      dtype='object')\n","Column names for lag = 2: Index(['month', 'shop_id', 'item_id', 'y_sales_L2', 'shop_id_sales_L2', 'shop_typeA_sales_L2', 'shop_typeB_sales_L2', 'shop_fd_sales_L2', 'item_id_sales_L2', 'item_cat0_sales_L2', 'item_catA_sales_L2',\n","       'item_cat3_sales_L2', 'item_cluster_sales_L2'],\n","      dtype='object')\n","Column names for lag = 3: Index(['month', 'shop_id', 'item_id', 'y_sales_L3', 'shop_id_sales_L3', 'shop_typeA_sales_L3', 'shop_typeB_sales_L3', 'shop_fd_sales_L3', 'item_id_sales_L3', 'item_cat0_sales_L3', 'item_catA_sales_L3',\n","       'item_cat3_sales_L3', 'item_cluster_sales_L3'],\n","      dtype='object')\n","Column names for lag = 6: Index(['month', 'shop_id', 'item_id', 'y_sales_L6', 'shop_id_sales_L6', 'shop_typeA_sales_L6', 'shop_typeB_sales_L6', 'shop_fd_sales_L6', 'item_id_sales_L6', 'item_cat0_sales_L6', 'item_catA_sales_L6',\n","       'item_cat3_sales_L6', 'item_cluster_sales_L6'],\n","      dtype='object')\n","Lagged 6 DataFrame length: 10,510,260\n","\n","Cartesian-product with lagged features dfL (after downcast):\n","    Column Name    DType  MBytes                  Column Name      DType  MBytes                    Column Name      DType  MBytes                    Column Name      DType  MBytes                    Column Name      DType  MBytes                    Column Name      DType  MBytes       \n","          Index    int64     0.0                    item_catA       int8     8.1             item_cat0_sales_L1    float32    32.5               item_id_sales_L2    float32    32.5               shop_fd_sales_L3    float32    32.5            shop_typeB_sales_L6    float32    32.5       \n","          month     int8     8.1                    item_cat3       int8     8.1             item_catA_sales_L1    float32    32.5             item_cat0_sales_L2    float32    32.5               item_id_sales_L3    float32    32.5               shop_fd_sales_L6    float32    32.5       \n","        shop_id     int8     8.1                     y_target    float32    32.5             item_cat3_sales_L1    float32    32.5             item_catA_sales_L2    float32    32.5             item_cat0_sales_L3    float32    32.5               item_id_sales_L6    float32    32.5       \n","        item_id    int16    16.2                   y_sales_L1    float32    32.5          item_cluster_sales_L1    float32    32.5             item_cat3_sales_L2    float32    32.5             item_catA_sales_L3    float32    32.5             item_cat0_sales_L6    float32    32.5       \n","     shop_typeA     int8     8.1             shop_id_sales_L1    float32    32.5                     y_sales_L2    float32    32.5          item_cluster_sales_L2    float32    32.5             item_cat3_sales_L3    float32    32.5             item_catA_sales_L6    float32    32.5       \n","     shop_typeB     int8     8.1          shop_typeA_sales_L1    float32    32.5               shop_id_sales_L2    float32    32.5                     y_sales_L3    float32    32.5          item_cluster_sales_L3    float32    32.5             item_cat3_sales_L6    float32    32.5       \n","        shop_fd     int8     8.1          shop_typeB_sales_L1    float32    32.5            shop_typeA_sales_L2    float32    32.5               shop_id_sales_L3    float32    32.5                     y_sales_L6    float32    32.5          item_cluster_sales_L6    float32    32.5       \n","   item_cluster    int16    16.2             shop_fd_sales_L1    float32    32.5            shop_typeB_sales_L2    float32    32.5            shop_typeA_sales_L3    float32    32.5               shop_id_sales_L6    float32    32.5                                                         \n","      item_cat0     int8     8.1             item_id_sales_L1    float32    32.5               shop_fd_sales_L2    float32    32.5            shop_typeB_sales_L3    float32    32.5            shop_typeA_sales_L6    float32    32.5                                                         \n","\n","Number of rows in DataFrame: 8,117,271\n","DataFrame total memory usage: 1429 MB\n","\n","dfL.head():\n","   month  shop_id  item_id  shop_typeA  shop_typeB  shop_fd  item_cluster  item_cat0  item_catA  item_cat3  y_target  y_sales_L1  shop_id_sales_L1  shop_typeA_sales_L1  shop_typeB_sales_L1  ...  item_id_sales_L3  \\\n","0      8        2       27           9           0        5           158         19          5          4       nan         nan               nan                  nan                  nan  ...               nan   \n","1      8        2       28           9           0        5           158         30          6          4       nan         nan               nan                  nan                  nan  ...               nan   \n","2      8        2       30           9           0        5           158         40          6          7       nan         nan               nan                  nan                  nan  ...                49   \n","3      8        2       31           9           0        5           158         37         18          7       nan         nan               nan                  nan                  nan  ...               nan   \n","4      8        2       32           9           0        5           167         40          6          7       nan         nan               nan                  nan                  nan  ...               nan   \n","\n","   item_cat0_sales_L3  item_catA_sales_L3  item_cat3_sales_L3  item_cluster_sales_L3  y_sales_L6  shop_id_sales_L6  shop_typeA_sales_L6  shop_typeB_sales_L6  shop_fd_sales_L6  item_id_sales_L6  item_cat0_sales_L6  \\\n","0                 nan                 nan                 nan                    nan         nan               nan                  nan                  nan               nan               nan                 nan   \n","1                 nan                 nan                 nan                    nan         nan               nan                  nan                  nan               nan               nan                 nan   \n","2               25992               49172               35380                    113           1               753                 4629               130460              4629               508               36253   \n","3                 nan                 nan                 nan                    nan           1               753                 4629               130460              4629               219                6088   \n","4                 nan                 nan                 nan                    nan         nan               nan                  nan                  nan               nan               nan                 nan   \n","\n","   item_catA_sales_L6  item_cat3_sales_L6  item_cluster_sales_L6  \n","0                 nan                 nan                    nan  \n","1                 nan                 nan                    nan  \n","2               69617               45498                    846  \n","3                7578               45498                    846  \n","4                 nan                 nan                    nan  \n","\n","[5 rows x 51 columns]\n","\n","Done: Sat 08:32:18 07/04/20\n","\n","CPU times: user 34.4 s, sys: 7.94 s, total: 42.3 s\n","Wall time: 42.2 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ip91WlhglvC4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593865940118,"user_tz":240,"elapsed":110927,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}}},"source":["try: del df\n","except: pass"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jtZ0iBdUCD-Z","colab_type":"text"},"source":["#**Modeling**\n","*   Train/Val/Test split\n","*   Model Fit & Validate\n","*   Test/Submission Results\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9TJk9bzeCjqF","colab_type":"text"},"source":["##**Train/Test split**"]},{"cell_type":"code","metadata":{"id":"9YCzNW7-oHsF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593867187050,"user_tz":240,"elapsed":372,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"5c0198a1-e439-4af9-8a2e-80cce22f4b6c"},"source":["def TTSplit(df=dfL,train_start=TRAIN_START_MONTH,train_end=TRAIN_FINAL_MONTH):\n","    \"\"\"\n","    Split data into training months + a single val month + month 34 test\n","    \"\"\"\n","    #data = df.copy(deep=True) \n","    data = df.drop(['shop_typeB','shop_fd',\n","                    'shop_fd_sales_L1',\n","                    'shop_typeA_sales_L2','shop_typeB_sales_L2','shop_fd_sales_L2',\n","                    'shop_typeA_sales_L3','shop_typeB_sales_L3','shop_fd_sales_L3','shop_id_sales_L3',\n","                    'shop_typeA_sales_L6','shop_typeB_sales_L6','shop_fd_sales_L6','shop_id_sales_L6',\n","                    'item_catA_sales_L6'], axis=1)\n","    data.y_target = data.y_target.fillna(0).clip(SALES_TRAIN_CLIP_L, SALES_TRAIN_CLIP_H)\n","\n","    train = data.query('(month >= @train_start) & (month <= @train_end)')\n","    y_train = train['y_target'].astype(np.float32)\n","    y_train = y_train.reset_index(drop=True)\n","    X_train = train.drop(['y_target'], axis=1)\n","    X_train = X_train.reset_index(drop=True)\n","\n","    val = data.query('(month > (@train_end)) & (month < 34)')\n","    y_val = val['y_target'].astype(np.float32)\n","    y_val = y_val.reset_index(drop=True)\n","    X_val = val.drop(['y_target'], axis=1)\n","    X_val = X_val.reset_index(drop=True)\n","\n","    X_test = data.query('month == 34').drop(['y_target'], axis=1)\n","    X_test = X_test.reset_index(drop=True)\n","\n","    del data\n","    del train\n","    del val\n","\n","    feature_names = X_train.columns\n","    X_train_np = X_train.to_numpy(dtype = np.float32)\n","    X_val_np = X_val.to_numpy(dtype = np.float32)\n","    X_test_np = X_test.to_numpy(dtype = np.float32)\n","\n","    print(f'\\nsize of X_train_np = {X_train_np.nbytes/(10**6):0.1f} MB')\n","\n","    del X_train\n","    del X_val\n","\n","    return X_test,y_train,y_val,feature_names,X_train_np,X_val_np,X_test_np\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Done: Sat 08:53:05 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HprRItOZV8o6","colab_type":"text"},"source":["##**LightGBM - Lightweight Gradient-Boosted Decision Tree**"]},{"cell_type":"code","metadata":{"id":"CyAnC6q2qG6w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593865940119,"user_tz":240,"elapsed":110915,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"809fadfb-1297-466b-af34-4b6d300e8138"},"source":["def model(X_train_np, y_train, X_val_np, y_val, X_test_np):\n","    # Adjust LGBM Parameters to see if we can get a better result\n","    model_lgbm = LGBMRegressor(\n","        objective='regression', \n","        boosting='gbdt',\n","        metric='rmse',\n","        device_type='cpu',\n","        verbosity=2,\n","        #output_freq=10,\n","        learning_rate=0.05, #0.1,\n","        num_iterations=1000,\n","        early_stopping_round=50,\n","        feature_fraction=0.8,\n","        seed=42\n","    )\n","\n","    # categorical_feature=1,2,3,4,5,6  LGBM doesn't like this as a parameter\n","    #min_data_per_group=100,\n","    #max_cat_to_onehot=8,\n","    #top_k=20,\n","    #max_bin=255,\n","    #min_data_in_bin=3,\n","\n","    model_lgbm.fit(X_train_np, y_train,\n","                eval_set=[(X_val_np, y_val)])\n","        \n","\n","    y_pred_train =  model_lgbm.predict(X_train_np).clip(SALES_PREDICT_CLIP_L, SALES_PREDICT_CLIP_H)\n","    y_pred_val = model_lgbm.predict(X_val_np).clip(SALES_PREDICT_CLIP_L, SALES_PREDICT_CLIP_H)\n","    y_pred_test = model_lgbm.predict(X_test_np).clip(SALES_PREDICT_CLIP_L, SALES_PREDICT_CLIP_H)\n","    train_score, val_score = sklearn.metrics.r2_score(y_train, y_pred_train), sklearn.metrics.r2_score(y_val, y_pred_val)\n","    train_rmse, val_rmse = np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(sklearn.metrics.mean_squared_error(y_val, y_pred_val))\n","    print(f'R^2 train =  {train_score:.4f}    R^2 val =  {val_score:.4f}')\n","    print(f'RMSE train = {train_rmse:.4f}    RMSE val = {val_rmse:.4f}')\n","\n","    return model_lgbm, y_pred_test, train_score, val_score, train_rmse, val_rmse\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Done: Sat 08:32:18 07/04/20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D2tNdYiiNa7x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593867953629,"user_tz":240,"elapsed":760880,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"1850aa92-ff6b-4990-df5c-0efc56670237"},"source":["ensemble_feature_names = []\n","ensemble_y_pred_test = []\n","ensemble_df_columns = ['train_r2', 'val_r2', 'train_rmse', 'val_rmse']\n","ensemble_df_rows = []\n","for train_final_mo in [30,31,32]:\n","    X_test, y_train, y_val, feature_names, X_train_np, X_val_np, X_test_np = TTSplit(df=dfL,train_start=TRAIN_START_MONTH,train_end=train_final_mo)\n","    model_lgbm, y_pred_test, train_r2, val_r2, train_rmse, val_rmse = model(X_train_np, y_train, X_val_np, y_val, X_test_np)\n","    ensemble_feature_names.append(feature_names)\n","    ensemble_y_pred_test.append(y_pred_test)\n","    ensemble_df_rows.append([train_r2, val_r2, train_rmse, val_rmse])\n","\n","ensemble_scores = pd.DataFrame(ensemble_df_rows, columns = ensemble_df_columns)\n","display(ensemble_scores.head())\n","#####\n","# To do:  loop over several (3?) train end months, and average the test predictions\n","#####\n","# Simple ensemble averaging\n","y_test_pred_avg = np.mean(ensemble_y_pred_test, axis=0)\n","y_pr_test_mrg = pd.DataFrame.from_dict({'item_cnt_month':y_test_pred_avg,'shop_id':X_test.shop_id,'item_id':X_test.item_id})\n","y_pr_test_mrg = test.merge(y_pr_test_mrg, on=['shop_id','item_id'], how= 'left').reset_index(drop=True)\n","y_submission = y_pr_test_mrg.drop(['shop_id','item_id'],axis=1)\n","print(len(y_submission))\n","print(y_submission.head())\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["\n","size of X_train_np = 1012.4 MB\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["[1]\tvalid_0's rmse: 1.10297\n","Training until validation scores don't improve for 50 rounds.\n","[2]\tvalid_0's rmse: 1.08716\n","[3]\tvalid_0's rmse: 1.07237\n","[4]\tvalid_0's rmse: 1.05896\n","[5]\tvalid_0's rmse: 1.0465\n","[6]\tvalid_0's rmse: 1.03525\n","[7]\tvalid_0's rmse: 1.02471\n","[8]\tvalid_0's rmse: 1.01687\n","[9]\tvalid_0's rmse: 1.00793\n","[10]\tvalid_0's rmse: 0.999803\n","[11]\tvalid_0's rmse: 0.991929\n","[12]\tvalid_0's rmse: 0.985404\n","[13]\tvalid_0's rmse: 0.979776\n","[14]\tvalid_0's rmse: 0.974015\n","[15]\tvalid_0's rmse: 0.968672\n","[16]\tvalid_0's rmse: 0.964049\n","[17]\tvalid_0's rmse: 0.960403\n","[18]\tvalid_0's rmse: 0.956265\n","[19]\tvalid_0's rmse: 0.952231\n","[20]\tvalid_0's rmse: 0.948287\n","[21]\tvalid_0's rmse: 0.945496\n","[22]\tvalid_0's rmse: 0.942304\n","[23]\tvalid_0's rmse: 0.939797\n","[24]\tvalid_0's rmse: 0.93709\n","[25]\tvalid_0's rmse: 0.934693\n","[26]\tvalid_0's rmse: 0.932675\n","[27]\tvalid_0's rmse: 0.930615\n","[28]\tvalid_0's rmse: 0.928696\n","[29]\tvalid_0's rmse: 0.92665\n","[30]\tvalid_0's rmse: 0.925115\n","[31]\tvalid_0's rmse: 0.923664\n","[32]\tvalid_0's rmse: 0.922315\n","[33]\tvalid_0's rmse: 0.921014\n","[34]\tvalid_0's rmse: 0.920078\n","[35]\tvalid_0's rmse: 0.919231\n","[36]\tvalid_0's rmse: 0.918303\n","[37]\tvalid_0's rmse: 0.916845\n","[38]\tvalid_0's rmse: 0.916108\n","[39]\tvalid_0's rmse: 0.915182\n","[40]\tvalid_0's rmse: 0.9144\n","[41]\tvalid_0's rmse: 0.913796\n","[42]\tvalid_0's rmse: 0.913191\n","[43]\tvalid_0's rmse: 0.912445\n","[44]\tvalid_0's rmse: 0.91188\n","[45]\tvalid_0's rmse: 0.911482\n","[46]\tvalid_0's rmse: 0.910891\n","[47]\tvalid_0's rmse: 0.910493\n","[48]\tvalid_0's rmse: 0.909815\n","[49]\tvalid_0's rmse: 0.909461\n","[50]\tvalid_0's rmse: 0.90913\n","[51]\tvalid_0's rmse: 0.90859\n","[52]\tvalid_0's rmse: 0.908226\n","[53]\tvalid_0's rmse: 0.907858\n","[54]\tvalid_0's rmse: 0.907492\n","[55]\tvalid_0's rmse: 0.907067\n","[56]\tvalid_0's rmse: 0.906869\n","[57]\tvalid_0's rmse: 0.90617\n","[58]\tvalid_0's rmse: 0.90586\n","[59]\tvalid_0's rmse: 0.905522\n","[60]\tvalid_0's rmse: 0.905433\n","[61]\tvalid_0's rmse: 0.905263\n","[62]\tvalid_0's rmse: 0.905111\n","[63]\tvalid_0's rmse: 0.904999\n","[64]\tvalid_0's rmse: 0.904506\n","[65]\tvalid_0's rmse: 0.904053\n","[66]\tvalid_0's rmse: 0.903747\n","[67]\tvalid_0's rmse: 0.903154\n","[68]\tvalid_0's rmse: 0.902809\n","[69]\tvalid_0's rmse: 0.902789\n","[70]\tvalid_0's rmse: 0.902512\n","[71]\tvalid_0's rmse: 0.902396\n","[72]\tvalid_0's rmse: 0.901937\n","[73]\tvalid_0's rmse: 0.901756\n","[74]\tvalid_0's rmse: 0.901706\n","[75]\tvalid_0's rmse: 0.901643\n","[76]\tvalid_0's rmse: 0.901632\n","[77]\tvalid_0's rmse: 0.901502\n","[78]\tvalid_0's rmse: 0.901403\n","[79]\tvalid_0's rmse: 0.901214\n","[80]\tvalid_0's rmse: 0.901085\n","[81]\tvalid_0's rmse: 0.90097\n","[82]\tvalid_0's rmse: 0.900948\n","[83]\tvalid_0's rmse: 0.900893\n","[84]\tvalid_0's rmse: 0.900782\n","[85]\tvalid_0's rmse: 0.900676\n","[86]\tvalid_0's rmse: 0.900562\n","[87]\tvalid_0's rmse: 0.900491\n","[88]\tvalid_0's rmse: 0.900342\n","[89]\tvalid_0's rmse: 0.900314\n","[90]\tvalid_0's rmse: 0.900243\n","[91]\tvalid_0's rmse: 0.900275\n","[92]\tvalid_0's rmse: 0.900296\n","[93]\tvalid_0's rmse: 0.89996\n","[94]\tvalid_0's rmse: 0.899945\n","[95]\tvalid_0's rmse: 0.899393\n","[96]\tvalid_0's rmse: 0.899191\n","[97]\tvalid_0's rmse: 0.899057\n","[98]\tvalid_0's rmse: 0.899064\n","[99]\tvalid_0's rmse: 0.898962\n","[100]\tvalid_0's rmse: 0.89872\n","[101]\tvalid_0's rmse: 0.898665\n","[102]\tvalid_0's rmse: 0.898144\n","[103]\tvalid_0's rmse: 0.89815\n","[104]\tvalid_0's rmse: 0.897962\n","[105]\tvalid_0's rmse: 0.897872\n","[106]\tvalid_0's rmse: 0.897535\n","[107]\tvalid_0's rmse: 0.897568\n","[108]\tvalid_0's rmse: 0.897442\n","[109]\tvalid_0's rmse: 0.897444\n","[110]\tvalid_0's rmse: 0.897446\n","[111]\tvalid_0's rmse: 0.895993\n","[112]\tvalid_0's rmse: 0.895944\n","[113]\tvalid_0's rmse: 0.895944\n","[114]\tvalid_0's rmse: 0.895224\n","[115]\tvalid_0's rmse: 0.895131\n","[116]\tvalid_0's rmse: 0.895058\n","[117]\tvalid_0's rmse: 0.895088\n","[118]\tvalid_0's rmse: 0.895087\n","[119]\tvalid_0's rmse: 0.894856\n","[120]\tvalid_0's rmse: 0.894852\n","[121]\tvalid_0's rmse: 0.894846\n","[122]\tvalid_0's rmse: 0.894768\n","[123]\tvalid_0's rmse: 0.894639\n","[124]\tvalid_0's rmse: 0.894641\n","[125]\tvalid_0's rmse: 0.894473\n","[126]\tvalid_0's rmse: 0.894421\n","[127]\tvalid_0's rmse: 0.894419\n","[128]\tvalid_0's rmse: 0.894125\n","[129]\tvalid_0's rmse: 0.893884\n","[130]\tvalid_0's rmse: 0.893873\n","[131]\tvalid_0's rmse: 0.89305\n","[132]\tvalid_0's rmse: 0.893049\n","[133]\tvalid_0's rmse: 0.893057\n","[134]\tvalid_0's rmse: 0.893084\n","[135]\tvalid_0's rmse: 0.891958\n","[136]\tvalid_0's rmse: 0.891963\n","[137]\tvalid_0's rmse: 0.891963\n","[138]\tvalid_0's rmse: 0.891947\n","[139]\tvalid_0's rmse: 0.8919\n","[140]\tvalid_0's rmse: 0.891835\n","[141]\tvalid_0's rmse: 0.89167\n","[142]\tvalid_0's rmse: 0.891672\n","[143]\tvalid_0's rmse: 0.89159\n","[144]\tvalid_0's rmse: 0.891529\n","[145]\tvalid_0's rmse: 0.891493\n","[146]\tvalid_0's rmse: 0.891403\n","[147]\tvalid_0's rmse: 0.891383\n","[148]\tvalid_0's rmse: 0.891346\n","[149]\tvalid_0's rmse: 0.89099\n","[150]\tvalid_0's rmse: 0.890993\n","[151]\tvalid_0's rmse: 0.890919\n","[152]\tvalid_0's rmse: 0.890923\n","[153]\tvalid_0's rmse: 0.890925\n","[154]\tvalid_0's rmse: 0.890903\n","[155]\tvalid_0's rmse: 0.890883\n","[156]\tvalid_0's rmse: 0.89065\n","[157]\tvalid_0's rmse: 0.890629\n","[158]\tvalid_0's rmse: 0.890522\n","[159]\tvalid_0's rmse: 0.890521\n","[160]\tvalid_0's rmse: 0.890472\n","[161]\tvalid_0's rmse: 0.88924\n","[162]\tvalid_0's rmse: 0.889215\n","[163]\tvalid_0's rmse: 0.889098\n","[164]\tvalid_0's rmse: 0.889059\n","[165]\tvalid_0's rmse: 0.889083\n","[166]\tvalid_0's rmse: 0.889111\n","[167]\tvalid_0's rmse: 0.88912\n","[168]\tvalid_0's rmse: 0.889116\n","[169]\tvalid_0's rmse: 0.889122\n","[170]\tvalid_0's rmse: 0.889273\n","[171]\tvalid_0's rmse: 0.889306\n","[172]\tvalid_0's rmse: 0.889396\n","[173]\tvalid_0's rmse: 0.889398\n","[174]\tvalid_0's rmse: 0.889377\n","[175]\tvalid_0's rmse: 0.889176\n","[176]\tvalid_0's rmse: 0.889107\n","[177]\tvalid_0's rmse: 0.888924\n","[178]\tvalid_0's rmse: 0.888916\n","[179]\tvalid_0's rmse: 0.88888\n","[180]\tvalid_0's rmse: 0.888901\n","[181]\tvalid_0's rmse: 0.888933\n","[182]\tvalid_0's rmse: 0.888881\n","[183]\tvalid_0's rmse: 0.888895\n","[184]\tvalid_0's rmse: 0.888898\n","[185]\tvalid_0's rmse: 0.88882\n","[186]\tvalid_0's rmse: 0.888825\n","[187]\tvalid_0's rmse: 0.888781\n","[188]\tvalid_0's rmse: 0.888716\n","[189]\tvalid_0's rmse: 0.888709\n","[190]\tvalid_0's rmse: 0.888645\n","[191]\tvalid_0's rmse: 0.88861\n","[192]\tvalid_0's rmse: 0.88859\n","[193]\tvalid_0's rmse: 0.888592\n","[194]\tvalid_0's rmse: 0.888627\n","[195]\tvalid_0's rmse: 0.888634\n","[196]\tvalid_0's rmse: 0.888597\n","[197]\tvalid_0's rmse: 0.888637\n","[198]\tvalid_0's rmse: 0.888604\n","[199]\tvalid_0's rmse: 0.888542\n","[200]\tvalid_0's rmse: 0.888541\n","[201]\tvalid_0's rmse: 0.888491\n","[202]\tvalid_0's rmse: 0.888459\n","[203]\tvalid_0's rmse: 0.888439\n","[204]\tvalid_0's rmse: 0.888427\n","[205]\tvalid_0's rmse: 0.888401\n","[206]\tvalid_0's rmse: 0.888399\n","[207]\tvalid_0's rmse: 0.888439\n","[208]\tvalid_0's rmse: 0.888445\n","[209]\tvalid_0's rmse: 0.888429\n","[210]\tvalid_0's rmse: 0.888433\n","[211]\tvalid_0's rmse: 0.888464\n","[212]\tvalid_0's rmse: 0.888477\n","[213]\tvalid_0's rmse: 0.888484\n","[214]\tvalid_0's rmse: 0.888417\n","[215]\tvalid_0's rmse: 0.888406\n","[216]\tvalid_0's rmse: 0.888312\n","[217]\tvalid_0's rmse: 0.888294\n","[218]\tvalid_0's rmse: 0.88827\n","[219]\tvalid_0's rmse: 0.887602\n","[220]\tvalid_0's rmse: 0.887595\n","[221]\tvalid_0's rmse: 0.887592\n","[222]\tvalid_0's rmse: 0.887618\n","[223]\tvalid_0's rmse: 0.887593\n","[224]\tvalid_0's rmse: 0.887585\n","[225]\tvalid_0's rmse: 0.887585\n","[226]\tvalid_0's rmse: 0.887578\n","[227]\tvalid_0's rmse: 0.887567\n","[228]\tvalid_0's rmse: 0.887544\n","[229]\tvalid_0's rmse: 0.887551\n","[230]\tvalid_0's rmse: 0.887547\n","[231]\tvalid_0's rmse: 0.887532\n","[232]\tvalid_0's rmse: 0.887514\n","[233]\tvalid_0's rmse: 0.887546\n","[234]\tvalid_0's rmse: 0.887549\n","[235]\tvalid_0's rmse: 0.887549\n","[236]\tvalid_0's rmse: 0.887532\n","[237]\tvalid_0's rmse: 0.887532\n","[238]\tvalid_0's rmse: 0.887484\n","[239]\tvalid_0's rmse: 0.887476\n","[240]\tvalid_0's rmse: 0.887514\n","[241]\tvalid_0's rmse: 0.887536\n","[242]\tvalid_0's rmse: 0.887443\n","[243]\tvalid_0's rmse: 0.887496\n","[244]\tvalid_0's rmse: 0.887448\n","[245]\tvalid_0's rmse: 0.887176\n","[246]\tvalid_0's rmse: 0.887175\n","[247]\tvalid_0's rmse: 0.887171\n","[248]\tvalid_0's rmse: 0.887165\n","[249]\tvalid_0's rmse: 0.88713\n","[250]\tvalid_0's rmse: 0.887132\n","[251]\tvalid_0's rmse: 0.88713\n","[252]\tvalid_0's rmse: 0.887104\n","[253]\tvalid_0's rmse: 0.887085\n","[254]\tvalid_0's rmse: 0.887048\n","[255]\tvalid_0's rmse: 0.88702\n","[256]\tvalid_0's rmse: 0.887026\n","[257]\tvalid_0's rmse: 0.887041\n","[258]\tvalid_0's rmse: 0.886912\n","[259]\tvalid_0's rmse: 0.886911\n","[260]\tvalid_0's rmse: 0.886911\n","[261]\tvalid_0's rmse: 0.886901\n","[262]\tvalid_0's rmse: 0.886907\n","[263]\tvalid_0's rmse: 0.886889\n","[264]\tvalid_0's rmse: 0.886825\n","[265]\tvalid_0's rmse: 0.886791\n","[266]\tvalid_0's rmse: 0.886736\n","[267]\tvalid_0's rmse: 0.886664\n","[268]\tvalid_0's rmse: 0.886643\n","[269]\tvalid_0's rmse: 0.886629\n","[270]\tvalid_0's rmse: 0.886626\n","[271]\tvalid_0's rmse: 0.886623\n","[272]\tvalid_0's rmse: 0.886626\n","[273]\tvalid_0's rmse: 0.886602\n","[274]\tvalid_0's rmse: 0.886622\n","[275]\tvalid_0's rmse: 0.886648\n","[276]\tvalid_0's rmse: 0.886743\n","[277]\tvalid_0's rmse: 0.886717\n","[278]\tvalid_0's rmse: 0.886703\n","[279]\tvalid_0's rmse: 0.886709\n","[280]\tvalid_0's rmse: 0.886698\n","[281]\tvalid_0's rmse: 0.886692\n","[282]\tvalid_0's rmse: 0.886695\n","[283]\tvalid_0's rmse: 0.886692\n","[284]\tvalid_0's rmse: 0.886678\n","[285]\tvalid_0's rmse: 0.88667\n","[286]\tvalid_0's rmse: 0.886673\n","[287]\tvalid_0's rmse: 0.886736\n","[288]\tvalid_0's rmse: 0.886752\n","[289]\tvalid_0's rmse: 0.886719\n","[290]\tvalid_0's rmse: 0.886709\n","[291]\tvalid_0's rmse: 0.886693\n","[292]\tvalid_0's rmse: 0.886653\n","[293]\tvalid_0's rmse: 0.886629\n","[294]\tvalid_0's rmse: 0.886581\n","[295]\tvalid_0's rmse: 0.886604\n","[296]\tvalid_0's rmse: 0.886597\n","[297]\tvalid_0's rmse: 0.88656\n","[298]\tvalid_0's rmse: 0.886626\n","[299]\tvalid_0's rmse: 0.886593\n","[300]\tvalid_0's rmse: 0.886573\n","[301]\tvalid_0's rmse: 0.886559\n","[302]\tvalid_0's rmse: 0.886557\n","[303]\tvalid_0's rmse: 0.886309\n","[304]\tvalid_0's rmse: 0.886446\n","[305]\tvalid_0's rmse: 0.886438\n","[306]\tvalid_0's rmse: 0.886446\n","[307]\tvalid_0's rmse: 0.886437\n","[308]\tvalid_0's rmse: 0.886435\n","[309]\tvalid_0's rmse: 0.88643\n","[310]\tvalid_0's rmse: 0.88645\n","[311]\tvalid_0's rmse: 0.886451\n","[312]\tvalid_0's rmse: 0.886437\n","[313]\tvalid_0's rmse: 0.886426\n","[314]\tvalid_0's rmse: 0.886428\n","[315]\tvalid_0's rmse: 0.886448\n","[316]\tvalid_0's rmse: 0.88647\n","[317]\tvalid_0's rmse: 0.886383\n","[318]\tvalid_0's rmse: 0.886099\n","[319]\tvalid_0's rmse: 0.88605\n","[320]\tvalid_0's rmse: 0.886009\n","[321]\tvalid_0's rmse: 0.885952\n","[322]\tvalid_0's rmse: 0.885902\n","[323]\tvalid_0's rmse: 0.885905\n","[324]\tvalid_0's rmse: 0.885903\n","[325]\tvalid_0's rmse: 0.885904\n","[326]\tvalid_0's rmse: 0.885857\n","[327]\tvalid_0's rmse: 0.885807\n","[328]\tvalid_0's rmse: 0.885806\n","[329]\tvalid_0's rmse: 0.885709\n","[330]\tvalid_0's rmse: 0.885703\n","[331]\tvalid_0's rmse: 0.885665\n","[332]\tvalid_0's rmse: 0.885641\n","[333]\tvalid_0's rmse: 0.885613\n","[334]\tvalid_0's rmse: 0.885619\n","[335]\tvalid_0's rmse: 0.885589\n","[336]\tvalid_0's rmse: 0.885569\n","[337]\tvalid_0's rmse: 0.885588\n","[338]\tvalid_0's rmse: 0.885494\n","[339]\tvalid_0's rmse: 0.885454\n","[340]\tvalid_0's rmse: 0.885446\n","[341]\tvalid_0's rmse: 0.885446\n","[342]\tvalid_0's rmse: 0.885534\n","[343]\tvalid_0's rmse: 0.885561\n","[344]\tvalid_0's rmse: 0.885565\n","[345]\tvalid_0's rmse: 0.885577\n","[346]\tvalid_0's rmse: 0.885575\n","[347]\tvalid_0's rmse: 0.885521\n","[348]\tvalid_0's rmse: 0.885513\n","[349]\tvalid_0's rmse: 0.885531\n","[350]\tvalid_0's rmse: 0.885524\n","[351]\tvalid_0's rmse: 0.885523\n","[352]\tvalid_0's rmse: 0.885517\n","[353]\tvalid_0's rmse: 0.885535\n","[354]\tvalid_0's rmse: 0.885563\n","[355]\tvalid_0's rmse: 0.885565\n","[356]\tvalid_0's rmse: 0.885555\n","[357]\tvalid_0's rmse: 0.885543\n","[358]\tvalid_0's rmse: 0.885481\n","[359]\tvalid_0's rmse: 0.885479\n","[360]\tvalid_0's rmse: 0.885447\n","[361]\tvalid_0's rmse: 0.885464\n","[362]\tvalid_0's rmse: 0.885437\n","[363]\tvalid_0's rmse: 0.885424\n","[364]\tvalid_0's rmse: 0.885428\n","[365]\tvalid_0's rmse: 0.885433\n","[366]\tvalid_0's rmse: 0.885444\n","[367]\tvalid_0's rmse: 0.885409\n","[368]\tvalid_0's rmse: 0.885412\n","[369]\tvalid_0's rmse: 0.885415\n","[370]\tvalid_0's rmse: 0.885408\n","[371]\tvalid_0's rmse: 0.885417\n","[372]\tvalid_0's rmse: 0.885419\n","[373]\tvalid_0's rmse: 0.885406\n","[374]\tvalid_0's rmse: 0.885389\n","[375]\tvalid_0's rmse: 0.885349\n","[376]\tvalid_0's rmse: 0.885355\n","[377]\tvalid_0's rmse: 0.885363\n","[378]\tvalid_0's rmse: 0.885366\n","[379]\tvalid_0's rmse: 0.885346\n","[380]\tvalid_0's rmse: 0.885367\n","[381]\tvalid_0's rmse: 0.885307\n","[382]\tvalid_0's rmse: 0.885326\n","[383]\tvalid_0's rmse: 0.885311\n","[384]\tvalid_0's rmse: 0.885248\n","[385]\tvalid_0's rmse: 0.885209\n","[386]\tvalid_0's rmse: 0.885232\n","[387]\tvalid_0's rmse: 0.885231\n","[388]\tvalid_0's rmse: 0.885228\n","[389]\tvalid_0's rmse: 0.885248\n","[390]\tvalid_0's rmse: 0.885249\n","[391]\tvalid_0's rmse: 0.885247\n","[392]\tvalid_0's rmse: 0.88522\n","[393]\tvalid_0's rmse: 0.885183\n","[394]\tvalid_0's rmse: 0.885149\n","[395]\tvalid_0's rmse: 0.885154\n","[396]\tvalid_0's rmse: 0.885154\n","[397]\tvalid_0's rmse: 0.885152\n","[398]\tvalid_0's rmse: 0.885266\n","[399]\tvalid_0's rmse: 0.885259\n","[400]\tvalid_0's rmse: 0.885252\n","[401]\tvalid_0's rmse: 0.885216\n","[402]\tvalid_0's rmse: 0.885201\n","[403]\tvalid_0's rmse: 0.885195\n","[404]\tvalid_0's rmse: 0.885181\n","[405]\tvalid_0's rmse: 0.885172\n","[406]\tvalid_0's rmse: 0.885158\n","[407]\tvalid_0's rmse: 0.88515\n","[408]\tvalid_0's rmse: 0.885181\n","[409]\tvalid_0's rmse: 0.885195\n","[410]\tvalid_0's rmse: 0.885218\n","[411]\tvalid_0's rmse: 0.885218\n","[412]\tvalid_0's rmse: 0.885207\n","[413]\tvalid_0's rmse: 0.885212\n","[414]\tvalid_0's rmse: 0.885261\n","[415]\tvalid_0's rmse: 0.885264\n","[416]\tvalid_0's rmse: 0.885252\n","[417]\tvalid_0's rmse: 0.885013\n","[418]\tvalid_0's rmse: 0.885006\n","[419]\tvalid_0's rmse: 0.884854\n","[420]\tvalid_0's rmse: 0.8848\n","[421]\tvalid_0's rmse: 0.884803\n","[422]\tvalid_0's rmse: 0.8848\n","[423]\tvalid_0's rmse: 0.884771\n","[424]\tvalid_0's rmse: 0.884784\n","[425]\tvalid_0's rmse: 0.884759\n","[426]\tvalid_0's rmse: 0.884692\n","[427]\tvalid_0's rmse: 0.88468\n","[428]\tvalid_0's rmse: 0.884664\n","[429]\tvalid_0's rmse: 0.884672\n","[430]\tvalid_0's rmse: 0.884669\n","[431]\tvalid_0's rmse: 0.884647\n","[432]\tvalid_0's rmse: 0.884641\n","[433]\tvalid_0's rmse: 0.884647\n","[434]\tvalid_0's rmse: 0.884652\n","[435]\tvalid_0's rmse: 0.884671\n","[436]\tvalid_0's rmse: 0.884702\n","[437]\tvalid_0's rmse: 0.884698\n","[438]\tvalid_0's rmse: 0.884665\n","[439]\tvalid_0's rmse: 0.884688\n","[440]\tvalid_0's rmse: 0.884679\n","[441]\tvalid_0's rmse: 0.884688\n","[442]\tvalid_0's rmse: 0.884697\n","[443]\tvalid_0's rmse: 0.884692\n","[444]\tvalid_0's rmse: 0.884689\n","[445]\tvalid_0's rmse: 0.884717\n","[446]\tvalid_0's rmse: 0.884727\n","[447]\tvalid_0's rmse: 0.884847\n","[448]\tvalid_0's rmse: 0.88485\n","[449]\tvalid_0's rmse: 0.884829\n","[450]\tvalid_0's rmse: 0.884729\n","[451]\tvalid_0's rmse: 0.884729\n","[452]\tvalid_0's rmse: 0.884727\n","[453]\tvalid_0's rmse: 0.884726\n","[454]\tvalid_0's rmse: 0.884678\n","[455]\tvalid_0's rmse: 0.884665\n","[456]\tvalid_0's rmse: 0.884656\n","[457]\tvalid_0's rmse: 0.884672\n","[458]\tvalid_0's rmse: 0.884663\n","[459]\tvalid_0's rmse: 0.884678\n","[460]\tvalid_0's rmse: 0.884637\n","[461]\tvalid_0's rmse: 0.884637\n","[462]\tvalid_0's rmse: 0.884672\n","[463]\tvalid_0's rmse: 0.884665\n","[464]\tvalid_0's rmse: 0.884666\n","[465]\tvalid_0's rmse: 0.884671\n","[466]\tvalid_0's rmse: 0.88467\n","[467]\tvalid_0's rmse: 0.884669\n","[468]\tvalid_0's rmse: 0.884638\n","[469]\tvalid_0's rmse: 0.884667\n","[470]\tvalid_0's rmse: 0.884582\n","[471]\tvalid_0's rmse: 0.884568\n","[472]\tvalid_0's rmse: 0.884581\n","[473]\tvalid_0's rmse: 0.884569\n","[474]\tvalid_0's rmse: 0.884579\n","[475]\tvalid_0's rmse: 0.884555\n","[476]\tvalid_0's rmse: 0.884543\n","[477]\tvalid_0's rmse: 0.884547\n","[478]\tvalid_0's rmse: 0.884537\n","[479]\tvalid_0's rmse: 0.884546\n","[480]\tvalid_0's rmse: 0.884531\n","[481]\tvalid_0's rmse: 0.884534\n","[482]\tvalid_0's rmse: 0.884536\n","[483]\tvalid_0's rmse: 0.884533\n","[484]\tvalid_0's rmse: 0.884488\n","[485]\tvalid_0's rmse: 0.884498\n","[486]\tvalid_0's rmse: 0.884506\n","[487]\tvalid_0's rmse: 0.884509\n","[488]\tvalid_0's rmse: 0.884511\n","[489]\tvalid_0's rmse: 0.884552\n","[490]\tvalid_0's rmse: 0.884536\n","[491]\tvalid_0's rmse: 0.884514\n","[492]\tvalid_0's rmse: 0.884514\n","[493]\tvalid_0's rmse: 0.884507\n","[494]\tvalid_0's rmse: 0.884444\n","[495]\tvalid_0's rmse: 0.884428\n","[496]\tvalid_0's rmse: 0.884422\n","[497]\tvalid_0's rmse: 0.884415\n","[498]\tvalid_0's rmse: 0.884392\n","[499]\tvalid_0's rmse: 0.884392\n","[500]\tvalid_0's rmse: 0.884389\n","[501]\tvalid_0's rmse: 0.884388\n","[502]\tvalid_0's rmse: 0.88438\n","[503]\tvalid_0's rmse: 0.884386\n","[504]\tvalid_0's rmse: 0.884344\n","[505]\tvalid_0's rmse: 0.884352\n","[506]\tvalid_0's rmse: 0.884412\n","[507]\tvalid_0's rmse: 0.884415\n","[508]\tvalid_0's rmse: 0.884414\n","[509]\tvalid_0's rmse: 0.884435\n","[510]\tvalid_0's rmse: 0.884427\n","[511]\tvalid_0's rmse: 0.884349\n","[512]\tvalid_0's rmse: 0.884345\n","[513]\tvalid_0's rmse: 0.883789\n","[514]\tvalid_0's rmse: 0.883782\n","[515]\tvalid_0's rmse: 0.88381\n","[516]\tvalid_0's rmse: 0.883769\n","[517]\tvalid_0's rmse: 0.88379\n","[518]\tvalid_0's rmse: 0.883485\n","[519]\tvalid_0's rmse: 0.883458\n","[520]\tvalid_0's rmse: 0.883422\n","[521]\tvalid_0's rmse: 0.883393\n","[522]\tvalid_0's rmse: 0.883399\n","[523]\tvalid_0's rmse: 0.883395\n","[524]\tvalid_0's rmse: 0.883425\n","[525]\tvalid_0's rmse: 0.883412\n","[526]\tvalid_0's rmse: 0.883403\n","[527]\tvalid_0's rmse: 0.883409\n","[528]\tvalid_0's rmse: 0.883373\n","[529]\tvalid_0's rmse: 0.883373\n","[530]\tvalid_0's rmse: 0.883377\n","[531]\tvalid_0's rmse: 0.883368\n","[532]\tvalid_0's rmse: 0.883367\n","[533]\tvalid_0's rmse: 0.883353\n","[534]\tvalid_0's rmse: 0.883298\n","[535]\tvalid_0's rmse: 0.883308\n","[536]\tvalid_0's rmse: 0.883308\n","[537]\tvalid_0's rmse: 0.883317\n","[538]\tvalid_0's rmse: 0.883296\n","[539]\tvalid_0's rmse: 0.88327\n","[540]\tvalid_0's rmse: 0.883263\n","[541]\tvalid_0's rmse: 0.883257\n","[542]\tvalid_0's rmse: 0.883254\n","[543]\tvalid_0's rmse: 0.88323\n","[544]\tvalid_0's rmse: 0.883248\n","[545]\tvalid_0's rmse: 0.883214\n","[546]\tvalid_0's rmse: 0.883208\n","[547]\tvalid_0's rmse: 0.883224\n","[548]\tvalid_0's rmse: 0.883222\n","[549]\tvalid_0's rmse: 0.883228\n","[550]\tvalid_0's rmse: 0.883226\n","[551]\tvalid_0's rmse: 0.883201\n","[552]\tvalid_0's rmse: 0.883188\n","[553]\tvalid_0's rmse: 0.883191\n","[554]\tvalid_0's rmse: 0.883188\n","[555]\tvalid_0's rmse: 0.883174\n","[556]\tvalid_0's rmse: 0.883191\n","[557]\tvalid_0's rmse: 0.883193\n","[558]\tvalid_0's rmse: 0.883186\n","[559]\tvalid_0's rmse: 0.883194\n","[560]\tvalid_0's rmse: 0.883181\n","[561]\tvalid_0's rmse: 0.883208\n","[562]\tvalid_0's rmse: 0.883204\n","[563]\tvalid_0's rmse: 0.8832\n","[564]\tvalid_0's rmse: 0.883182\n","[565]\tvalid_0's rmse: 0.883168\n","[566]\tvalid_0's rmse: 0.883174\n","[567]\tvalid_0's rmse: 0.883153\n","[568]\tvalid_0's rmse: 0.883159\n","[569]\tvalid_0's rmse: 0.883077\n","[570]\tvalid_0's rmse: 0.883076\n","[571]\tvalid_0's rmse: 0.883078\n","[572]\tvalid_0's rmse: 0.883088\n","[573]\tvalid_0's rmse: 0.883081\n","[574]\tvalid_0's rmse: 0.883081\n","[575]\tvalid_0's rmse: 0.883068\n","[576]\tvalid_0's rmse: 0.883015\n","[577]\tvalid_0's rmse: 0.883021\n","[578]\tvalid_0's rmse: 0.882967\n","[579]\tvalid_0's rmse: 0.882956\n","[580]\tvalid_0's rmse: 0.882972\n","[581]\tvalid_0's rmse: 0.882905\n","[582]\tvalid_0's rmse: 0.882901\n","[583]\tvalid_0's rmse: 0.882899\n","[584]\tvalid_0's rmse: 0.882894\n","[585]\tvalid_0's rmse: 0.882926\n","[586]\tvalid_0's rmse: 0.882789\n","[587]\tvalid_0's rmse: 0.882788\n","[588]\tvalid_0's rmse: 0.882803\n","[589]\tvalid_0's rmse: 0.882796\n","[590]\tvalid_0's rmse: 0.88277\n","[591]\tvalid_0's rmse: 0.882767\n","[592]\tvalid_0's rmse: 0.882755\n","[593]\tvalid_0's rmse: 0.882779\n","[594]\tvalid_0's rmse: 0.882758\n","[595]\tvalid_0's rmse: 0.88277\n","[596]\tvalid_0's rmse: 0.882755\n","[597]\tvalid_0's rmse: 0.882756\n","[598]\tvalid_0's rmse: 0.88276\n","[599]\tvalid_0's rmse: 0.882736\n","[600]\tvalid_0's rmse: 0.882727\n","[601]\tvalid_0's rmse: 0.882717\n","[602]\tvalid_0's rmse: 0.88267\n","[603]\tvalid_0's rmse: 0.882664\n","[604]\tvalid_0's rmse: 0.882639\n","[605]\tvalid_0's rmse: 0.882635\n","[606]\tvalid_0's rmse: 0.882644\n","[607]\tvalid_0's rmse: 0.882648\n","[608]\tvalid_0's rmse: 0.882642\n","[609]\tvalid_0's rmse: 0.882633\n","[610]\tvalid_0's rmse: 0.882541\n","[611]\tvalid_0's rmse: 0.88253\n","[612]\tvalid_0's rmse: 0.882547\n","[613]\tvalid_0's rmse: 0.882537\n","[614]\tvalid_0's rmse: 0.882546\n","[615]\tvalid_0's rmse: 0.88253\n","[616]\tvalid_0's rmse: 0.882505\n","[617]\tvalid_0's rmse: 0.882536\n","[618]\tvalid_0's rmse: 0.882526\n","[619]\tvalid_0's rmse: 0.882525\n","[620]\tvalid_0's rmse: 0.882519\n","[621]\tvalid_0's rmse: 0.882579\n","[622]\tvalid_0's rmse: 0.882568\n","[623]\tvalid_0's rmse: 0.882533\n","[624]\tvalid_0's rmse: 0.882537\n","[625]\tvalid_0's rmse: 0.882514\n","[626]\tvalid_0's rmse: 0.882486\n","[627]\tvalid_0's rmse: 0.882466\n","[628]\tvalid_0's rmse: 0.882466\n","[629]\tvalid_0's rmse: 0.882473\n","[630]\tvalid_0's rmse: 0.882449\n","[631]\tvalid_0's rmse: 0.882454\n","[632]\tvalid_0's rmse: 0.882454\n","[633]\tvalid_0's rmse: 0.882472\n","[634]\tvalid_0's rmse: 0.882467\n","[635]\tvalid_0's rmse: 0.88243\n","[636]\tvalid_0's rmse: 0.882435\n","[637]\tvalid_0's rmse: 0.882431\n","[638]\tvalid_0's rmse: 0.882417\n","[639]\tvalid_0's rmse: 0.882407\n","[640]\tvalid_0's rmse: 0.882403\n","[641]\tvalid_0's rmse: 0.882408\n","[642]\tvalid_0's rmse: 0.88237\n","[643]\tvalid_0's rmse: 0.882355\n","[644]\tvalid_0's rmse: 0.882509\n","[645]\tvalid_0's rmse: 0.882503\n","[646]\tvalid_0's rmse: 0.882472\n","[647]\tvalid_0's rmse: 0.882475\n","[648]\tvalid_0's rmse: 0.882473\n","[649]\tvalid_0's rmse: 0.882466\n","[650]\tvalid_0's rmse: 0.88244\n","[651]\tvalid_0's rmse: 0.882424\n","[652]\tvalid_0's rmse: 0.882425\n","[653]\tvalid_0's rmse: 0.882425\n","[654]\tvalid_0's rmse: 0.88244\n","[655]\tvalid_0's rmse: 0.882413\n","[656]\tvalid_0's rmse: 0.882391\n","[657]\tvalid_0's rmse: 0.882406\n","[658]\tvalid_0's rmse: 0.882405\n","[659]\tvalid_0's rmse: 0.882394\n","[660]\tvalid_0's rmse: 0.882401\n","[661]\tvalid_0's rmse: 0.882401\n","[662]\tvalid_0's rmse: 0.882397\n","[663]\tvalid_0's rmse: 0.882235\n","[664]\tvalid_0's rmse: 0.882214\n","[665]\tvalid_0's rmse: 0.882431\n","[666]\tvalid_0's rmse: 0.882428\n","[667]\tvalid_0's rmse: 0.882447\n","[668]\tvalid_0's rmse: 0.882443\n","[669]\tvalid_0's rmse: 0.882443\n","[670]\tvalid_0's rmse: 0.882445\n","[671]\tvalid_0's rmse: 0.882473\n","[672]\tvalid_0's rmse: 0.882478\n","[673]\tvalid_0's rmse: 0.88246\n","[674]\tvalid_0's rmse: 0.882453\n","[675]\tvalid_0's rmse: 0.882423\n","[676]\tvalid_0's rmse: 0.882342\n","[677]\tvalid_0's rmse: 0.882337\n","[678]\tvalid_0's rmse: 0.882341\n","[679]\tvalid_0's rmse: 0.882328\n","[680]\tvalid_0's rmse: 0.882327\n","[681]\tvalid_0's rmse: 0.882321\n","[682]\tvalid_0's rmse: 0.882337\n","[683]\tvalid_0's rmse: 0.882352\n","[684]\tvalid_0's rmse: 0.882339\n","[685]\tvalid_0's rmse: 0.882346\n","[686]\tvalid_0's rmse: 0.882465\n","[687]\tvalid_0's rmse: 0.882443\n","[688]\tvalid_0's rmse: 0.882465\n","[689]\tvalid_0's rmse: 0.882463\n","[690]\tvalid_0's rmse: 0.882413\n","[691]\tvalid_0's rmse: 0.88241\n","[692]\tvalid_0's rmse: 0.882404\n","[693]\tvalid_0's rmse: 0.882372\n","[694]\tvalid_0's rmse: 0.882343\n","[695]\tvalid_0's rmse: 0.882348\n","[696]\tvalid_0's rmse: 0.882355\n","[697]\tvalid_0's rmse: 0.882314\n","[698]\tvalid_0's rmse: 0.882308\n","[699]\tvalid_0's rmse: 0.882308\n","[700]\tvalid_0's rmse: 0.88227\n","[701]\tvalid_0's rmse: 0.882265\n","[702]\tvalid_0's rmse: 0.882265\n","[703]\tvalid_0's rmse: 0.882272\n","[704]\tvalid_0's rmse: 0.882269\n","[705]\tvalid_0's rmse: 0.882264\n","[706]\tvalid_0's rmse: 0.882242\n","[707]\tvalid_0's rmse: 0.882227\n","[708]\tvalid_0's rmse: 0.882189\n","[709]\tvalid_0's rmse: 0.882171\n","[710]\tvalid_0's rmse: 0.882181\n","[711]\tvalid_0's rmse: 0.882173\n","[712]\tvalid_0's rmse: 0.882172\n","[713]\tvalid_0's rmse: 0.882167\n","[714]\tvalid_0's rmse: 0.882157\n","[715]\tvalid_0's rmse: 0.882167\n","[716]\tvalid_0's rmse: 0.881976\n","[717]\tvalid_0's rmse: 0.881974\n","[718]\tvalid_0's rmse: 0.88197\n","[719]\tvalid_0's rmse: 0.881918\n","[720]\tvalid_0's rmse: 0.881888\n","[721]\tvalid_0's rmse: 0.881882\n","[722]\tvalid_0's rmse: 0.88185\n","[723]\tvalid_0's rmse: 0.881849\n","[724]\tvalid_0's rmse: 0.881833\n","[725]\tvalid_0's rmse: 0.88185\n","[726]\tvalid_0's rmse: 0.881858\n","[727]\tvalid_0's rmse: 0.88187\n","[728]\tvalid_0's rmse: 0.881869\n","[729]\tvalid_0's rmse: 0.881851\n","[730]\tvalid_0's rmse: 0.881851\n","[731]\tvalid_0's rmse: 0.881831\n","[732]\tvalid_0's rmse: 0.881828\n","[733]\tvalid_0's rmse: 0.881802\n","[734]\tvalid_0's rmse: 0.88179\n","[735]\tvalid_0's rmse: 0.881795\n","[736]\tvalid_0's rmse: 0.881786\n","[737]\tvalid_0's rmse: 0.881778\n","[738]\tvalid_0's rmse: 0.881813\n","[739]\tvalid_0's rmse: 0.881821\n","[740]\tvalid_0's rmse: 0.881818\n","[741]\tvalid_0's rmse: 0.881816\n","[742]\tvalid_0's rmse: 0.881814\n","[743]\tvalid_0's rmse: 0.881804\n","[744]\tvalid_0's rmse: 0.881807\n","[745]\tvalid_0's rmse: 0.881806\n","[746]\tvalid_0's rmse: 0.881803\n","[747]\tvalid_0's rmse: 0.881839\n","[748]\tvalid_0's rmse: 0.881843\n","[749]\tvalid_0's rmse: 0.881775\n","[750]\tvalid_0's rmse: 0.881855\n","[751]\tvalid_0's rmse: 0.881862\n","[752]\tvalid_0's rmse: 0.881808\n","[753]\tvalid_0's rmse: 0.881809\n","[754]\tvalid_0's rmse: 0.881801\n","[755]\tvalid_0's rmse: 0.881802\n","[756]\tvalid_0's rmse: 0.881806\n","[757]\tvalid_0's rmse: 0.881818\n","[758]\tvalid_0's rmse: 0.881856\n","[759]\tvalid_0's rmse: 0.881851\n","[760]\tvalid_0's rmse: 0.881868\n","[761]\tvalid_0's rmse: 0.881793\n","[762]\tvalid_0's rmse: 0.8818\n","[763]\tvalid_0's rmse: 0.881823\n","[764]\tvalid_0's rmse: 0.881826\n","[765]\tvalid_0's rmse: 0.881837\n","[766]\tvalid_0's rmse: 0.881826\n","[767]\tvalid_0's rmse: 0.881826\n","[768]\tvalid_0's rmse: 0.881831\n","[769]\tvalid_0's rmse: 0.881826\n","[770]\tvalid_0's rmse: 0.881821\n","[771]\tvalid_0's rmse: 0.881824\n","[772]\tvalid_0's rmse: 0.881829\n","[773]\tvalid_0's rmse: 0.881828\n","[774]\tvalid_0's rmse: 0.881814\n","[775]\tvalid_0's rmse: 0.881813\n","[776]\tvalid_0's rmse: 0.881796\n","[777]\tvalid_0's rmse: 0.881793\n","[778]\tvalid_0's rmse: 0.881794\n","[779]\tvalid_0's rmse: 0.881788\n","[780]\tvalid_0's rmse: 0.881778\n","[781]\tvalid_0's rmse: 0.881761\n","[782]\tvalid_0's rmse: 0.881753\n","[783]\tvalid_0's rmse: 0.881776\n","[784]\tvalid_0's rmse: 0.881767\n","[785]\tvalid_0's rmse: 0.881757\n","[786]\tvalid_0's rmse: 0.881743\n","[787]\tvalid_0's rmse: 0.881745\n","[788]\tvalid_0's rmse: 0.881732\n","[789]\tvalid_0's rmse: 0.881733\n","[790]\tvalid_0's rmse: 0.881731\n","[791]\tvalid_0's rmse: 0.881729\n","[792]\tvalid_0's rmse: 0.881728\n","[793]\tvalid_0's rmse: 0.881745\n","[794]\tvalid_0's rmse: 0.88176\n","[795]\tvalid_0's rmse: 0.881763\n","[796]\tvalid_0's rmse: 0.881772\n","[797]\tvalid_0's rmse: 0.881763\n","[798]\tvalid_0's rmse: 0.881785\n","[799]\tvalid_0's rmse: 0.881763\n","[800]\tvalid_0's rmse: 0.881765\n","[801]\tvalid_0's rmse: 0.881748\n","[802]\tvalid_0's rmse: 0.88175\n","[803]\tvalid_0's rmse: 0.881732\n","[804]\tvalid_0's rmse: 0.881752\n","[805]\tvalid_0's rmse: 0.881735\n","[806]\tvalid_0's rmse: 0.881724\n","[807]\tvalid_0's rmse: 0.881716\n","[808]\tvalid_0's rmse: 0.881709\n","[809]\tvalid_0's rmse: 0.881697\n","[810]\tvalid_0's rmse: 0.881695\n","[811]\tvalid_0's rmse: 0.881692\n","[812]\tvalid_0's rmse: 0.881747\n","[813]\tvalid_0's rmse: 0.881745\n","[814]\tvalid_0's rmse: 0.881744\n","[815]\tvalid_0's rmse: 0.881693\n","[816]\tvalid_0's rmse: 0.8817\n","[817]\tvalid_0's rmse: 0.881633\n","[818]\tvalid_0's rmse: 0.881625\n","[819]\tvalid_0's rmse: 0.881602\n","[820]\tvalid_0's rmse: 0.881598\n","[821]\tvalid_0's rmse: 0.881583\n","[822]\tvalid_0's rmse: 0.881574\n","[823]\tvalid_0's rmse: 0.881583\n","[824]\tvalid_0's rmse: 0.88158\n","[825]\tvalid_0's rmse: 0.881732\n","[826]\tvalid_0's rmse: 0.881729\n","[827]\tvalid_0's rmse: 0.881696\n","[828]\tvalid_0's rmse: 0.881715\n","[829]\tvalid_0's rmse: 0.881711\n","[830]\tvalid_0's rmse: 0.881713\n","[831]\tvalid_0's rmse: 0.881709\n","[832]\tvalid_0's rmse: 0.881713\n","[833]\tvalid_0's rmse: 0.881715\n","[834]\tvalid_0's rmse: 0.881717\n","[835]\tvalid_0's rmse: 0.881716\n","[836]\tvalid_0's rmse: 0.88173\n","[837]\tvalid_0's rmse: 0.881723\n","[838]\tvalid_0's rmse: 0.881724\n","[839]\tvalid_0's rmse: 0.881712\n","[840]\tvalid_0's rmse: 0.88171\n","[841]\tvalid_0's rmse: 0.881707\n","[842]\tvalid_0's rmse: 0.881691\n","[843]\tvalid_0's rmse: 0.881705\n","[844]\tvalid_0's rmse: 0.881673\n","[845]\tvalid_0's rmse: 0.881664\n","[846]\tvalid_0's rmse: 0.881666\n","[847]\tvalid_0's rmse: 0.881672\n","[848]\tvalid_0's rmse: 0.881663\n","[849]\tvalid_0's rmse: 0.881662\n","[850]\tvalid_0's rmse: 0.881671\n","[851]\tvalid_0's rmse: 0.88168\n","[852]\tvalid_0's rmse: 0.881676\n","[853]\tvalid_0's rmse: 0.881676\n","[854]\tvalid_0's rmse: 0.881376\n","[855]\tvalid_0's rmse: 0.881366\n","[856]\tvalid_0's rmse: 0.881367\n","[857]\tvalid_0's rmse: 0.881373\n","[858]\tvalid_0's rmse: 0.881382\n","[859]\tvalid_0's rmse: 0.881352\n","[860]\tvalid_0's rmse: 0.881369\n","[861]\tvalid_0's rmse: 0.881373\n","[862]\tvalid_0's rmse: 0.881355\n","[863]\tvalid_0's rmse: 0.88135\n","[864]\tvalid_0's rmse: 0.881349\n","[865]\tvalid_0's rmse: 0.881352\n","[866]\tvalid_0's rmse: 0.881342\n","[867]\tvalid_0's rmse: 0.881341\n","[868]\tvalid_0's rmse: 0.88136\n","[869]\tvalid_0's rmse: 0.88136\n","[870]\tvalid_0's rmse: 0.881356\n","[871]\tvalid_0's rmse: 0.88139\n","[872]\tvalid_0's rmse: 0.88138\n","[873]\tvalid_0's rmse: 0.881356\n","[874]\tvalid_0's rmse: 0.881295\n","[875]\tvalid_0's rmse: 0.881299\n","[876]\tvalid_0's rmse: 0.881292\n","[877]\tvalid_0's rmse: 0.88131\n","[878]\tvalid_0's rmse: 0.881306\n","[879]\tvalid_0's rmse: 0.881322\n","[880]\tvalid_0's rmse: 0.881305\n","[881]\tvalid_0's rmse: 0.881308\n","[882]\tvalid_0's rmse: 0.881323\n","[883]\tvalid_0's rmse: 0.881316\n","[884]\tvalid_0's rmse: 0.881425\n","[885]\tvalid_0's rmse: 0.881422\n","[886]\tvalid_0's rmse: 0.881417\n","[887]\tvalid_0's rmse: 0.881415\n","[888]\tvalid_0's rmse: 0.881414\n","[889]\tvalid_0's rmse: 0.881417\n","[890]\tvalid_0's rmse: 0.881404\n","[891]\tvalid_0's rmse: 0.881408\n","[892]\tvalid_0's rmse: 0.881408\n","[893]\tvalid_0's rmse: 0.881411\n","[894]\tvalid_0's rmse: 0.881414\n","[895]\tvalid_0's rmse: 0.881383\n","[896]\tvalid_0's rmse: 0.881374\n","[897]\tvalid_0's rmse: 0.881367\n","[898]\tvalid_0's rmse: 0.881352\n","[899]\tvalid_0's rmse: 0.881343\n","[900]\tvalid_0's rmse: 0.881375\n","[901]\tvalid_0's rmse: 0.881374\n","[902]\tvalid_0's rmse: 0.881383\n","[903]\tvalid_0's rmse: 0.88139\n","[904]\tvalid_0's rmse: 0.881393\n","[905]\tvalid_0's rmse: 0.881408\n","[906]\tvalid_0's rmse: 0.881415\n","[907]\tvalid_0's rmse: 0.881406\n","[908]\tvalid_0's rmse: 0.881404\n","[909]\tvalid_0's rmse: 0.881401\n","[910]\tvalid_0's rmse: 0.881409\n","[911]\tvalid_0's rmse: 0.881406\n","[912]\tvalid_0's rmse: 0.881384\n","[913]\tvalid_0's rmse: 0.88138\n","[914]\tvalid_0's rmse: 0.881379\n","[915]\tvalid_0's rmse: 0.881362\n","[916]\tvalid_0's rmse: 0.881362\n","[917]\tvalid_0's rmse: 0.881359\n","[918]\tvalid_0's rmse: 0.88135\n","[919]\tvalid_0's rmse: 0.88135\n","[920]\tvalid_0's rmse: 0.881364\n","[921]\tvalid_0's rmse: 0.881364\n","[922]\tvalid_0's rmse: 0.881371\n","[923]\tvalid_0's rmse: 0.881373\n","[924]\tvalid_0's rmse: 0.881371\n","[925]\tvalid_0's rmse: 0.881358\n","[926]\tvalid_0's rmse: 0.881356\n","Early stopping, best iteration is:\n","[876]\tvalid_0's rmse: 0.881292\n","R^2 train =  0.5403    R^2 val =  0.3809\n","RMSE train = 0.8394    RMSE val = 0.8813\n","\n","size of X_train_np = 1042.5 MB\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["[1]\tvalid_0's rmse: 1.1296\n","Training until validation scores don't improve for 50 rounds.\n","[2]\tvalid_0's rmse: 1.11436\n","[3]\tvalid_0's rmse: 1.10026\n","[4]\tvalid_0's rmse: 1.08717\n","[5]\tvalid_0's rmse: 1.07537\n","[6]\tvalid_0's rmse: 1.06458\n","[7]\tvalid_0's rmse: 1.05471\n","[8]\tvalid_0's rmse: 1.04768\n","[9]\tvalid_0's rmse: 1.03929\n","[10]\tvalid_0's rmse: 1.03165\n","[11]\tvalid_0's rmse: 1.02412\n","[12]\tvalid_0's rmse: 1.01764\n","[13]\tvalid_0's rmse: 1.01264\n","[14]\tvalid_0's rmse: 1.00709\n","[15]\tvalid_0's rmse: 1.00204\n","[16]\tvalid_0's rmse: 0.997731\n","[17]\tvalid_0's rmse: 0.994323\n","[18]\tvalid_0's rmse: 0.99058\n","[19]\tvalid_0's rmse: 0.986987\n","[20]\tvalid_0's rmse: 0.983375\n","[21]\tvalid_0's rmse: 0.981039\n","[22]\tvalid_0's rmse: 0.978278\n","[23]\tvalid_0's rmse: 0.975725\n","[24]\tvalid_0's rmse: 0.973154\n","[25]\tvalid_0's rmse: 0.971067\n","[26]\tvalid_0's rmse: 0.969274\n","[27]\tvalid_0's rmse: 0.967498\n","[28]\tvalid_0's rmse: 0.965667\n","[29]\tvalid_0's rmse: 0.964263\n","[30]\tvalid_0's rmse: 0.963065\n","[31]\tvalid_0's rmse: 0.961823\n","[32]\tvalid_0's rmse: 0.960597\n","[33]\tvalid_0's rmse: 0.959365\n","[34]\tvalid_0's rmse: 0.958225\n","[35]\tvalid_0's rmse: 0.957426\n","[36]\tvalid_0's rmse: 0.956643\n","[37]\tvalid_0's rmse: 0.955888\n","[38]\tvalid_0's rmse: 0.955206\n","[39]\tvalid_0's rmse: 0.95447\n","[40]\tvalid_0's rmse: 0.953054\n","[41]\tvalid_0's rmse: 0.952491\n","[42]\tvalid_0's rmse: 0.951305\n","[43]\tvalid_0's rmse: 0.950857\n","[44]\tvalid_0's rmse: 0.950459\n","[45]\tvalid_0's rmse: 0.949982\n","[46]\tvalid_0's rmse: 0.949231\n","[47]\tvalid_0's rmse: 0.948887\n","[48]\tvalid_0's rmse: 0.948582\n","[49]\tvalid_0's rmse: 0.948161\n","[50]\tvalid_0's rmse: 0.947911\n","[51]\tvalid_0's rmse: 0.947625\n","[52]\tvalid_0's rmse: 0.947327\n","[53]\tvalid_0's rmse: 0.947016\n","[54]\tvalid_0's rmse: 0.946771\n","[55]\tvalid_0's rmse: 0.94643\n","[56]\tvalid_0's rmse: 0.946213\n","[57]\tvalid_0's rmse: 0.945542\n","[58]\tvalid_0's rmse: 0.945375\n","[59]\tvalid_0's rmse: 0.945221\n","[60]\tvalid_0's rmse: 0.945056\n","[61]\tvalid_0's rmse: 0.944859\n","[62]\tvalid_0's rmse: 0.944666\n","[63]\tvalid_0's rmse: 0.944457\n","[64]\tvalid_0's rmse: 0.944337\n","[65]\tvalid_0's rmse: 0.944069\n","[66]\tvalid_0's rmse: 0.943568\n","[67]\tvalid_0's rmse: 0.943413\n","[68]\tvalid_0's rmse: 0.943316\n","[69]\tvalid_0's rmse: 0.943166\n","[70]\tvalid_0's rmse: 0.942991\n","[71]\tvalid_0's rmse: 0.942644\n","[72]\tvalid_0's rmse: 0.942408\n","[73]\tvalid_0's rmse: 0.942314\n","[74]\tvalid_0's rmse: 0.942141\n","[75]\tvalid_0's rmse: 0.94184\n","[76]\tvalid_0's rmse: 0.941604\n","[77]\tvalid_0's rmse: 0.941578\n","[78]\tvalid_0's rmse: 0.941542\n","[79]\tvalid_0's rmse: 0.941409\n","[80]\tvalid_0's rmse: 0.941127\n","[81]\tvalid_0's rmse: 0.940974\n","[82]\tvalid_0's rmse: 0.940907\n","[83]\tvalid_0's rmse: 0.940859\n","[84]\tvalid_0's rmse: 0.940837\n","[85]\tvalid_0's rmse: 0.940797\n","[86]\tvalid_0's rmse: 0.940714\n","[87]\tvalid_0's rmse: 0.940532\n","[88]\tvalid_0's rmse: 0.940414\n","[89]\tvalid_0's rmse: 0.939735\n","[90]\tvalid_0's rmse: 0.939726\n","[91]\tvalid_0's rmse: 0.939571\n","[92]\tvalid_0's rmse: 0.939574\n","[93]\tvalid_0's rmse: 0.939457\n","[94]\tvalid_0's rmse: 0.938748\n","[95]\tvalid_0's rmse: 0.938629\n","[96]\tvalid_0's rmse: 0.938448\n","[97]\tvalid_0's rmse: 0.938271\n","[98]\tvalid_0's rmse: 0.938272\n","[99]\tvalid_0's rmse: 0.938318\n","[100]\tvalid_0's rmse: 0.938315\n","[101]\tvalid_0's rmse: 0.938127\n","[102]\tvalid_0's rmse: 0.938098\n","[103]\tvalid_0's rmse: 0.937503\n","[104]\tvalid_0's rmse: 0.937267\n","[105]\tvalid_0's rmse: 0.937191\n","[106]\tvalid_0's rmse: 0.937074\n","[107]\tvalid_0's rmse: 0.936499\n","[108]\tvalid_0's rmse: 0.936441\n","[109]\tvalid_0's rmse: 0.936443\n","[110]\tvalid_0's rmse: 0.936306\n","[111]\tvalid_0's rmse: 0.9362\n","[112]\tvalid_0's rmse: 0.93617\n","[113]\tvalid_0's rmse: 0.936045\n","[114]\tvalid_0's rmse: 0.935405\n","[115]\tvalid_0's rmse: 0.935396\n","[116]\tvalid_0's rmse: 0.935415\n","[117]\tvalid_0's rmse: 0.935415\n","[118]\tvalid_0's rmse: 0.935337\n","[119]\tvalid_0's rmse: 0.935351\n","[120]\tvalid_0's rmse: 0.935348\n","[121]\tvalid_0's rmse: 0.935331\n","[122]\tvalid_0's rmse: 0.935331\n","[123]\tvalid_0's rmse: 0.93533\n","[124]\tvalid_0's rmse: 0.935255\n","[125]\tvalid_0's rmse: 0.935127\n","[126]\tvalid_0's rmse: 0.935027\n","[127]\tvalid_0's rmse: 0.935033\n","[128]\tvalid_0's rmse: 0.935033\n","[129]\tvalid_0's rmse: 0.934877\n","[130]\tvalid_0's rmse: 0.934906\n","[131]\tvalid_0's rmse: 0.934856\n","[132]\tvalid_0's rmse: 0.934876\n","[133]\tvalid_0's rmse: 0.934761\n","[134]\tvalid_0's rmse: 0.934762\n","[135]\tvalid_0's rmse: 0.934496\n","[136]\tvalid_0's rmse: 0.934522\n","[137]\tvalid_0's rmse: 0.934712\n","[138]\tvalid_0's rmse: 0.934289\n","[139]\tvalid_0's rmse: 0.934288\n","[140]\tvalid_0's rmse: 0.934289\n","[141]\tvalid_0's rmse: 0.934189\n","[142]\tvalid_0's rmse: 0.934188\n","[143]\tvalid_0's rmse: 0.93418\n","[144]\tvalid_0's rmse: 0.934187\n","[145]\tvalid_0's rmse: 0.934117\n","[146]\tvalid_0's rmse: 0.934112\n","[147]\tvalid_0's rmse: 0.934014\n","[148]\tvalid_0's rmse: 0.93395\n","[149]\tvalid_0's rmse: 0.933856\n","[150]\tvalid_0's rmse: 0.93384\n","[151]\tvalid_0's rmse: 0.933748\n","[152]\tvalid_0's rmse: 0.933732\n","[153]\tvalid_0's rmse: 0.933722\n","[154]\tvalid_0's rmse: 0.933725\n","[155]\tvalid_0's rmse: 0.933632\n","[156]\tvalid_0's rmse: 0.933635\n","[157]\tvalid_0's rmse: 0.933615\n","[158]\tvalid_0's rmse: 0.933534\n","[159]\tvalid_0's rmse: 0.933544\n","[160]\tvalid_0's rmse: 0.933555\n","[161]\tvalid_0's rmse: 0.933607\n","[162]\tvalid_0's rmse: 0.933605\n","[163]\tvalid_0's rmse: 0.933516\n","[164]\tvalid_0's rmse: 0.933425\n","[165]\tvalid_0's rmse: 0.933425\n","[166]\tvalid_0's rmse: 0.9334\n","[167]\tvalid_0's rmse: 0.933399\n","[168]\tvalid_0's rmse: 0.933373\n","[169]\tvalid_0's rmse: 0.933371\n","[170]\tvalid_0's rmse: 0.933251\n","[171]\tvalid_0's rmse: 0.933262\n","[172]\tvalid_0's rmse: 0.933262\n","[173]\tvalid_0's rmse: 0.933263\n","[174]\tvalid_0's rmse: 0.933247\n","[175]\tvalid_0's rmse: 0.93321\n","[176]\tvalid_0's rmse: 0.933191\n","[177]\tvalid_0's rmse: 0.933161\n","[178]\tvalid_0's rmse: 0.933151\n","[179]\tvalid_0's rmse: 0.933177\n","[180]\tvalid_0's rmse: 0.933161\n","[181]\tvalid_0's rmse: 0.93316\n","[182]\tvalid_0's rmse: 0.933119\n","[183]\tvalid_0's rmse: 0.932558\n","[184]\tvalid_0's rmse: 0.932559\n","[185]\tvalid_0's rmse: 0.93256\n","[186]\tvalid_0's rmse: 0.932525\n","[187]\tvalid_0's rmse: 0.932513\n","[188]\tvalid_0's rmse: 0.93257\n","[189]\tvalid_0's rmse: 0.932579\n","[190]\tvalid_0's rmse: 0.932583\n","[191]\tvalid_0's rmse: 0.932557\n","[192]\tvalid_0's rmse: 0.932585\n","[193]\tvalid_0's rmse: 0.932387\n","[194]\tvalid_0's rmse: 0.932513\n","[195]\tvalid_0's rmse: 0.932496\n","[196]\tvalid_0's rmse: 0.932484\n","[197]\tvalid_0's rmse: 0.932489\n","[198]\tvalid_0's rmse: 0.932473\n","[199]\tvalid_0's rmse: 0.932511\n","[200]\tvalid_0's rmse: 0.932511\n","[201]\tvalid_0's rmse: 0.932547\n","[202]\tvalid_0's rmse: 0.932455\n","[203]\tvalid_0's rmse: 0.932519\n","[204]\tvalid_0's rmse: 0.932511\n","[205]\tvalid_0's rmse: 0.93251\n","[206]\tvalid_0's rmse: 0.932497\n","[207]\tvalid_0's rmse: 0.932459\n","[208]\tvalid_0's rmse: 0.932453\n","[209]\tvalid_0's rmse: 0.932437\n","[210]\tvalid_0's rmse: 0.932449\n","[211]\tvalid_0's rmse: 0.932528\n","[212]\tvalid_0's rmse: 0.932529\n","[213]\tvalid_0's rmse: 0.932611\n","[214]\tvalid_0's rmse: 0.932582\n","[215]\tvalid_0's rmse: 0.932547\n","[216]\tvalid_0's rmse: 0.932599\n","[217]\tvalid_0's rmse: 0.932558\n","[218]\tvalid_0's rmse: 0.932532\n","[219]\tvalid_0's rmse: 0.932192\n","[220]\tvalid_0's rmse: 0.932187\n","[221]\tvalid_0's rmse: 0.932175\n","[222]\tvalid_0's rmse: 0.932163\n","[223]\tvalid_0's rmse: 0.932196\n","[224]\tvalid_0's rmse: 0.932147\n","[225]\tvalid_0's rmse: 0.932151\n","[226]\tvalid_0's rmse: 0.932193\n","[227]\tvalid_0's rmse: 0.932267\n","[228]\tvalid_0's rmse: 0.93225\n","[229]\tvalid_0's rmse: 0.932253\n","[230]\tvalid_0's rmse: 0.930625\n","[231]\tvalid_0's rmse: 0.930625\n","[232]\tvalid_0's rmse: 0.930621\n","[233]\tvalid_0's rmse: 0.930519\n","[234]\tvalid_0's rmse: 0.93051\n","[235]\tvalid_0's rmse: 0.93051\n","[236]\tvalid_0's rmse: 0.930427\n","[237]\tvalid_0's rmse: 0.93033\n","[238]\tvalid_0's rmse: 0.930313\n","[239]\tvalid_0's rmse: 0.930321\n","[240]\tvalid_0's rmse: 0.930395\n","[241]\tvalid_0's rmse: 0.930399\n","[242]\tvalid_0's rmse: 0.930493\n","[243]\tvalid_0's rmse: 0.930457\n","[244]\tvalid_0's rmse: 0.930721\n","[245]\tvalid_0's rmse: 0.930715\n","[246]\tvalid_0's rmse: 0.930715\n","[247]\tvalid_0's rmse: 0.930698\n","[248]\tvalid_0's rmse: 0.930685\n","[249]\tvalid_0's rmse: 0.930661\n","[250]\tvalid_0's rmse: 0.9306\n","[251]\tvalid_0's rmse: 0.930472\n","[252]\tvalid_0's rmse: 0.930515\n","[253]\tvalid_0's rmse: 0.930504\n","[254]\tvalid_0's rmse: 0.930463\n","[255]\tvalid_0's rmse: 0.930491\n","[256]\tvalid_0's rmse: 0.93046\n","[257]\tvalid_0's rmse: 0.930453\n","[258]\tvalid_0's rmse: 0.930388\n","[259]\tvalid_0's rmse: 0.930417\n","[260]\tvalid_0's rmse: 0.930394\n","[261]\tvalid_0's rmse: 0.930392\n","[262]\tvalid_0's rmse: 0.930361\n","[263]\tvalid_0's rmse: 0.930359\n","[264]\tvalid_0's rmse: 0.930399\n","[265]\tvalid_0's rmse: 0.930399\n","[266]\tvalid_0's rmse: 0.930399\n","[267]\tvalid_0's rmse: 0.930455\n","[268]\tvalid_0's rmse: 0.930636\n","[269]\tvalid_0's rmse: 0.930634\n","[270]\tvalid_0's rmse: 0.930628\n","[271]\tvalid_0's rmse: 0.930611\n","[272]\tvalid_0's rmse: 0.930599\n","[273]\tvalid_0's rmse: 0.930581\n","[274]\tvalid_0's rmse: 0.930662\n","[275]\tvalid_0's rmse: 0.930675\n","[276]\tvalid_0's rmse: 0.930571\n","[277]\tvalid_0's rmse: 0.930555\n","[278]\tvalid_0's rmse: 0.930586\n","[279]\tvalid_0's rmse: 0.930583\n","[280]\tvalid_0's rmse: 0.930618\n","[281]\tvalid_0's rmse: 0.930609\n","[282]\tvalid_0's rmse: 0.930629\n","[283]\tvalid_0's rmse: 0.930641\n","[284]\tvalid_0's rmse: 0.930647\n","[285]\tvalid_0's rmse: 0.93064\n","[286]\tvalid_0's rmse: 0.93064\n","[287]\tvalid_0's rmse: 0.93065\n","[288]\tvalid_0's rmse: 0.930376\n","Early stopping, best iteration is:\n","[238]\tvalid_0's rmse: 0.930313\n","R^2 train =  0.4824    R^2 val =  0.3409\n","RMSE train = 0.8872    RMSE val = 0.9303\n","\n","size of X_train_np = 1073.1 MB\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n","  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"],"name":"stderr"},{"output_type":"stream","text":["[1]\tvalid_0's rmse: 1.12289\n","Training until validation scores don't improve for 50 rounds.\n","[2]\tvalid_0's rmse: 1.10876\n","[3]\tvalid_0's rmse: 1.09559\n","[4]\tvalid_0's rmse: 1.08371\n","[5]\tvalid_0's rmse: 1.07277\n","[6]\tvalid_0's rmse: 1.06289\n","[7]\tvalid_0's rmse: 1.05373\n","[8]\tvalid_0's rmse: 1.04693\n","[9]\tvalid_0's rmse: 1.03922\n","[10]\tvalid_0's rmse: 1.03235\n","[11]\tvalid_0's rmse: 1.02542\n","[12]\tvalid_0's rmse: 1.01982\n","[13]\tvalid_0's rmse: 1.01502\n","[14]\tvalid_0's rmse: 1.01027\n","[15]\tvalid_0's rmse: 1.00569\n","[16]\tvalid_0's rmse: 1.00163\n","[17]\tvalid_0's rmse: 0.998501\n","[18]\tvalid_0's rmse: 0.99529\n","[19]\tvalid_0's rmse: 0.991854\n","[20]\tvalid_0's rmse: 0.989063\n","[21]\tvalid_0's rmse: 0.986928\n","[22]\tvalid_0's rmse: 0.984567\n","[23]\tvalid_0's rmse: 0.982342\n","[24]\tvalid_0's rmse: 0.980371\n","[25]\tvalid_0's rmse: 0.978658\n","[26]\tvalid_0's rmse: 0.976935\n","[27]\tvalid_0's rmse: 0.975557\n","[28]\tvalid_0's rmse: 0.974137\n","[29]\tvalid_0's rmse: 0.972756\n","[30]\tvalid_0's rmse: 0.971484\n","[31]\tvalid_0's rmse: 0.970455\n","[32]\tvalid_0's rmse: 0.969673\n","[33]\tvalid_0's rmse: 0.96863\n","[34]\tvalid_0's rmse: 0.967797\n","[35]\tvalid_0's rmse: 0.967165\n","[36]\tvalid_0's rmse: 0.966383\n","[37]\tvalid_0's rmse: 0.965595\n","[38]\tvalid_0's rmse: 0.965059\n","[39]\tvalid_0's rmse: 0.964497\n","[40]\tvalid_0's rmse: 0.963951\n","[41]\tvalid_0's rmse: 0.962048\n","[42]\tvalid_0's rmse: 0.961476\n","[43]\tvalid_0's rmse: 0.960911\n","[44]\tvalid_0's rmse: 0.960573\n","[45]\tvalid_0's rmse: 0.960233\n","[46]\tvalid_0's rmse: 0.95989\n","[47]\tvalid_0's rmse: 0.959606\n","[48]\tvalid_0's rmse: 0.959332\n","[49]\tvalid_0's rmse: 0.958997\n","[50]\tvalid_0's rmse: 0.958494\n","[51]\tvalid_0's rmse: 0.958292\n","[52]\tvalid_0's rmse: 0.958112\n","[53]\tvalid_0's rmse: 0.957997\n","[54]\tvalid_0's rmse: 0.957687\n","[55]\tvalid_0's rmse: 0.957361\n","[56]\tvalid_0's rmse: 0.957175\n","[57]\tvalid_0's rmse: 0.957038\n","[58]\tvalid_0's rmse: 0.956884\n","[59]\tvalid_0's rmse: 0.956751\n","[60]\tvalid_0's rmse: 0.956608\n","[61]\tvalid_0's rmse: 0.956481\n","[62]\tvalid_0's rmse: 0.956351\n","[63]\tvalid_0's rmse: 0.956289\n","[64]\tvalid_0's rmse: 0.956221\n","[65]\tvalid_0's rmse: 0.956089\n","[66]\tvalid_0's rmse: 0.955909\n","[67]\tvalid_0's rmse: 0.955753\n","[68]\tvalid_0's rmse: 0.955657\n","[69]\tvalid_0's rmse: 0.955446\n","[70]\tvalid_0's rmse: 0.954883\n","[71]\tvalid_0's rmse: 0.954668\n","[72]\tvalid_0's rmse: 0.954592\n","[73]\tvalid_0's rmse: 0.9546\n","[74]\tvalid_0's rmse: 0.954537\n","[75]\tvalid_0's rmse: 0.953794\n","[76]\tvalid_0's rmse: 0.953779\n","[77]\tvalid_0's rmse: 0.953555\n","[78]\tvalid_0's rmse: 0.953469\n","[79]\tvalid_0's rmse: 0.95335\n","[80]\tvalid_0's rmse: 0.953224\n","[81]\tvalid_0's rmse: 0.953165\n","[82]\tvalid_0's rmse: 0.952913\n","[83]\tvalid_0's rmse: 0.95318\n","[84]\tvalid_0's rmse: 0.95315\n","[85]\tvalid_0's rmse: 0.952436\n","[86]\tvalid_0's rmse: 0.952286\n","[87]\tvalid_0's rmse: 0.952246\n","[88]\tvalid_0's rmse: 0.952195\n","[89]\tvalid_0's rmse: 0.952106\n","[90]\tvalid_0's rmse: 0.952052\n","[91]\tvalid_0's rmse: 0.952022\n","[92]\tvalid_0's rmse: 0.951994\n","[93]\tvalid_0's rmse: 0.95166\n","[94]\tvalid_0's rmse: 0.951518\n","[95]\tvalid_0's rmse: 0.950848\n","[96]\tvalid_0's rmse: 0.95068\n","[97]\tvalid_0's rmse: 0.950677\n","[98]\tvalid_0's rmse: 0.950679\n","[99]\tvalid_0's rmse: 0.950632\n","[100]\tvalid_0's rmse: 0.950444\n","[101]\tvalid_0's rmse: 0.950237\n","[102]\tvalid_0's rmse: 0.950157\n","[103]\tvalid_0's rmse: 0.950145\n","[104]\tvalid_0's rmse: 0.950082\n","[105]\tvalid_0's rmse: 0.94998\n","[106]\tvalid_0's rmse: 0.948889\n","[107]\tvalid_0's rmse: 0.948881\n","[108]\tvalid_0's rmse: 0.94868\n","[109]\tvalid_0's rmse: 0.948652\n","[110]\tvalid_0's rmse: 0.948659\n","[111]\tvalid_0's rmse: 0.9485\n","[112]\tvalid_0's rmse: 0.948374\n","[113]\tvalid_0's rmse: 0.948346\n","[114]\tvalid_0's rmse: 0.948315\n","[115]\tvalid_0's rmse: 0.948318\n","[116]\tvalid_0's rmse: 0.947492\n","[117]\tvalid_0's rmse: 0.947446\n","[118]\tvalid_0's rmse: 0.947448\n","[119]\tvalid_0's rmse: 0.947419\n","[120]\tvalid_0's rmse: 0.947283\n","[121]\tvalid_0's rmse: 0.947224\n","[122]\tvalid_0's rmse: 0.947174\n","[123]\tvalid_0's rmse: 0.947023\n","[124]\tvalid_0's rmse: 0.946952\n","[125]\tvalid_0's rmse: 0.946896\n","[126]\tvalid_0's rmse: 0.946873\n","[127]\tvalid_0's rmse: 0.946901\n","[128]\tvalid_0's rmse: 0.946863\n","[129]\tvalid_0's rmse: 0.946784\n","[130]\tvalid_0's rmse: 0.946783\n","[131]\tvalid_0's rmse: 0.946782\n","[132]\tvalid_0's rmse: 0.94665\n","[133]\tvalid_0's rmse: 0.946056\n","[134]\tvalid_0's rmse: 0.946019\n","[135]\tvalid_0's rmse: 0.945996\n","[136]\tvalid_0's rmse: 0.945944\n","[137]\tvalid_0's rmse: 0.945881\n","[138]\tvalid_0's rmse: 0.94587\n","[139]\tvalid_0's rmse: 0.945863\n","[140]\tvalid_0's rmse: 0.945862\n","[141]\tvalid_0's rmse: 0.945866\n","[142]\tvalid_0's rmse: 0.945865\n","[143]\tvalid_0's rmse: 0.945945\n","[144]\tvalid_0's rmse: 0.945896\n","[145]\tvalid_0's rmse: 0.945802\n","[146]\tvalid_0's rmse: 0.945598\n","[147]\tvalid_0's rmse: 0.945366\n","[148]\tvalid_0's rmse: 0.945383\n","[149]\tvalid_0's rmse: 0.945467\n","[150]\tvalid_0's rmse: 0.945459\n","[151]\tvalid_0's rmse: 0.945458\n","[152]\tvalid_0's rmse: 0.945326\n","[153]\tvalid_0's rmse: 0.945305\n","[154]\tvalid_0's rmse: 0.945306\n","[155]\tvalid_0's rmse: 0.945459\n","[156]\tvalid_0's rmse: 0.945459\n","[157]\tvalid_0's rmse: 0.945236\n","[158]\tvalid_0's rmse: 0.945238\n","[159]\tvalid_0's rmse: 0.94531\n","[160]\tvalid_0's rmse: 0.945305\n","[161]\tvalid_0's rmse: 0.943627\n","[162]\tvalid_0's rmse: 0.943708\n","[163]\tvalid_0's rmse: 0.943726\n","[164]\tvalid_0's rmse: 0.943705\n","[165]\tvalid_0's rmse: 0.943686\n","[166]\tvalid_0's rmse: 0.943966\n","[167]\tvalid_0's rmse: 0.943952\n","[168]\tvalid_0's rmse: 0.943716\n","[169]\tvalid_0's rmse: 0.943664\n","[170]\tvalid_0's rmse: 0.943668\n","[171]\tvalid_0's rmse: 0.943563\n","[172]\tvalid_0's rmse: 0.943585\n","[173]\tvalid_0's rmse: 0.943565\n","[174]\tvalid_0's rmse: 0.941835\n","[175]\tvalid_0's rmse: 0.941831\n","[176]\tvalid_0's rmse: 0.941801\n","[177]\tvalid_0's rmse: 0.941799\n","[178]\tvalid_0's rmse: 0.941788\n","[179]\tvalid_0's rmse: 0.941897\n","[180]\tvalid_0's rmse: 0.941902\n","[181]\tvalid_0's rmse: 0.941804\n","[182]\tvalid_0's rmse: 0.941784\n","[183]\tvalid_0's rmse: 0.94177\n","[184]\tvalid_0's rmse: 0.941788\n","[185]\tvalid_0's rmse: 0.941588\n","[186]\tvalid_0's rmse: 0.941522\n","[187]\tvalid_0's rmse: 0.941453\n","[188]\tvalid_0's rmse: 0.941388\n","[189]\tvalid_0's rmse: 0.941323\n","[190]\tvalid_0's rmse: 0.941316\n","[191]\tvalid_0's rmse: 0.941296\n","[192]\tvalid_0's rmse: 0.941507\n","[193]\tvalid_0's rmse: 0.941443\n","[194]\tvalid_0's rmse: 0.941443\n","[195]\tvalid_0's rmse: 0.941422\n","[196]\tvalid_0's rmse: 0.941415\n","[197]\tvalid_0's rmse: 0.941406\n","[198]\tvalid_0's rmse: 0.9414\n","[199]\tvalid_0's rmse: 0.940514\n","[200]\tvalid_0's rmse: 0.940732\n","[201]\tvalid_0's rmse: 0.940813\n","[202]\tvalid_0's rmse: 0.940767\n","[203]\tvalid_0's rmse: 0.940873\n","[204]\tvalid_0's rmse: 0.940866\n","[205]\tvalid_0's rmse: 0.940844\n","[206]\tvalid_0's rmse: 0.940835\n","[207]\tvalid_0's rmse: 0.940877\n","[208]\tvalid_0's rmse: 0.940879\n","[209]\tvalid_0's rmse: 0.940766\n","[210]\tvalid_0's rmse: 0.940684\n","[211]\tvalid_0's rmse: 0.94069\n","[212]\tvalid_0's rmse: 0.94068\n","[213]\tvalid_0's rmse: 0.940696\n","[214]\tvalid_0's rmse: 0.940662\n","[215]\tvalid_0's rmse: 0.940798\n","[216]\tvalid_0's rmse: 0.940799\n","[217]\tvalid_0's rmse: 0.940791\n","[218]\tvalid_0's rmse: 0.94075\n","[219]\tvalid_0's rmse: 0.940697\n","[220]\tvalid_0's rmse: 0.940697\n","[221]\tvalid_0's rmse: 0.940615\n","[222]\tvalid_0's rmse: 0.940629\n","[223]\tvalid_0's rmse: 0.940601\n","[224]\tvalid_0's rmse: 0.940579\n","[225]\tvalid_0's rmse: 0.940499\n","[226]\tvalid_0's rmse: 0.940486\n","[227]\tvalid_0's rmse: 0.940435\n","[228]\tvalid_0's rmse: 0.940433\n","[229]\tvalid_0's rmse: 0.940528\n","[230]\tvalid_0's rmse: 0.940514\n","[231]\tvalid_0's rmse: 0.940455\n","[232]\tvalid_0's rmse: 0.940614\n","[233]\tvalid_0's rmse: 0.939752\n","[234]\tvalid_0's rmse: 0.939765\n","[235]\tvalid_0's rmse: 0.939745\n","[236]\tvalid_0's rmse: 0.939731\n","[237]\tvalid_0's rmse: 0.939711\n","[238]\tvalid_0's rmse: 0.939725\n","[239]\tvalid_0's rmse: 0.939733\n","[240]\tvalid_0's rmse: 0.939655\n","[241]\tvalid_0's rmse: 0.939689\n","[242]\tvalid_0's rmse: 0.939901\n","[243]\tvalid_0's rmse: 0.939978\n","[244]\tvalid_0's rmse: 0.939918\n","[245]\tvalid_0's rmse: 0.939912\n","[246]\tvalid_0's rmse: 0.93989\n","[247]\tvalid_0's rmse: 0.939817\n","[248]\tvalid_0's rmse: 0.939811\n","[249]\tvalid_0's rmse: 0.940036\n","[250]\tvalid_0's rmse: 0.94007\n","[251]\tvalid_0's rmse: 0.940031\n","[252]\tvalid_0's rmse: 0.940041\n","[253]\tvalid_0's rmse: 0.940016\n","[254]\tvalid_0's rmse: 0.939917\n","[255]\tvalid_0's rmse: 0.939893\n","[256]\tvalid_0's rmse: 0.93983\n","[257]\tvalid_0's rmse: 0.939782\n","[258]\tvalid_0's rmse: 0.939702\n","[259]\tvalid_0's rmse: 0.939714\n","[260]\tvalid_0's rmse: 0.939697\n","[261]\tvalid_0's rmse: 0.939685\n","[262]\tvalid_0's rmse: 0.939644\n","[263]\tvalid_0's rmse: 0.939596\n","[264]\tvalid_0's rmse: 0.939611\n","[265]\tvalid_0's rmse: 0.939599\n","[266]\tvalid_0's rmse: 0.939585\n","[267]\tvalid_0's rmse: 0.939849\n","[268]\tvalid_0's rmse: 0.939925\n","[269]\tvalid_0's rmse: 0.93992\n","[270]\tvalid_0's rmse: 0.93981\n","[271]\tvalid_0's rmse: 0.939789\n","[272]\tvalid_0's rmse: 0.939795\n","[273]\tvalid_0's rmse: 0.939796\n","[274]\tvalid_0's rmse: 0.939776\n","[275]\tvalid_0's rmse: 0.939816\n","[276]\tvalid_0's rmse: 0.939788\n","[277]\tvalid_0's rmse: 0.939787\n","[278]\tvalid_0's rmse: 0.939772\n","[279]\tvalid_0's rmse: 0.939772\n","[280]\tvalid_0's rmse: 0.93988\n","[281]\tvalid_0's rmse: 0.939864\n","[282]\tvalid_0's rmse: 0.939856\n","[283]\tvalid_0's rmse: 0.93984\n","[284]\tvalid_0's rmse: 0.939841\n","[285]\tvalid_0's rmse: 0.939833\n","[286]\tvalid_0's rmse: 0.939802\n","[287]\tvalid_0's rmse: 0.939608\n","[288]\tvalid_0's rmse: 0.939547\n","[289]\tvalid_0's rmse: 0.939549\n","[290]\tvalid_0's rmse: 0.939549\n","[291]\tvalid_0's rmse: 0.939631\n","[292]\tvalid_0's rmse: 0.939629\n","[293]\tvalid_0's rmse: 0.939604\n","[294]\tvalid_0's rmse: 0.939584\n","[295]\tvalid_0's rmse: 0.939604\n","[296]\tvalid_0's rmse: 0.939679\n","[297]\tvalid_0's rmse: 0.939653\n","[298]\tvalid_0's rmse: 0.939528\n","[299]\tvalid_0's rmse: 0.938883\n","[300]\tvalid_0's rmse: 0.939181\n","[301]\tvalid_0's rmse: 0.939182\n","[302]\tvalid_0's rmse: 0.939139\n","[303]\tvalid_0's rmse: 0.939123\n","[304]\tvalid_0's rmse: 0.939098\n","[305]\tvalid_0's rmse: 0.939054\n","[306]\tvalid_0's rmse: 0.939067\n","[307]\tvalid_0's rmse: 0.939058\n","[308]\tvalid_0's rmse: 0.938965\n","[309]\tvalid_0's rmse: 0.938961\n","[310]\tvalid_0's rmse: 0.93896\n","[311]\tvalid_0's rmse: 0.938955\n","[312]\tvalid_0's rmse: 0.938891\n","[313]\tvalid_0's rmse: 0.938719\n","[314]\tvalid_0's rmse: 0.93659\n","[315]\tvalid_0's rmse: 0.936497\n","[316]\tvalid_0's rmse: 0.936489\n","[317]\tvalid_0's rmse: 0.936529\n","[318]\tvalid_0's rmse: 0.93651\n","[319]\tvalid_0's rmse: 0.936419\n","[320]\tvalid_0's rmse: 0.936431\n","[321]\tvalid_0's rmse: 0.936416\n","[322]\tvalid_0's rmse: 0.936415\n","[323]\tvalid_0's rmse: 0.936421\n","[324]\tvalid_0's rmse: 0.936414\n","[325]\tvalid_0's rmse: 0.936383\n","[326]\tvalid_0's rmse: 0.936327\n","[327]\tvalid_0's rmse: 0.936297\n","[328]\tvalid_0's rmse: 0.936288\n","[329]\tvalid_0's rmse: 0.936278\n","[330]\tvalid_0's rmse: 0.936265\n","[331]\tvalid_0's rmse: 0.936264\n","[332]\tvalid_0's rmse: 0.936239\n","[333]\tvalid_0's rmse: 0.93624\n","[334]\tvalid_0's rmse: 0.935084\n","[335]\tvalid_0's rmse: 0.935071\n","[336]\tvalid_0's rmse: 0.934427\n","[337]\tvalid_0's rmse: 0.934414\n","[338]\tvalid_0's rmse: 0.934415\n","[339]\tvalid_0's rmse: 0.934413\n","[340]\tvalid_0's rmse: 0.934376\n","[341]\tvalid_0's rmse: 0.934367\n","[342]\tvalid_0's rmse: 0.933944\n","[343]\tvalid_0's rmse: 0.933937\n","[344]\tvalid_0's rmse: 0.93393\n","[345]\tvalid_0's rmse: 0.934084\n","[346]\tvalid_0's rmse: 0.933655\n","[347]\tvalid_0's rmse: 0.933659\n","[348]\tvalid_0's rmse: 0.9337\n","[349]\tvalid_0's rmse: 0.933672\n","[350]\tvalid_0's rmse: 0.933642\n","[351]\tvalid_0's rmse: 0.933642\n","[352]\tvalid_0's rmse: 0.933641\n","[353]\tvalid_0's rmse: 0.933475\n","[354]\tvalid_0's rmse: 0.933435\n","[355]\tvalid_0's rmse: 0.933459\n","[356]\tvalid_0's rmse: 0.933428\n","[357]\tvalid_0's rmse: 0.933408\n","[358]\tvalid_0's rmse: 0.933351\n","[359]\tvalid_0's rmse: 0.933344\n","[360]\tvalid_0's rmse: 0.93331\n","[361]\tvalid_0's rmse: 0.933276\n","[362]\tvalid_0's rmse: 0.933266\n","[363]\tvalid_0's rmse: 0.933307\n","[364]\tvalid_0's rmse: 0.933275\n","[365]\tvalid_0's rmse: 0.933222\n","[366]\tvalid_0's rmse: 0.933149\n","[367]\tvalid_0's rmse: 0.93316\n","[368]\tvalid_0's rmse: 0.9332\n","[369]\tvalid_0's rmse: 0.933214\n","[370]\tvalid_0's rmse: 0.933212\n","[371]\tvalid_0's rmse: 0.933164\n","[372]\tvalid_0's rmse: 0.933198\n","[373]\tvalid_0's rmse: 0.933296\n","[374]\tvalid_0's rmse: 0.933336\n","[375]\tvalid_0's rmse: 0.933328\n","[376]\tvalid_0's rmse: 0.933331\n","[377]\tvalid_0's rmse: 0.93333\n","[378]\tvalid_0's rmse: 0.933414\n","[379]\tvalid_0's rmse: 0.933395\n","[380]\tvalid_0's rmse: 0.933379\n","[381]\tvalid_0's rmse: 0.933363\n","[382]\tvalid_0's rmse: 0.933356\n","[383]\tvalid_0's rmse: 0.933277\n","[384]\tvalid_0's rmse: 0.933271\n","[385]\tvalid_0's rmse: 0.933256\n","[386]\tvalid_0's rmse: 0.933236\n","[387]\tvalid_0's rmse: 0.933255\n","[388]\tvalid_0's rmse: 0.933274\n","[389]\tvalid_0's rmse: 0.933248\n","[390]\tvalid_0's rmse: 0.933208\n","[391]\tvalid_0's rmse: 0.933205\n","[392]\tvalid_0's rmse: 0.933211\n","[393]\tvalid_0's rmse: 0.933204\n","[394]\tvalid_0's rmse: 0.933201\n","[395]\tvalid_0's rmse: 0.93323\n","[396]\tvalid_0's rmse: 0.933235\n","[397]\tvalid_0's rmse: 0.933209\n","[398]\tvalid_0's rmse: 0.933283\n","[399]\tvalid_0's rmse: 0.933229\n","[400]\tvalid_0's rmse: 0.933224\n","[401]\tvalid_0's rmse: 0.933203\n","[402]\tvalid_0's rmse: 0.933232\n","[403]\tvalid_0's rmse: 0.933244\n","[404]\tvalid_0's rmse: 0.933213\n","[405]\tvalid_0's rmse: 0.933212\n","[406]\tvalid_0's rmse: 0.933188\n","[407]\tvalid_0's rmse: 0.93322\n","[408]\tvalid_0's rmse: 0.932926\n","[409]\tvalid_0's rmse: 0.932899\n","[410]\tvalid_0's rmse: 0.932894\n","[411]\tvalid_0's rmse: 0.932884\n","[412]\tvalid_0's rmse: 0.932982\n","[413]\tvalid_0's rmse: 0.932981\n","[414]\tvalid_0's rmse: 0.932949\n","[415]\tvalid_0's rmse: 0.932939\n","[416]\tvalid_0's rmse: 0.932938\n","[417]\tvalid_0's rmse: 0.932944\n","[418]\tvalid_0's rmse: 0.932935\n","[419]\tvalid_0's rmse: 0.932933\n","[420]\tvalid_0's rmse: 0.932924\n","[421]\tvalid_0's rmse: 0.932922\n","[422]\tvalid_0's rmse: 0.932928\n","[423]\tvalid_0's rmse: 0.932927\n","[424]\tvalid_0's rmse: 0.932933\n","[425]\tvalid_0's rmse: 0.93293\n","[426]\tvalid_0's rmse: 0.932931\n","[427]\tvalid_0's rmse: 0.932925\n","[428]\tvalid_0's rmse: 0.932919\n","[429]\tvalid_0's rmse: 0.933213\n","[430]\tvalid_0's rmse: 0.933195\n","[431]\tvalid_0's rmse: 0.933088\n","[432]\tvalid_0's rmse: 0.933097\n","[433]\tvalid_0's rmse: 0.933093\n","[434]\tvalid_0's rmse: 0.933007\n","[435]\tvalid_0's rmse: 0.93301\n","[436]\tvalid_0's rmse: 0.932949\n","[437]\tvalid_0's rmse: 0.932875\n","[438]\tvalid_0's rmse: 0.932829\n","[439]\tvalid_0's rmse: 0.932826\n","[440]\tvalid_0's rmse: 0.932833\n","[441]\tvalid_0's rmse: 0.932817\n","[442]\tvalid_0's rmse: 0.933558\n","[443]\tvalid_0's rmse: 0.933542\n","[444]\tvalid_0's rmse: 0.933531\n","[445]\tvalid_0's rmse: 0.933516\n","[446]\tvalid_0's rmse: 0.933605\n","[447]\tvalid_0's rmse: 0.933609\n","[448]\tvalid_0's rmse: 0.933579\n","[449]\tvalid_0's rmse: 0.933585\n","[450]\tvalid_0's rmse: 0.933598\n","[451]\tvalid_0's rmse: 0.933598\n","[452]\tvalid_0's rmse: 0.933619\n","[453]\tvalid_0's rmse: 0.933582\n","[454]\tvalid_0's rmse: 0.933583\n","[455]\tvalid_0's rmse: 0.93357\n","[456]\tvalid_0's rmse: 0.933731\n","[457]\tvalid_0's rmse: 0.933987\n","[458]\tvalid_0's rmse: 0.933982\n","[459]\tvalid_0's rmse: 0.933983\n","[460]\tvalid_0's rmse: 0.933946\n","[461]\tvalid_0's rmse: 0.933933\n","[462]\tvalid_0's rmse: 0.933904\n","[463]\tvalid_0's rmse: 0.933905\n","[464]\tvalid_0's rmse: 0.933891\n","[465]\tvalid_0's rmse: 0.933854\n","[466]\tvalid_0's rmse: 0.933932\n","[467]\tvalid_0's rmse: 0.933912\n","[468]\tvalid_0's rmse: 0.933921\n","[469]\tvalid_0's rmse: 0.933928\n","[470]\tvalid_0's rmse: 0.933886\n","[471]\tvalid_0's rmse: 0.933819\n","[472]\tvalid_0's rmse: 0.933825\n","[473]\tvalid_0's rmse: 0.933959\n","[474]\tvalid_0's rmse: 0.933958\n","[475]\tvalid_0's rmse: 0.933926\n","[476]\tvalid_0's rmse: 0.933936\n","[477]\tvalid_0's rmse: 0.933924\n","[478]\tvalid_0's rmse: 0.933876\n","[479]\tvalid_0's rmse: 0.933875\n","[480]\tvalid_0's rmse: 0.933874\n","[481]\tvalid_0's rmse: 0.93387\n","[482]\tvalid_0's rmse: 0.933858\n","[483]\tvalid_0's rmse: 0.93385\n","[484]\tvalid_0's rmse: 0.933802\n","[485]\tvalid_0's rmse: 0.933797\n","[486]\tvalid_0's rmse: 0.933794\n","[487]\tvalid_0's rmse: 0.93378\n","[488]\tvalid_0's rmse: 0.934117\n","[489]\tvalid_0's rmse: 0.934162\n","[490]\tvalid_0's rmse: 0.934164\n","[491]\tvalid_0's rmse: 0.934136\n","Early stopping, best iteration is:\n","[441]\tvalid_0's rmse: 0.932817\n","R^2 train =  0.5024    R^2 val =  0.3283\n","RMSE train = 0.8684    RMSE val = 0.9328\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train_r2</th>\n","      <th>val_r2</th>\n","      <th>train_rmse</th>\n","      <th>val_rmse</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.540</td>\n","      <td>0.381</td>\n","      <td>0.839</td>\n","      <td>0.881</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.482</td>\n","      <td>0.341</td>\n","      <td>0.887</td>\n","      <td>0.930</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.502</td>\n","      <td>0.328</td>\n","      <td>0.868</td>\n","      <td>0.933</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   train_r2  val_r2  train_rmse  val_rmse\n","0     0.540   0.381       0.839     0.881\n","1     0.482   0.341       0.887     0.930\n","2     0.502   0.328       0.868     0.933"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["214200\n","   ID  item_cnt_month\n","0   0           0.913\n","1   1           0.070\n","2   2           1.273\n","3   3           0.232\n","4   4           0.491\n","Done: Sat 09:05:52 07/04/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VvQ_hOR88pVo","colab_type":"text"},"source":["#####Submission prep"]},{"cell_type":"code","metadata":{"id":"YtId88q4FDPB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1593789578194,"user_tz":240,"elapsed":580,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"89912501-1fcc-4a22-cba4-cf7fee58e158"},"source":["# # Merge the test predictions with IDs from the original test dataset, and keep only columns \"ID\" and \"item_cnt_month\"\n","# y_pr_test_mrg = pd.DataFrame.from_dict({'item_cnt_month':y_pred_test,'shop_id':X_test.shop_id,'item_id':X_test.item_id})\n","# y_pr_test_mrg = test.merge(y_pr_test_mrg, on=['shop_id','item_id'], how= 'left').reset_index(drop=True)\n","# y_submission = y_pr_test_mrg.drop(['shop_id','item_id'],axis=1)\n","# print(len(y_submission))\n","# print(y_submission.head())\n","\n","# print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["214200\n","   ID  item_cnt_month\n","0   0           0.925\n","1   1           0.072\n","2   2           1.332\n","3   3           0.237\n","4   4           0.573\n","Done: Fri 11:19:37 07/03/20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UpSqGEJd8oqo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593867968527,"user_tz":240,"elapsed":1147,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"7f7eacfb-c996-491f-d6a0-78bd4c5c0e63"},"source":["model_name = 'LGBMv5mg_01'\n","if not model_name:\n","    model_name = input(\"Enter the Model Name Substring for Output File Naming (like: LGBMv4mg_01 )\")\n","    \n","%cd \"{GDRIVE_REPO_PATH}\"\n","\n","y_submission.to_csv(\"./models_and_predictions/\" + model_name + '_submission.csv', index=False)\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final/Kag\n","Done: Sat 09:06:07 07/04/20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YbsAkV525HIH","colab_type":"code","colab":{}},"source":["'''\n","Best Coursera score so far: 8/10 public and private LB scores are: 0.985186 and 0.979359 on 5/12 with Andreas' numbers\n","Best with this model: v3_06: Coursera: 8/10 public and private LB scores are: 0.997198 and 0.998091\n","\n","Done: Sat 08:32:18 07/04/20\n","\n","LGBMv5mg_01\n","like v4_06 except average the predictions from training/val splits 10-30/31-33, 10-31/32-33, 10-32/33\n","train_r2\tval_r2\ttrain_rmse\tval_rmse\n","0\t0.540\t0.381\t0.839\t0.881\n","1\t0.482\t0.341\t0.887\t0.930\n","2\t0.502\t0.328\t0.868\t0.933\n","Coursera: 8/10 public and private LB scores are: 0.991743 and 0.992586\n","\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R83oQzqT1KGc","colab_type":"code","colab":{}},"source":["'''\n","Best Coursera score so far: 8/10 public and private LB scores are: 0.985186 and 0.979359 on 5/12 with Andreas' numbers\n","Best with this model: v4_06: Coursera: 8/10 public and private LB scores are: 0.992181 and 0.994315\n","\n","Done: Fri 09:17:02 07/03/20\n","\n","LGBMv4mg_01\n","lags of 1,2,3,6; CartProd/TrainStart= month 8; TrainEnd=32; Val = month 33\n","pre-train clip(-20,20), prediction clip(-20,20)\n","Early stopping, best iteration is:\n","[140]\tvalid_0's rmse: 0.935371\n","R^2 train =  0.4823    R^2 val =  0.3246\n","RMSE train = 0.8858    RMSE val = 0.9354\n","Coursera 8/10 public and private LB scores are: 0.997333 and 0.998032\n","\n","v4_02\n","like _01 but drop these features: ['shop_typeB','shop_fd','shop_typeA_sales_L2','shop_fd_sales_L2','shop_typeA_sales_L3','shop_fd_sales_L3','shop_typeA_sales_L6','shop_fd_sales_L6']\n","Early stopping, best iteration is:\n","[264]\tvalid_0's rmse: 0.929946\n","R^2 train =  0.5111    R^2 val =  0.3324\n","RMSE train = 0.8608    RMSE val = 0.9299\n","Coursera 8/10 public and private LB scores are: 0.998931 and 0.999337\n","\n","v4_03 ... also drop 'shop_typeB_sales_L6'\n","Early stopping, best iteration is:\n","[391]\tvalid_0's rmse: 0.933397\n","R^2 train =  0.5296    R^2 val =  0.3275\n","RMSE train = 0.8444    RMSE val = 0.9334\n","\n","v4_04 ... more drops:  like v4_01, but drop(['shop_typeB','shop_fd',\n","                  'shop_typeA_sales_L2','shop_typeB_sales_L2','shop_fd_sales_L2',\n","                  'shop_typeA_sales_L3','shop_typeB_sales_L3','shop_fd_sales_L3',\n","                  'shop_typeA_sales_L6','shop_typeB_sales_L6','shop_fd_sales_L6',\n","                  'item_catA_sales_L6'], axis=1)\n","Early stopping, best iteration is:\n","[214]\tvalid_0's rmse: 0.933106\n","R^2 train =  0.5069    R^2 val =  0.3279\n","RMSE train = 0.8644    RMSE val = 0.9331\n","\n","v4_05 ... more drops: like v4_01 but drop(['shop_typeB','shop_fd',\n","                  'shop_fd_sales_L1',\n","                  'shop_typeA_sales_L2','shop_typeB_sales_L2','shop_fd_sales_L2',\n","                  'shop_typeA_sales_L3','shop_typeB_sales_L3','shop_fd_sales_L3','shop_id_sales_L3',\n","                  'shop_typeA_sales_L6','shop_typeB_sales_L6','shop_fd_sales_L6','shop_id_sales_L6',\n","                  'item_catA_sales_L6'], axis=1)\n","Early stopping, best iteration is:\n","[157]\tvalid_0's rmse: 0.936376\n","R^2 train =  0.4899    R^2 val =  0.3232\n","RMSE train = 0.8792    RMSE val = 0.9364\n","\n","v4_06 ... like _05, but change learning rate from 0.1 to 0.05\n","Early stopping, best iteration is:\n","[441]\tvalid_0's rmse: 0.932817\n","R^2 train =  0.5024    R^2 val =  0.3283\n","RMSE train = 0.8684    RMSE val = 0.9328\n","Coursera 8/10 public and private LB scores are: 0.992181 and 0.994315\n","\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jvSOoCGTvi1D","colab_type":"text"},"source":["#####Feature Importance"]},{"cell_type":"code","metadata":{"id":"LbszXTq0vhZ-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593787541776,"user_tz":240,"elapsed":1069,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"7ce65a92-3f29-4400-bc1c-62c4f4b519b1"},"source":["# Plot feature importance - Results Visualization\n","feature_importance = model_lgbm.feature_importances_\n","# make importances relative to max importance\n","feature_importance = 100.0 * (feature_importance / feature_importance.max())\n","sorted_idx = np.arange(feature_importance.shape[0])\n","pos = np.arange(sorted_idx.shape[0]) + .5\n","plt.figure(figsize=(14,20)) \n","plt.barh(pos, feature_importance[sorted_idx], align='center')\n","plt.yticks(pos, feature_names[sorted_idx])\n","plt.xlabel('Relative Importance')\n","plt.title('Variable Importance')\n","plt.tick_params(axis='y', which='major', labelsize = 13)\n","# plt.savefig('LGBM_feature_importance_v1.4_mg.png')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1008x1440 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Rjq-rrEDzOJ2"},"source":["#####Stop Execution / Record Results"]},{"cell_type":"code","metadata":{"id":"Hma9PfJGRCHk","colab_type":"code","colab":{}},"source":["# Dummy cell to stop the execution so we don't run any of the random code below (if we select \"Run All\", e.g.)\n","b4 = b5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Q7KJcJrvuR3","colab_type":"code","colab":{}},"source":["Best Coursera score so far: 8/10 public and private LB scores are: 0.985186 and 0.979359 on 5/12 with Andreas' numbers\n","\n","LGBMv3mg_01:  Pre-train clip 0,20; CartProd/TrainStart= month 10; End=32; Val = month 33\n","    learning_rate=0.1,\n","    num_iterations=1000,\n","    early_stopping_round=50,\n","    feature_fraction=0.8,\n","Early stopping, best iteration is:\n","[121]\tvalid_0's rmse: 0.950043\n","R^2 train =  0.4789    R^2 val =  0.3032\n","RMSE train = 0.8829    RMSE val = 0.9500\n","Coursera 8/10 public and private LB scores are: 0.997392 and 0.999304\n","\n","_02: no Pre-train clip (used sqrt compression earlier)\n","Early stopping, best iteration is:\n","[107]\tvalid_0's rmse: 1.37628\n","R^2 train =  0.2077    R^2 val =  0.1750\n","RMSE train = 2.5109    RMSE val = 2.1412\n","Coursera 5/10 public and private LB scores are: 1.008014 and 1.004042\n","\n","_03: like _01 but pre-train clip at 0,18\n","Early stopping, best iteration is:\n","[171]\tvalid_0's rmse: 0.915338\n","R^2 train =  0.4927    R^2 val =  0.3079\n","RMSE train = 0.8446    RMSE val = 0.9153\n","Coursera 5/10 public and private LB scores are: 0.998724 and 1.000856\n","\n","_04: like _01 but train 10-31, val 32-33\n","Early stopping, best iteration is:\n","[87]\tvalid_0's rmse: 0.938215\n","R^2 train =  0.4726    R^2 val =  0.3296\n","RMSE train = 0.8898    RMSE val = 0.9382\n","Coursera 5/10 public and private LB scores are: 1.000803 and 1.001518\n","\n","_05: like _01 but train 24-32, val 33\n","Early stopping, best iteration is:\n","[122]\tvalid_0's rmse: 0.960556\n","R^2 train =  0.5164    R^2 val =  0.2878\n","RMSE train = 0.7662    RMSE val = 0.9605\n","Coursera 5/10 public and private LB scores are: 1.012674 and 1.014969\n","\n","_06: like _01 but include lags of 1,2,3,6; CartProd/TrainStart= month 8; TrainEnd=32; Val = month 33\n","Early stopping, best iteration is:\n","[189]\tvalid_0's rmse: 0.93307\n","R^2 train =  0.4996    R^2 val =  0.3280\n","RMSE train = 0.8708    RMSE val = 0.9330\n","Coursera: 8/10 public and private LB scores are: 0.997198 and 0.998091\n","\n","_07: like 06, but scale sales by 'week_retail_weight', and store sales as a float throughout (no downcasting = downcasting to float throughout)==> strange LGBM fitting behavior\n","Early stopping, best iteration is:\n","[4]\tvalid_0's rmse: 0.655184\n","R^2 train =  0.1618    R^2 val =  0.0691\n","RMSE train = 0.7422    RMSE val = 0.6552\n","Coursera: 3/10 public and private LB scores are: 1.170977 and 1.162842\n","\n","_08: like 06, but no downcasting\n","Early stopping, best iteration is:\n","[189]\tvalid_0's rmse: 0.93307\n","R^2 train =  0.4996    R^2 val =  0.3280\n","RMSE train = 0.8708    RMSE val = 0.9330"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHCHpzsG71yl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1593784880544,"user_tz":240,"elapsed":571,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"32597999-4b8a-4576-ecfc-db02f7ee4a8d"},"source":["x = np.array(([1, np.NaN, 2.5],[2,3,4]))\n","print(x)\n","x=x.astype(np.float16)\n","print(x)\n","print(x.nbytes)\n","print(x.itemsize)\n","print(x.dtype)\n","print(np.float16(5).itemsize)\n","print(np.float32(5).itemsize)\n","print(np.float64(5).itemsize)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1.  nan 2.5]\n"," [2.  3.  4. ]]\n","[[1.  nan 2.5]\n"," [2.  3.  4. ]]\n","12\n","2\n","float16\n","2\n","4\n","8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oqC_Y9nHrNmy","colab_type":"text"},"source":["#**Miscellaneous Code Snippets and Thoughts for Future Work**"]},{"cell_type":"code","metadata":{"id":"30rP_K48EY4s","colab_type":"code","colab":{}},"source":["# # save predictions for an ensemble\n","# pickle.dump(y_pred_train, open(\"./models_and_predictions/\" + model_name + '_pred_train.pickle', 'wb'))\n","# pickle.dump(y_pred_val, open(\"./models_and_predictions/\" + model_name + '_pred_val.pickle', 'wb'))\n","# pickle.dump(y_pred_test, open(\"./models_and_predictions/\" + model_name + '_pred_test.pickle', 'wb'))\n","\n","# # save the model to disk\n","# pickle.dump(model, open(\"./models_and_predictions/\" + model_name + '_model.sav', 'wb'))\n","\n"," \n","# # load the model from disk\n","# loaded_model = pickle.load(open(model_file_name, 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kiRO8mgIk7nR"},"source":["###**Force predictions = 0 for shops that have closed**"]},{"cell_type":"code","metadata":{"id":"_qwYN3cCJyRh","colab_type":"code","colab":{}},"source":["'''\n","# It looks like the average prediction for items that haven't sold in the previous 6 months before month 34\n","#   is roughly 1647 / 23982 = 0.07\n","#\n","# Let's try setting these items' predictions to 0 and see if the grader is happy\n","'''\n","\n","# Nope, this actually made things slightly worse per the coursera grader\n","\n","'''\n","nosales = y_pr_test_mrg.loc[y_pr_test_mrg['item_id'].isin(items_6mo_in_test)]\n","print(len(nosales))\n","print(nosales.item_cnt_month.sum())\n","nosales['item_cnt_month'] = 0\n","y_pr_test_mrg = y_pr_test_mrg.merge(nosales[['shop_id','item_id','item_cnt_month']], on=['shop_id','item_id'], how='left').fillna(1)\n","print(len(y_pr_test_mrg))\n","print(y_pr_test_mrg.head())\n","y_pr_test_mrg['item_cnt_month'] = 0\n","y_pr_test_mrg = y_pr_test_mrg.eval('item_cnt_month = item_cnt_month_x * item_cnt_month_y')\n","print(len(y_pr_test_mrg))\n","print(y_pr_test_mrg.head())\n","nosales = y_pr_test_mrg.loc[y_pr_test_mrg['item_id'].isin(items_6mo_in_test)]\n","print(len(nosales))\n","print(nosales.item_cnt_month.sum())\n","\n","y_submission = y_pr_test_mrg.drop(['shop_id','item_id','item_cnt_month_x','item_cnt_month_y'],axis=1)\n","print(len(y_submission))\n","print(y_submission.head())\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-yaXpG71QxcW","colab_type":"text"},"source":["####Model-Specific Feature Set\n","* Recode Ordinal-Encoded Categorical Features for similar value ranges between the features, so they will have similar weight as inputs to the model\n","* However, StandardScaler will not remove the undesired \"ordinality\" of the category coding.  In future, we need to do something like mean encoding, one-hot encoding, or dense one-hot (embedded) encoding."]},{"cell_type":"code","metadata":{"id":"8a0v1BXjRcGJ","colab_type":"code","colab":{}},"source":["#Remove categorical features unless encoded (e.g one-hot encoding) for basically any method other than a tree method (Linear Regresion, Neural Networks etc)\n","# from sklearn.preprocessing import StandardScaler\n","LinRegFeaturesToDrop= ['month', 'shop_id', 'item_id', 'item_cat0']\n","scaler =  StandardScaler()\n","\n","X_train_LinReg = scaler.fit_transform(X_train.drop(LinRegFeaturesToDrop, axis = 1))\n","X_val_LinReg = scaler.transform(X_val.drop(LinRegFeaturesToDrop, axis = 1))\n","X_test_LinReg = scaler.transform(X_test.drop(LinRegFeaturesToDrop, axis = 1))\n","feature_names_LinReg = X_train.drop(LinRegFeaturesToDrop, axis = 1).columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-Z8YXnTghQL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589152641499,"user_tz":-60,"elapsed":5468,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"11777f06-1d1e-4519-e31d-435950719551"},"source":["feature_names = X_train.columns\n","X_train_np = X_train.to_numpy(dtype = np.float16)\n","del X_train\n","X_val_np = X_val.to_numpy(dtype = np.float16)\n","del X_val\n","X_test_np = X_test.to_numpy(dtype = np.float16)\n","del X_test\n","X_train_np.nbytes/(10**6)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["638.256072"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"markdown","metadata":{"id":"V_kNfg6lCCHv","colab_type":"text"},"source":["###**XGBoost - Gradient-Boosted Decision Tree**"]},{"cell_type":"code","metadata":{"id":"X8zOwfReTlVs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1589145927916,"user_tz":-60,"elapsed":96458,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"dd1ed91a-e025-4210-9259-873d3fde6845"},"source":["%%time\n","X_train_model, X_val_model, X_test_model = X_train_np, X_val_np, X_test_np\n","\n","model = XGBRegressor()\n","model.fit(X_train_model, y_train)\n","\n","y_pred_train, y_pred_val, y_pred_test =  model.predict(X_train_model).clip(0,20), model.predict(X_val_model).clip(0,20), model.predict(X_test_model).clip(0,20)\n","train_score, val_score = sklearn.metrics.r2_score(y_train, y_pred_train), sklearn.metrics.r2_score(y_val, y_pred_val)\n","train_rmse, val_rmse = np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(sklearn.metrics.mean_squared_error(y_val, y_pred_val))\n","print('R^2 train_score is ' + str(train_score) + 'R^2 val_score is ' + str(val_score))\n","print('RMSE train_score is ' + str(train_rmse) + 'RMSE val_score is ' + str(val_rmse))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[21:24:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","R^2 train_score is 0.09796589353051244R^2 val_score is 0.06403915444253994\n","RMSE train_score is 8.607288197126733RMSE val_score is 10.750826813311914\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DwbakC5XvxQg","colab_type":"text"},"source":["####Feature Importance and Submission of Results for XGBoost"]},{"cell_type":"code","metadata":{"id":"bkGLTm-yCQ4h","colab_type":"code","colab":{}},"source":["# Plot feature importance - Results Visualization\n","feature_importance = model.feature_importances_\n","# make importances relative to max importance\n","feature_importance = 100.0 * (feature_importance / feature_importance.max())\n","sorted_idx = np.argsort(feature_importance)\n","pos = np.arange(sorted_idx.shape[0]) + .5\n","plt.figure(figsize=(14,20)) \n","plt.barh(pos, feature_importance[sorted_idx], align='center')\n","plt.yticks(pos, feature_names[sorted_idx])\n","plt.xlabel('Relative Importance')\n","plt.title('Variable Importance')\n","plt.tick_params(axis='y', which='major', labelsize = 13)\n","plt.show()\n","plt.savefig('gbt_feature_importance_mg.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Su5SgInLCFTM","colab_type":"text"},"source":["Sumbission prep"]},{"cell_type":"code","metadata":{"id":"NdyG1LThCKu_","colab_type":"code","colab":{}},"source":["model_name = 'XGBv2'\n","\n","submission = pd.DataFrame({\n","    \"ID\": test.index, \n","    \"item_cnt_month\": y_pred_test\n","})\n","submission.to_csv(model_name + '_submission.csv', index=False)\n","\n","# save predictions for an ensemble\n","pickle.dump(y_pred_train, open(model_name + '_pred_train.pickle', 'wb'))\n","pickle.dump(y_pred_val, open(model_name + '_pred_val.pickle', 'wb'))\n","pickle.dump(y_pred_test, open(model_name + '_pred_test.pickle', 'wb'))\n","\n","# save the model to disk\n","pickle.dump(model, open(model_name + '_model.sav', 'wb'))\n","\n"," \n","# # load the model from disk\n","# loaded_model = pickle.load(open(model_file_name, 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eMUj_QJP1Vur","colab_type":"text"},"source":["###**To-Do List**"]},{"cell_type":"markdown","metadata":{"id":"YQ7tffMSSfn7","colab_type":"text"},"source":["####1. **Test/Train Split**\n","* **Don't Shuffle for now** ... Time-series data generally benefits from being fed to model without shuffling (Andreas).</br>\n","Although, I'm curious about shuffling the training/val data rows, within a given month at least, and after split.  I definitely think the val data should come from the last xx months, where xx= 1 to 6, depending on size of dataset, and month range of truncated data set.\n","* **Possible Model Split or Additional Feature**... Consider sales variance by_year or by_2years (instead of by_month) for items with low price, vs. variance for items with high price... (or, low/high sales)... sales trends could be different enough that we might benefit from adding such a feature, or from training multiple models with training/val/test data split according to the focus of each model. </br> Based on the graphics of feature importance generated by Andreas, I'm not sure this is a big issue, but if I'm understanding correctly, the std is only calculated on a monthly grouping, and not on the entire sales_train set.  The std might be more important if mean or median of 6, 12, 18, or 24 months is made into a feature.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K_Rfgp-vIkAP"},"source":["####2. **Weighting of shops and items based on recent behavior**\n","* **Explicit Forcing of Predictions = 0** for items or shops that have zero sales in the past 3, 6, or 12 months (as if the shop closed, or as if the item is no longer being sold).  Need to first check the months at 11, 12, 13 before the test month, to make sure shop opening, or item for sale is not a seasonal thing.\n","* **Weighting for shops based on integral of sales**... The thought is that Andreas' feature importance plot shows trend-based features to be of minor importance, so it may be more relevant to look at trend-based features where final month (or two or three) have zero sales vs. those that have trends without zero sales. (e.g., if zero sales for months 30-33, or if 500 sales for months 30-33, you have same trend, but would want to make very different predictions... so trend may be more relevant when combining with some knowledge about number of sales, like a feature = \"trend x total sales.\"  (i.e., the integral of sales rather than the slope of sales).  This might be simply done with pandas' \"rolling\" method.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"88vnjiHjIk5k"},"source":["####3. **Feature Adjustment**\n","* **Re-Scale the Stats-Based Features**... perhaps not important for decision tree models, but other models will probably benefit by scaling everything to the same range (perhaps int16 or uint16). Or, scale to slightly different ranges, based on intuition of feature importance.  Sales by shop_item pair per month is likely more important than sales by item_cat3 per month, yet the latter is presently substantially larger than the former.\n","* **Better encoding for categorical features**... instead of a random-ordinal encoding or a pure ordinal encoding, we should reduce the influence of encoding on feature behavior. Consider mean-encoding or sklearn.feature_extraction.FeatureHasher or TensorFlow embedded categorization to keep number of features down? Could be more memory-friendly than one-hot encoding.\n","* **Workdays and Holidays per month** ... Adjust item_cnt_day by number of days in month block; also adjust for holidays and weekends, if it is clear there are no sales on such days.  Or, give different weight to sales on weekends or holidays if we see these dominate the sales vs. if they have very few sales. (Scale by number of weekends/holidays in each month vs. Nov. 2015).  Need to do further EDA first, to see if there really is a deviation of sales on these non-standard days, probably using original dataset grouped by shop_id.</br>\n","Also need to check on monthly behavior... months like December, January, and February may behave differently than other months because of Christmas and because of the large concentration of Russian holidays.  It could make sense to scale the sales of these months so they fit better the overall trends of sales from October to March.  In this way, we feed the model a better-behaved dataset that is not overly influenced by crazy months (particularly, since we are given November as test, and will validate on \"smooth\" months like October, or Sept+Oct, or Aug+Sept+Oct... and won't be doing any test/val on crazy months)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9gjvmWf3Ilmu"},"source":["####4. **Data Memory Requirements and Model Training Time**\n","* **Expanding the Number of Rows in Test/Val**... Consider expansion of cartesian-product size and number of dataframe months being kept for test/val, if things are running quickly and without huge memory requirements.\n","* **More Categ. Features**... Consider expansion of the number of categorical generated features that are included.  I so far have only chosen a few, which I though matched with Andreas' output of feature importance.\n","* **More Stats Features**... Consider expansion of the number of stats features to be included.  I chose to use only the sum() aggregation function because it was simple to implement and understand, and matched well with Andreas' feature importance.  I could add in other stats like std, or (as described above) something like a rolling integral, or some other stat aggregation where instead of \"by_month\", it could be \"by_3mo\" or \"by_season\"\n","* **Interpolating Price for Cartesian-Product Rows**... Consider inclusion of price in the train/val/test data, where some sort of interpolation is used to fill the empty values after cartesian-product merge.  Maybe something simple like ffill or a fast algorithm.\n","* **Interpolating Sales for Cartesian-Product Rows**... Consider the case where sales_train doesn't represent *all* sales over that time period... some shop-item combinations may have nonzero sales, but were not included in the sales_train dataset for some reason.  (I don't think we were given any guarantees that sales_train was a complete representation of all sales.)  We may want to run training/val after cartesian-product merge, and see if it gives nonzero sales predictions for any of the newly-merged rows.  Then, we use these predictions, re-generate the features, and re-train the model.  Repeat as long as the model keeps getting better.  (This could also be a way to refine or interpolate for *price* if we choose to use it as a feature or feature generator.)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CuRc3tgI2BzU","colab_type":"text"},"source":["####Done:\n","* pd.cut or pd.qcut to reduce complexity of item price feature --> int16\n","* When grouping by month, use sum() for item_cnt_day, but use median() for other integer type features so the feature column will also be an integer (not sure if this is going to be strictly true, after watching how pandas behaves... I believe I saw one time where pandas gave the median as something like 100.5, to show that values 100 and 101 were equally centered in the data.  So instead of choosing one of these integer values, it may return a float.... I need to check if this can be set in the median() parameters, or if downcasting to an integer forces it to round the float properly vs. generating a crazy number or a NaN)\n","* Temporarily merge test rows into training data set before performing feature generation, so that where desirable, the feature generation is applied in a way that gives minimal \"special treatment\" to test or train sets.\n","* Convert data types and category encodings so as to use minimal memory (int8 or int16 better than int32, int64, float32, string).\n","* Similarly, focus on most important features (as determined from earlier modeling experiments by Andreas), and delete less-helpful columns to reduce memory requirements.\n","* Also, discard features (luckily mostly of secondary importance) that need to be stored with 4 or more bytes, as these features rapidly grow the dataset size.\n","* Be sure to reset_index(drop=True) as this can save many Megabytes if it had changed to the default int64. (I don't know yet exactly when pandas decides to do this... probably after something like a merge or group operation that can influence the index.  Anyhow... just be sure to reset the index when memory is of importance.)\n","* Keep dataset size down by judiciously choosing shops/items to use in cartesian-product when filling out the sparse sales_train data to better match the test set shop/item pairs.\n","* Keep number of lag features relatively small, and the number of months in the biggest lag to be reasonably small, so we can drop a significant number of early months from the training data.\n"]},{"cell_type":"markdown","metadata":{"id":"au82dd3m59n0","colab_type":"text"},"source":["###**Using Feathering to Save / Load Large Datafiles More Quickly**"]},{"cell_type":"code","metadata":{"id":"j83GHWtrz_Gy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1592357042844,"user_tz":240,"elapsed":7512,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"bda835b2-4e46-4673-a412-dbc6254617d6"},"source":["\n","import feather   # this is 3x to 8x faster than pd.read_csv and pd.to_hdf, but file size is 2x hdf and 10x csv.gz\n","\n","if not traintest_loaded:\n","    print(f'traintest dataframe creation started: {strftime(\"%a %X %x\")}\\n')\n","    traintest = clean_merge_augment()\n","\n","    # optional save file as feather type (big file; don't store inside repo) and/or csv.gz type (inside repo)\n","    %cd \"{OUT_OF_REPO_PATH}\"\n","    traintest.to_feather('traintest.ftr')\n","    print(\"traintest.ftr feather file stored on google drive, outside repo\")\n","    %cd \"{GDRIVE_REPO_PATH}\"\n","    # alternative, or, in addition, can save as csv.gz for < 100 MB storage and sync with GitHub\n","    compression_opts = dict(method='gzip',\n","                            archive_name='traintest.csv')  \n","    traintest.to_csv('data_output/traintest.csv.gz', index=False, compression=compression_opts)\n","    print(\"traintest.csv.gz file stored on google drive in data_output directory\")\n","    print(f'traintest file save done: {strftime(\"%a %X %x\")}')\n","\n","display(traintest[traintest.week == 102].tail(2))\n","\n","\n","# Reading in the feather file:\n","#  Except for fast-loading (large filesize) feather format files, \n","#   the data is coming from a public repo on GitHub at github.com/migai/Kag that has been synced to my local repo on Google Drive\n","\n","'''\n","############################################################\n","############################################################\n","'''\n","# Replace this path with the path on *your* Google Drive where the repo master branch is stored\n","#   (on GitHub, the remote repo is located at github.com/migai/Kag --> below is my cloned repo location)\n","GDRIVE_REPO_PATH = \"/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final/Kag\"\n","OUT_OF_REPO_PATH = \"/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final\"   # place > 100MB files here, because they won't sync with GitHub\n","\n","traintest_loaded = True   # set this to True if you plan to load the .ftr or the .csv.gz version of the traintest dataframe, and skip the calculations below that generated it\n","ftr_file_load_employed = True #False #True  # set to True if you wish to load the .ftr version or the .csv.gz version... it's faster, but its a 10x larger file, and won't work in the GitHub repo push\n","\n","\n","# if using large feather file for fast loading, use the routine here\n","#   note that this is too large to push to GitHub, so if you want to go this route, \n","#   you'll first have to load (more slowly) the 'data_output/traintest.csv.gz' file \n","#   with pandas read_csv, and then store the file as feather type (outside your local GitHub repo)\n","#   Or, you can just recreate the dataframe by running the first few code cells that do merging and data manipulation\n","# load feather files manually for now\n","if (traintest_loaded and ftr_file_load_employed):\n","    print('ftr files source directory: ', end='')\n","    %cd \"{OUT_OF_REPO_PATH}\"\n","    traintest = pd.read_feather('traintest.ftr', columns=None, use_threads=True)\n","    print(\"Loading ftr Files from Google Drive (outside repo) into Colab... \\n\\nData Frame: traintest (from ftr)\")\n","    print(traintest.head(2))\n","\n","'''\n","############################################################\n","############################################################\n","'''"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>day</th>\n","      <th>DoW</th>\n","      <th>DoM</th>\n","      <th>week</th>\n","      <th>qtr</th>\n","      <th>season</th>\n","      <th>month</th>\n","      <th>price</th>\n","      <th>sales</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_name</th>\n","      <th>it_test</th>\n","      <th>item_category_id</th>\n","      <th>item_category_name</th>\n","      <th>it_cat_test</th>\n","      <th>item_cat3</th>\n","      <th>item_cat4</th>\n","      <th>shop_name</th>\n","      <th>sh_cat</th>\n","      <th>sh_test</th>\n","      <th>district</th>\n","      <th>city</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2257039</th>\n","      <td>718</td>\n","      <td>Sat</td>\n","      <td>20</td>\n","      <td>102</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>399</td>\n","      <td>1</td>\n","      <td>59</td>\n","      <td>21970</td>\n","      <td>shar predictor soccer ball</td>\n","      <td>False</td>\n","      <td>69</td>\n","      <td>Gifts - Souvenirs</td>\n","      <td>True</td>\n","      <td>Gifts</td>\n","      <td>Gifts</td>\n","      <td>Yaroslavl shopping center \"Altair\"</td>\n","      <td>SEC</td>\n","      <td>True</td>\n","      <td>Central</td>\n","      <td>Yaroslavl</td>\n","    </tr>\n","    <tr>\n","      <th>2257040</th>\n","      <td>718</td>\n","      <td>Sat</td>\n","      <td>20</td>\n","      <td>102</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>499</td>\n","      <td>1</td>\n","      <td>59</td>\n","      <td>22060</td>\n","      <td>epic bluray dvd</td>\n","      <td>True</td>\n","      <td>37</td>\n","      <td>Movie - Blu-Ray</td>\n","      <td>True</td>\n","      <td>Movies</td>\n","      <td>Movies</td>\n","      <td>Yaroslavl shopping center \"Altair\"</td>\n","      <td>SEC</td>\n","      <td>True</td>\n","      <td>Central</td>\n","      <td>Yaroslavl</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         day  DoW  DoM  week  qtr  season  month  price  sales  shop_id  item_id                   item_name  it_test  item_category_id item_category_name  it_cat_test item_cat3 item_cat4                           shop_name  \\\n","2257039  718  Sat   20   102    8       1     23    399      1       59    21970  shar predictor soccer ball    False                69  Gifts - Souvenirs         True     Gifts     Gifts  Yaroslavl shopping center \"Altair\"   \n","2257040  718  Sat   20   102    8       1     23    499      1       59    22060             epic bluray dvd     True                37    Movie - Blu-Ray         True    Movies    Movies  Yaroslavl shopping center \"Altair\"   \n","\n","        sh_cat  sh_test district       city  \n","2257039    SEC     True  Central  Yaroslavl  \n","2257040    SEC     True  Central  Yaroslavl  "]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","traintest done: Tue 21:24:00 06/16/20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qLM6IieFK_DM","colab_type":"code","colab":{}},"source":["# import pandas as pd\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# import os\n","# data_gdrive_repo_path = '/content/drive/My Drive/Colab Notebooks'\n","# os.chdir(data_gdrive_repo_path)\n","\n","data_folder = 'models_and_predictions/'\n","filename = 'TS_Stats-Features-for-Modelling-v3_mg.feather'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8GbWiS6Ms4f","colab_type":"code","colab":{}},"source":["data = matrix[matrix['month'] >= 14]\n","data.reset_index().astype('float32').to_feather(data_folder + filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swBPhtAcM5gX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1589109267790,"user_tz":-60,"elapsed":40694,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"0183ed56-c7b6-4b28-c643-0717c155508d"},"source":["data = pd.read_feather(data_folder + filename, columns=None, use_threads=True)\n","data = data.astype({'index': np.int32}).set_index('index')\n","cols_by_types = infer_variable_types(matrix)\n","data = sort_variable_types(data, categorical_cols = cols_by_types['categorical'], numerical_cols = cols_by_types['numerical'])\n","data.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","      <th>price_mean_by_item_lag_1</th>\n","      <th>price_mean_by_item_lag_2</th>\n","      <th>price_mean_by_item_lag_3</th>\n","      <th>price_mean_by_item_lag_6</th>\n","      <th>price_mean_by_item_lag_12</th>\n","      <th>sales_mean_by_item_lag_1</th>\n","      <th>sales_mean_by_item_lag_2</th>\n","      <th>sales_mean_by_item_lag_3</th>\n","      <th>sales_mean_by_item_lag_6</th>\n","      <th>sales_mean_by_item_lag_12</th>\n","      <th>price_mean_by_shop_lag_1</th>\n","      <th>price_mean_by_shop_lag_2</th>\n","      <th>price_mean_by_shop_lag_3</th>\n","      <th>price_mean_by_shop_lag_6</th>\n","      <th>price_mean_by_shop_lag_12</th>\n","      <th>sales_mean_by_shop_lag_1</th>\n","      <th>sales_mean_by_shop_lag_2</th>\n","      <th>sales_mean_by_shop_lag_3</th>\n","      <th>sales_mean_by_shop_lag_6</th>\n","      <th>sales_mean_by_shop_lag_12</th>\n","      <th>price_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_category_lag_2</th>\n","      <th>price_mean_by_item_category_lag_3</th>\n","      <th>price_mean_by_item_category_lag_6</th>\n","      <th>price_mean_by_item_category_lag_12</th>\n","      <th>sales_mean_by_item_category_lag_1</th>\n","      <th>sales_mean_by_item_category_lag_2</th>\n","      <th>sales_mean_by_item_category_lag_3</th>\n","      <th>sales_mean_by_item_category_lag_6</th>\n","      <th>sales_mean_by_item_category_lag_12</th>\n","      <th>price_std_by_item_lag_1</th>\n","      <th>price_median_by_item_lag_1</th>\n","      <th>sales_std_by_item_lag_1</th>\n","      <th>sales_median_by_item_lag_1</th>\n","      <th>price_std_by_shop_lag_1</th>\n","      <th>price_median_by_shop_lag_1</th>\n","      <th>sales_std_by_shop_lag_1</th>\n","      <th>sales_median_by_shop_lag_1</th>\n","      <th>price_std_by_item_category_lag_1</th>\n","      <th>price_median_by_item_category_lag_1</th>\n","      <th>sales_std_by_item_category_lag_1</th>\n","      <th>sales_median_by_item_category_lag_1</th>\n","      <th>trend_price_mean_by_item_lag_1</th>\n","      <th>trend_price_mean_by_item_lag_3</th>\n","      <th>trend_price_mean_by_item_lag_6</th>\n","      <th>trend_price_mean_by_item_lag_12</th>\n","      <th>trend_sales_mean_by_item_lag_1</th>\n","      <th>trend_sales_mean_by_item_lag_3</th>\n","      <th>trend_sales_mean_by_item_lag_6</th>\n","      <th>trend_sales_mean_by_item_lag_12</th>\n","      <th>trend_price_mean_by_shop_lag_1</th>\n","      <th>trend_price_mean_by_shop_lag_3</th>\n","      <th>trend_price_mean_by_shop_lag_6</th>\n","      <th>trend_price_mean_by_shop_lag_12</th>\n","      <th>trend_sales_mean_by_shop_lag_1</th>\n","      <th>trend_sales_mean_by_shop_lag_3</th>\n","      <th>trend_sales_mean_by_shop_lag_6</th>\n","      <th>trend_sales_mean_by_shop_lag_12</th>\n","      <th>trend_price_mean_by_item_category_lag_1</th>\n","      <th>trend_price_mean_by_item_category_lag_3</th>\n","      <th>trend_price_mean_by_item_category_lag_6</th>\n","      <th>trend_price_mean_by_item_category_lag_12</th>\n","      <th>trend_sales_mean_by_item_category_lag_1</th>\n","      <th>trend_sales_mean_by_item_category_lag_3</th>\n","      <th>trend_sales_mean_by_item_category_lag_6</th>\n","      <th>trend_sales_mean_by_item_category_lag_12</th>\n","      <th>above_12m_mean_price_mean_by_item</th>\n","      <th>above_12m_mean_sales_mean_by_item</th>\n","      <th>above_12m_mean_price_mean_by_shop</th>\n","      <th>above_12m_mean_sales_mean_by_shop</th>\n","      <th>above_12m_mean_price_mean_by_item_category</th>\n","      <th>above_12m_mean_sales_mean_by_item_category</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11128045</th>\n","      <td>34</td>\n","      <td>46</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>193773</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11128046</th>\n","      <td>34</td>\n","      <td>41</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>198873</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11128047</th>\n","      <td>34</td>\n","      <td>44</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>203973</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11128048</th>\n","      <td>34</td>\n","      <td>39</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>209073</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11128049</th>\n","      <td>34</td>\n","      <td>45</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>214173</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          date_block_num  ...  above_12m_mean_sales_mean_by_item_category\n","index                     ...                                            \n","11128045              34  ...                                         1.0\n","11128046              34  ...                                         1.0\n","11128047              34  ...                                         1.0\n","11128048              34  ...                                         1.0\n","11128049              34  ...                                         1.0\n","\n","[5 rows x 78 columns]"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"markdown","metadata":{"id":"VgzkOq08BH3l","colab_type":"text"},"source":["### **Feature Generation/Engineering (Andreas' Early Work)**\n","\n","Time series features\n","*   Statistics of previous months (e.g. mean of item_price for a specific item/shop in previous months)\n","*   Trends of previous months - rate of change of the above statistics based features (e.g. rate of change of mean item_price from today to the past 3 months for a specific shop/item)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E-yulvUJukr7"},"source":["####1.2) Statistics-Based Features -- Time Lag\n","\n","> Lag them (put them in the same row/month as the one you'll be using them to predict - e.g e.g if going to use 6 month ago mean of item_price to predict item_cnt of next month, put 6 month ago mean of item_price in the same row as current month's values, used to predict next month)\n"]},{"cell_type":"code","metadata":{"id":"qNf5zht40R6f","colab_type":"code","colab":{}},"source":["for i in range(len(Stats_features_second)):\n","  matrix_lagged = lag_feature(matrix, Stats_lags, Stats_features_second[i])\n","  matrix = pd.merge(matrix, matrix_lagged, on=['month','shop_id','item_id'], how='left')\n","del matrix_lagged"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8adt0-u0UF0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1589152323916,"user_tz":-60,"elapsed":185201,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"7c878d30-ad65-40e7-c37a-a9dc6dae2530"},"source":["for i in range(len(Stats_features_third)):\n","  matrix_lagged = lag_feature(matrix, Stats_lags, Stats_features_third[i])\n","  matrix = pd.merge(matrix, matrix_lagged, on=['month','shop_id','item_id'], how='left')\n","del matrix_lagged\n","\n","fetures_to_drop = TS_features + Stats_features #features are renamed and added as a new column within the lag_features functions, so remove these one\n","matrix = matrix.drop(fetures_to_drop, axis = 1)\n","matrix = matrix.fillna(0)\n","matrix[matrix['month']==13].head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","      <th>price_mean_by_item_lag_1</th>\n","      <th>price_mean_by_item_lag_2</th>\n","      <th>price_mean_by_item_lag_3</th>\n","      <th>price_mean_by_item_lag_6</th>\n","      <th>price_mean_by_item_lag_12</th>\n","      <th>sales_sum_by_item_lag_1</th>\n","      <th>sales_sum_by_item_lag_2</th>\n","      <th>sales_sum_by_item_lag_3</th>\n","      <th>sales_sum_by_item_lag_6</th>\n","      <th>sales_sum_by_item_lag_12</th>\n","      <th>price_mean_by_shop_lag_1</th>\n","      <th>price_mean_by_shop_lag_2</th>\n","      <th>price_mean_by_shop_lag_3</th>\n","      <th>price_mean_by_shop_lag_6</th>\n","      <th>price_mean_by_shop_lag_12</th>\n","      <th>sales_sum_by_shop_lag_1</th>\n","      <th>sales_sum_by_shop_lag_2</th>\n","      <th>sales_sum_by_shop_lag_3</th>\n","      <th>sales_sum_by_shop_lag_6</th>\n","      <th>sales_sum_by_shop_lag_12</th>\n","      <th>price_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_category_lag_2</th>\n","      <th>price_mean_by_item_category_lag_3</th>\n","      <th>price_mean_by_item_category_lag_6</th>\n","      <th>price_mean_by_item_category_lag_12</th>\n","      <th>sales_sum_by_item_category_lag_1</th>\n","      <th>sales_sum_by_item_category_lag_2</th>\n","      <th>sales_sum_by_item_category_lag_3</th>\n","      <th>sales_sum_by_item_category_lag_6</th>\n","      <th>sales_sum_by_item_category_lag_12</th>\n","      <th>price_std_by_item_lag_1</th>\n","      <th>price_median_by_item_lag_1</th>\n","      <th>sales_std_by_item_lag_1</th>\n","      <th>sales_median_by_item_lag_1</th>\n","      <th>price_std_by_shop_lag_1</th>\n","      <th>price_median_by_shop_lag_1</th>\n","      <th>sales_std_by_shop_lag_1</th>\n","      <th>sales_median_by_shop_lag_1</th>\n","      <th>price_std_by_item_category_lag_1</th>\n","      <th>price_median_by_item_category_lag_1</th>\n","      <th>sales_std_by_item_category_lag_1</th>\n","      <th>sales_median_by_item_category_lag_1</th>\n","      <th>sales_mean_by_item_lag_1</th>\n","      <th>sales_mean_by_shop_lag_1</th>\n","      <th>sales_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_and_shop_lag_1</th>\n","      <th>price_std_by_item_and_shop_lag_1</th>\n","      <th>price_median_by_item_and_shop_lag_1</th>\n","      <th>sales_sum_by_item_and_shop_lag_1</th>\n","      <th>sales_mean_by_item_and_shop_lag_1</th>\n","      <th>sales_std_by_item_and_shop_lag_1</th>\n","      <th>sales_median_by_item_and_shop_lag_1</th>\n","      <th>price_mean_by_month_lag_1</th>\n","      <th>price_std_by_month_lag_1</th>\n","      <th>price_median_by_month_lag_1</th>\n","      <th>sales_sum_by_month_lag_1</th>\n","      <th>sales_mean_by_month_lag_1</th>\n","      <th>sales_std_by_month_lag_1</th>\n","      <th>sales_median_by_month_lag_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2293</th>\n","      <td>13</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>1208.0</td>\n","      <td>1730.0</td>\n","      <td>1351.0</td>\n","      <td>1063.0</td>\n","      <td>1062.0</td>\n","      <td>890.0</td>\n","      <td>1322.0</td>\n","      <td>862.0</td>\n","      <td>875.0</td>\n","      <td>488.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>1419.0</td>\n","      <td>899.0</td>\n","      <td>0.528809</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.072266</td>\n","      <td>1.105469</td>\n","      <td>119.0</td>\n","      <td>0.0</td>\n","      <td>119.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2294</th>\n","      <td>13</td>\n","      <td>3</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>936.0</td>\n","      <td>1117.0</td>\n","      <td>906.0</td>\n","      <td>636.5</td>\n","      <td>724.0</td>\n","      <td>968.0</td>\n","      <td>1134.0</td>\n","      <td>970.0</td>\n","      <td>890.0</td>\n","      <td>798.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>1384.0</td>\n","      <td>598.5</td>\n","      <td>0.320557</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.057617</td>\n","      <td>1.105469</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2295</th>\n","      <td>13</td>\n","      <td>4</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>1060.0</td>\n","      <td>1129.0</td>\n","      <td>918.5</td>\n","      <td>689.0</td>\n","      <td>752.5</td>\n","      <td>1430.0</td>\n","      <td>2248.0</td>\n","      <td>1486.0</td>\n","      <td>1713.0</td>\n","      <td>2025.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>2436.0</td>\n","      <td>499.0</td>\n","      <td>0.667480</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.120117</td>\n","      <td>1.105469</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2296</th>\n","      <td>13</td>\n","      <td>5</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>885.0</td>\n","      <td>1025.0</td>\n","      <td>821.5</td>\n","      <td>580.0</td>\n","      <td>591.5</td>\n","      <td>1639.0</td>\n","      <td>2224.0</td>\n","      <td>1390.0</td>\n","      <td>1510.0</td>\n","      <td>877.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>1991.0</td>\n","      <td>399.0</td>\n","      <td>0.442139</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.099609</td>\n","      <td>1.105469</td>\n","      <td>149.0</td>\n","      <td>0.0</td>\n","      <td>149.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2297</th>\n","      <td>13</td>\n","      <td>6</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>998.0</td>\n","      <td>971.0</td>\n","      <td>790.5</td>\n","      <td>657.0</td>\n","      <td>703.0</td>\n","      <td>3024.0</td>\n","      <td>5468.0</td>\n","      <td>3938.0</td>\n","      <td>3702.0</td>\n","      <td>4008.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>2380.0</td>\n","      <td>399.0</td>\n","      <td>0.582031</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.106445</td>\n","      <td>1.105469</td>\n","      <td>149.0</td>\n","      <td>0.0</td>\n","      <td>149.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      date_block_num  ...  sales_median_by_month_lag_1\n","2293              13  ...                          1.0\n","2294              13  ...                          1.0\n","2295              13  ...                          1.0\n","2296              13  ...                          1.0\n","2297              13  ...                          1.0\n","\n","[5 rows x 65 columns]"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"hgmFHyzKX0EM","colab_type":"text"},"source":["####2.1) Trend-Based Features\n","\n","> Rate of change of Time series based features (mean of price or item count at past lags/months). Rates of change are calclulated for the past 1m, 3m, 6m, 12m\n","\n"]},{"cell_type":"code","metadata":{"id":"MvqHzOWVWbwv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1589152480965,"user_tz":-60,"elapsed":3045,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"2e4e8627-f7d7-4ccd-f863-9a85d295ea81"},"source":["ts = time.time()\n","trend_lags = [2, \n","              #4, 7, 13\n","              ]\n","for TS_feature in TS_features:\n","  for i in trend_lags:\n","    matrix['trend_' + TS_feature + '_lag_'+str(i-1)] = \\\n","        (matrix[TS_feature +'_lag_'+str(i)] - matrix[TS_feature + '_lag_1']) / matrix[TS_feature + '_lag_1']\n","print(time.time()-ts)\n","matrix.tail()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.1509287357330322\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","      <th>price_mean_by_item_lag_1</th>\n","      <th>price_mean_by_item_lag_2</th>\n","      <th>price_mean_by_item_lag_3</th>\n","      <th>price_mean_by_item_lag_6</th>\n","      <th>price_mean_by_item_lag_12</th>\n","      <th>sales_sum_by_item_lag_1</th>\n","      <th>sales_sum_by_item_lag_2</th>\n","      <th>sales_sum_by_item_lag_3</th>\n","      <th>sales_sum_by_item_lag_6</th>\n","      <th>sales_sum_by_item_lag_12</th>\n","      <th>price_mean_by_shop_lag_1</th>\n","      <th>price_mean_by_shop_lag_2</th>\n","      <th>price_mean_by_shop_lag_3</th>\n","      <th>price_mean_by_shop_lag_6</th>\n","      <th>price_mean_by_shop_lag_12</th>\n","      <th>sales_sum_by_shop_lag_1</th>\n","      <th>sales_sum_by_shop_lag_2</th>\n","      <th>sales_sum_by_shop_lag_3</th>\n","      <th>sales_sum_by_shop_lag_6</th>\n","      <th>sales_sum_by_shop_lag_12</th>\n","      <th>price_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_category_lag_2</th>\n","      <th>price_mean_by_item_category_lag_3</th>\n","      <th>price_mean_by_item_category_lag_6</th>\n","      <th>price_mean_by_item_category_lag_12</th>\n","      <th>sales_sum_by_item_category_lag_1</th>\n","      <th>sales_sum_by_item_category_lag_2</th>\n","      <th>sales_sum_by_item_category_lag_3</th>\n","      <th>sales_sum_by_item_category_lag_6</th>\n","      <th>sales_sum_by_item_category_lag_12</th>\n","      <th>price_std_by_item_lag_1</th>\n","      <th>price_median_by_item_lag_1</th>\n","      <th>sales_std_by_item_lag_1</th>\n","      <th>sales_median_by_item_lag_1</th>\n","      <th>price_std_by_shop_lag_1</th>\n","      <th>price_median_by_shop_lag_1</th>\n","      <th>sales_std_by_shop_lag_1</th>\n","      <th>sales_median_by_shop_lag_1</th>\n","      <th>price_std_by_item_category_lag_1</th>\n","      <th>price_median_by_item_category_lag_1</th>\n","      <th>sales_std_by_item_category_lag_1</th>\n","      <th>sales_median_by_item_category_lag_1</th>\n","      <th>sales_mean_by_item_lag_1</th>\n","      <th>sales_mean_by_shop_lag_1</th>\n","      <th>sales_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_and_shop_lag_1</th>\n","      <th>price_std_by_item_and_shop_lag_1</th>\n","      <th>price_median_by_item_and_shop_lag_1</th>\n","      <th>sales_sum_by_item_and_shop_lag_1</th>\n","      <th>sales_mean_by_item_and_shop_lag_1</th>\n","      <th>sales_std_by_item_and_shop_lag_1</th>\n","      <th>sales_median_by_item_and_shop_lag_1</th>\n","      <th>price_mean_by_month_lag_1</th>\n","      <th>price_std_by_month_lag_1</th>\n","      <th>price_median_by_month_lag_1</th>\n","      <th>sales_sum_by_month_lag_1</th>\n","      <th>sales_mean_by_month_lag_1</th>\n","      <th>sales_std_by_month_lag_1</th>\n","      <th>sales_median_by_month_lag_1</th>\n","      <th>trend_price_mean_by_item_lag_1</th>\n","      <th>trend_sales_sum_by_item_lag_1</th>\n","      <th>trend_price_mean_by_shop_lag_1</th>\n","      <th>trend_sales_sum_by_shop_lag_1</th>\n","      <th>trend_price_mean_by_item_category_lag_1</th>\n","      <th>trend_sales_sum_by_item_category_lag_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11128045</th>\n","      <td>34</td>\n","      <td>46</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>193773</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11128046</th>\n","      <td>34</td>\n","      <td>41</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>198873</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11128047</th>\n","      <td>34</td>\n","      <td>44</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>203973</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11128048</th>\n","      <td>34</td>\n","      <td>39</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>209073</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11128049</th>\n","      <td>34</td>\n","      <td>45</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>214173</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          date_block_num  ...  trend_sales_sum_by_item_category_lag_1\n","11128045              34  ...                                     NaN\n","11128046              34  ...                                     NaN\n","11128047              34  ...                                     NaN\n","11128048              34  ...                                     NaN\n","11128049              34  ...                                     NaN\n","\n","[5 rows x 71 columns]"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"7QrJ-MPsv8c7","colab_type":"text"},"source":["####3.0) Inspection of Data"]},{"cell_type":"markdown","metadata":{"id":"LnTL2HwA3Kyb","colab_type":"text"},"source":["Understanding dataframe created (\"matrix\")"]},{"cell_type":"code","metadata":{"id":"wQOL4w4XhqSB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1589152504290,"user_tz":-60,"elapsed":19340,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"7ea17cb6-d60c-4a64-ec18-5dde56e682b6"},"source":["matrix = matrix.replace([np.inf, -np.inf], np.nan)\n","matrix.fillna(0, inplace=True)\n","matrix.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","      <th>price_mean_by_item_lag_1</th>\n","      <th>price_mean_by_item_lag_2</th>\n","      <th>price_mean_by_item_lag_3</th>\n","      <th>price_mean_by_item_lag_6</th>\n","      <th>price_mean_by_item_lag_12</th>\n","      <th>sales_sum_by_item_lag_1</th>\n","      <th>sales_sum_by_item_lag_2</th>\n","      <th>sales_sum_by_item_lag_3</th>\n","      <th>sales_sum_by_item_lag_6</th>\n","      <th>sales_sum_by_item_lag_12</th>\n","      <th>price_mean_by_shop_lag_1</th>\n","      <th>price_mean_by_shop_lag_2</th>\n","      <th>price_mean_by_shop_lag_3</th>\n","      <th>price_mean_by_shop_lag_6</th>\n","      <th>price_mean_by_shop_lag_12</th>\n","      <th>sales_sum_by_shop_lag_1</th>\n","      <th>sales_sum_by_shop_lag_2</th>\n","      <th>sales_sum_by_shop_lag_3</th>\n","      <th>sales_sum_by_shop_lag_6</th>\n","      <th>sales_sum_by_shop_lag_12</th>\n","      <th>price_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_category_lag_2</th>\n","      <th>price_mean_by_item_category_lag_3</th>\n","      <th>price_mean_by_item_category_lag_6</th>\n","      <th>price_mean_by_item_category_lag_12</th>\n","      <th>sales_sum_by_item_category_lag_1</th>\n","      <th>sales_sum_by_item_category_lag_2</th>\n","      <th>sales_sum_by_item_category_lag_3</th>\n","      <th>sales_sum_by_item_category_lag_6</th>\n","      <th>sales_sum_by_item_category_lag_12</th>\n","      <th>price_std_by_item_lag_1</th>\n","      <th>price_median_by_item_lag_1</th>\n","      <th>sales_std_by_item_lag_1</th>\n","      <th>sales_median_by_item_lag_1</th>\n","      <th>price_std_by_shop_lag_1</th>\n","      <th>price_median_by_shop_lag_1</th>\n","      <th>sales_std_by_shop_lag_1</th>\n","      <th>sales_median_by_shop_lag_1</th>\n","      <th>price_std_by_item_category_lag_1</th>\n","      <th>price_median_by_item_category_lag_1</th>\n","      <th>sales_std_by_item_category_lag_1</th>\n","      <th>sales_median_by_item_category_lag_1</th>\n","      <th>sales_mean_by_item_lag_1</th>\n","      <th>sales_mean_by_shop_lag_1</th>\n","      <th>sales_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_and_shop_lag_1</th>\n","      <th>price_std_by_item_and_shop_lag_1</th>\n","      <th>price_median_by_item_and_shop_lag_1</th>\n","      <th>sales_sum_by_item_and_shop_lag_1</th>\n","      <th>sales_mean_by_item_and_shop_lag_1</th>\n","      <th>sales_std_by_item_and_shop_lag_1</th>\n","      <th>sales_median_by_item_and_shop_lag_1</th>\n","      <th>price_mean_by_month_lag_1</th>\n","      <th>price_std_by_month_lag_1</th>\n","      <th>price_median_by_month_lag_1</th>\n","      <th>sales_sum_by_month_lag_1</th>\n","      <th>sales_mean_by_month_lag_1</th>\n","      <th>sales_std_by_month_lag_1</th>\n","      <th>sales_median_by_month_lag_1</th>\n","      <th>trend_price_mean_by_item_lag_1</th>\n","      <th>trend_sales_sum_by_item_lag_1</th>\n","      <th>trend_price_mean_by_shop_lag_1</th>\n","      <th>trend_sales_sum_by_shop_lag_1</th>\n","      <th>trend_price_mean_by_item_category_lag_1</th>\n","      <th>trend_sales_sum_by_item_category_lag_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   date_block_num  ...  trend_sales_sum_by_item_category_lag_1\n","0               0  ...                                     0.0\n","1               0  ...                                     0.0\n","2               0  ...                                     0.0\n","3               0  ...                                     0.0\n","4               0  ...                                     0.0\n","\n","[5 rows x 71 columns]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"bVaYMbcmuEb5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1589151521421,"user_tz":-60,"elapsed":731359,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"18724c80-6305-4ee3-a3b1-465a837c509a"},"source":["matrix.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_month', 'ID',\n","       'item_category_id', 'price_mean_by_item_lag_1',\n","       'price_mean_by_item_lag_2', 'price_mean_by_item_lag_3',\n","       'price_mean_by_item_lag_6', 'price_mean_by_item_lag_12',\n","       'sales_sum_by_item_lag_1', 'sales_sum_by_item_lag_2',\n","       'sales_sum_by_item_lag_3', 'sales_sum_by_item_lag_6',\n","       'sales_sum_by_item_lag_12', 'price_mean_by_shop_lag_1',\n","       'price_mean_by_shop_lag_2', 'price_mean_by_shop_lag_3',\n","       'price_mean_by_shop_lag_6', 'price_mean_by_shop_lag_12',\n","       'sales_sum_by_shop_lag_1', 'sales_sum_by_shop_lag_2',\n","       'sales_sum_by_shop_lag_3', 'sales_sum_by_shop_lag_6',\n","       'sales_sum_by_shop_lag_12', 'price_mean_by_item_category_lag_1',\n","       'price_mean_by_item_category_lag_2',\n","       'price_mean_by_item_category_lag_3',\n","       'price_mean_by_item_category_lag_6',\n","       'price_mean_by_item_category_lag_12',\n","       'sales_sum_by_item_category_lag_1', 'sales_sum_by_item_category_lag_2',\n","       'sales_sum_by_item_category_lag_3', 'sales_sum_by_item_category_lag_6',\n","       'sales_sum_by_item_category_lag_12', 'price_std_by_item_lag_1',\n","       'price_median_by_item_lag_1', 'sales_std_by_item_lag_1',\n","       'sales_median_by_item_lag_1', 'price_std_by_shop_lag_1',\n","       'price_median_by_shop_lag_1', 'sales_std_by_shop_lag_1',\n","       'sales_median_by_shop_lag_1', 'price_std_by_item_category_lag_1',\n","       'price_median_by_item_category_lag_1',\n","       'sales_std_by_item_category_lag_1',\n","       'sales_median_by_item_category_lag_1', 'sales_mean_by_item_lag_1',\n","       'sales_mean_by_shop_lag_1', 'sales_mean_by_item_category_lag_1',\n","       'price_mean_by_item_and_shop_lag_1', 'price_std_by_item_and_shop_lag_1',\n","       'price_median_by_item_and_shop_lag_1',\n","       'sales_sum_by_item_and_shop_lag_1', 'sales_mean_by_item_and_shop_lag_1',\n","       'sales_std_by_item_and_shop_lag_1',\n","       'sales_median_by_item_and_shop_lag_1', 'price_mean_by_month_lag_1',\n","       'price_std_by_month_lag_1', 'price_median_by_month_lag_1',\n","       'sales_sum_by_month_lag_1', 'sales_mean_by_month_lag_1',\n","       'sales_std_by_month_lag_1', 'sales_median_by_month_lag_1',\n","       'trend_price_mean_by_item_lag_1', 'trend_sales_sum_by_item_lag_1',\n","       'trend_price_mean_by_shop_lag_1', 'trend_sales_sum_by_shop_lag_1',\n","       'trend_price_mean_by_item_category_lag_1',\n","       'trend_sales_sum_by_item_category_lag_1'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"QBP59nqnt43y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"status":"ok","timestamp":1589151656777,"user_tz":-60,"elapsed":37533,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"112d82e7-d609-49cc-eb39-7d072f50f00f"},"source":["df = matrix\n","df1 = df.describe(include = 'all')\n","\n","df1.loc['dtype'] = df.dtypes\n","df1.loc['size'] = len(df)\n","df1.loc['% count'] = df.isnull().mean()\n","df1.loc['%count 0'] = df.apply(lambda col: (col.count() - np.count_nonzero(col)))\n","df1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>15.3396</td>\n","      <td>31.196</td>\n","      <td>11303.7</td>\n","      <td>NaN</td>\n","      <td>2061.52</td>\n","      <td>44.9441</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9.7604</td>\n","      <td>17.3538</td>\n","      <td>6210.93</td>\n","      <td>0</td>\n","      <td>17033.3</td>\n","      <td>15.1401</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>7</td>\n","      <td>16</td>\n","      <td>5947</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>15</td>\n","      <td>30</td>\n","      <td>11388</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>23</td>\n","      <td>47</td>\n","      <td>16592</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>34</td>\n","      <td>59</td>\n","      <td>22169</td>\n","      <td>20</td>\n","      <td>214199</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>dtype</th>\n","      <td>int8</td>\n","      <td>int8</td>\n","      <td>int16</td>\n","      <td>float16</td>\n","      <td>int32</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>size</th>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","    </tr>\n","    <tr>\n","      <th>% count</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>%count 0</th>\n","      <td>365175</td>\n","      <td>16283</td>\n","      <td>50</td>\n","      <td>9522424</td>\n","      <td>10913851</td>\n","      <td>179</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         date_block_num      shop_id  ...           ID item_category_id\n","count       1.11280e+07  1.11280e+07  ...  1.11280e+07      1.11280e+07\n","mean            15.3396       31.196  ...      2061.52          44.9441\n","std              9.7604      17.3538  ...      17033.3          15.1401\n","min                   0            0  ...            0                0\n","25%                   7           16  ...            0               37\n","50%                  15           30  ...            0               40\n","75%                  23           47  ...            0               55\n","max                  34           59  ...       214199               83\n","dtype              int8         int8  ...        int32            int64\n","size           11128050     11128050  ...     11128050         11128050\n","% count               0            0  ...            0                0\n","%count 0         365175        16283  ...     10913851              179\n","\n","[12 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"l_RFPPPP9yr6","colab_type":"code","colab":{}},"source":["data = matrix\n","\n","use_toy_data = False #to be used just for code to run quicker when tests are needed to be made\n","if use_toy_data == True:\n","  train_start_index = 26\n","else:\n","  train_start_index = 14 #skip first 13 months - used to caclulate time series features\n","train_final_index = 28 #makes validation set to be 20% of the non-test data (threshold is surely debatable)\n","\n","data = data[data['month'] >= train_start_index]\n","\n","X_train = data[data.month <= train_final_index].drop(['item_cnt_month', 'ID'], axis=1)\n","y_train = np.array(data[data.month <= train_final_index]['item_cnt_month'])\n","\n","X_val = data[(data.month > train_final_index) & (data.month <= 33)].drop(['item_cnt_month', 'ID'], axis=1)\n","y_val = np.array(data[(data.month > train_final_index) & (data.month <= 33)]['item_cnt_month'])\n","\n","X_test = data[data.month == 34].drop(['item_cnt_month', 'ID'], axis=1)\n","X_test = pd.merge(test, X_test, on= ['month', 'item_id', 'shop_id']).drop(['ID'], axis = 1) #to ensure consistency in rows with test sumbission file\n","del data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFmSE7O4XU8r","colab_type":"code","colab":{}},"source":["#---------------------------Create Stats based features--------------------------------\n","#Stats based features = features computed based on stats of item price/cnt of shops or item for just the previous month\n","\n","ts = time.time()\n","Stats_lags = [1]\n","\n","Stats_features = [\n","                  'price_std_by_item', 'price_median_by_item',\n","                 'sales_std_by_item', 'sales_median_by_item',\n","                 'price_std_by_shop', 'price_median_by_shop',\n","                 'sales_std_by_shop', 'sales_median_by_shop',\n","                 'price_std_by_item_category', 'price_median_by_item_category',\n","                 'sales_std_by_item_category', 'sales_median_by_item_category',\n","                  'sales_mean_by_item', 'sales_mean_by_shop', 'sales_mean_by_item_category' ,\n","                  'price_mean_by_item_and_shop', 'price_std_by_item_and_shop', 'price_median_by_item_and_shop',\n","                  'sales_by_item_and_shop', 'sales_mean_by_item_and_shop', 'sales_std_by_item_and_shop', 'sales_median_by_item_and_shop',\n","                  'price_mean_by_month', 'price_std_by_month', 'price_median_by_month',\n","                  'sales_by_month', 'sales_mean_by_month', 'sales_std_by_month', 'sales_median_by_month'\n","                ]\n","                                  \n","'''\n","\n","'''\n","#Splitting Stats_features as below helped as a quick fix for the session getting crashed from running out of RAM (if GPU still crashes, use TPU for this one - has more RAM)\n","length = len(Stats_features)\n","index = length//3\n","Stats_features_first = Stats_features[:index]\n","Stats_features_second = Stats_features[index:(index*2)]\n","Stats_features_third = Stats_features[(index*2):]\n","\n","for i in range(len(Stats_features_first)):\n","  matrix_lagged = lag_feature(matrix, Stats_lags, Stats_features_first[i])\n","  matrix = pd.merge(matrix, matrix_lagged, on=['month','shop_id','item_id'], how='left')\n","del matrix_lagged\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HNJknAGqN1K9"},"source":["####4.0) Miscellaneous"]},{"cell_type":"code","metadata":{"id":"jcT_wG39WbOi","colab_type":"code","colab":{}},"source":["# Discarding price information for now, due to issues with filling cartesian product empty values\n","# # item price is overly descriptive, and requires a 4-byte storage per entry\n","# #  let's bin it down to just 127 categories, binned by quantiles, and store in int8 1-byte values\n","# #  Note: due to duplication of bin boundaries, need to set q=750 to get 200 categories (uint8); q=370 gives 127 categories (int8)\n","\n","# # # 350 --> 117, 200 --> 83 ,  500-->153,  750-->200, 370-->127\n","# # nbins, labelrange = 370, 127\n","# # i_p_binned, i_p_boundaries = pd.qcut(stt.item_price,q=nbins,precision=0,duplicates='drop',retbins=True,labels=list(range(labelrange)))\n","# # bins_table = pd.DataFrame(zip(i_p_boundaries,list(range(labelrange))),columns=['Threshold','Label'])\n","# # ipbins=i_p_binned.value_counts()\n","# # bins_table['bin_counts'] = bins_table.Label.apply(lambda x: ipbins.loc[x] if x in ipbins.index else 0)\n","# # bar = bins_table.iloc[:][:].plot.bar(x='Threshold',y='bin_counts',figsize=(20,8))\n","\n","# N_BINS = 370  # will return only 127 bins, due to data distribution causing bin overlap\n","\n","# price_binned = pd.qcut(stt.price[stt.month < 34], q=N_BINS, precision=0, duplicates='drop', labels=False)\n","# testbins = pd.Series(np.zeros((TEST_LENGTH), dtype=np.int8))\n","# price_binned = price_binned.append(testbins, ignore_index=True)\n","# stt.price = price_binned.astype(np.int8)\n","# print(stt.head(2))\n","# print(stt.tail(2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QerShYfcQXAD","colab_type":"code","colab":{}},"source":["# In future, this is some thinking on how one might interpolate prices into empty cartesian-product rows\n","# skip this; we are leaving out the \"price\" feature for now\n","\n","# Compute 'price' feature for month=34 (test set) and any cartesian-product empties\n","#  use most recent monthly 'price' median for shop_item pair = month 34 shop-item pair\n","#  use monthly 'price' median by item if shop-item pair is not in months 0-33\n","#  use monthly 'price' median by shop_item_cluster if item is not in months 0-33\n","#  use monthly 'price' median by item_cluster if shop_item_cluster is not in months 0-33\n","#  use monthly 'price' median by shop_item_cat if item_cluster is not in months 0-33\n","#  use monthly 'price' median by item_cat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"omEWIciMxBmI","colab_type":"code","colab":{}},"source":["# DESIRED_DTYPES = ['ID               int32   index value from test data set; drop before model training if desired (= 0 for all train data)',\n","#                   'month            int8\tordinal-encoded month # from start of train data',\n","#                   'shop_id\t        int8\tcategorical range(60) original shop_id values, minus 0,1,9,11,13',\n","#                   'item_id\t        int16\tcategorical range(22170) original item_id values, 21671 present in sales_train_cln_mrg',\n","#                   'price\t        int8\tcontinuous (binned) variable, downcast from float64; price is in range (0 to 59200]',\n","#                   'item_cnt_day     int8   continuous variable, items sold that day at that shop, after clipping to 120 or some other desired value',\n","#                   'sales            int8   continuous variable, items sold that day at that shop, after clipping to 120 or some other desired value',\n","#                   'item_cnt_month\tint16\tcontinuous variable, items sold during the month at that shop, max value = 120 * 31days = int16; clip to 20 after model transform is applied',\n","#                   'sales_month  \tint16\tcontinuous variable, items sold during the month at that shop, max value = 120 * 31days = int16; clip to 20 after model transform is applied',\n","#                   'shop_typeA\t    int8\tCategorical feature indicating small shop / mall / SEC / online...',\n","#                   'shop_typeB\tint8\tCategorical feature like shop_typeA_enc, but merging together mall/Mega/SEC so fewer categories',\n","#                   'item_cat0\tint8\tOriginal category codes for the items (0 to 83)',\n","#                   'item_catA\t    int8\treduction of original 84 categories, grouping primarily by item type',\n","#                   'item_cat3\t    int8\treduction of original 84 categories, grouping primarily by item brand',\n","#                   'item_cluster\t    int16\tCategorical grouping of items by name similarity; encoding weighted',\n","#                   'item_test\t    int8\tTrue(=1) if item id is in the test set',\n","#                   'shop_test\t    int8\tTrue(=1) if shop id is in the test set',\n","#                   'shop_item_test\tint8\tTrue(=1) if shop-item pair is in the test set',\n","#                   'fd_popdens_enc\tint8\tCategorical feature indicating population density of the federal district the shop is in',\n","#                   'fd_gdp_enc\t    int8\tCategorical feature indicating gdp/person for the federal district the shop is in',\n","#                   'shop_city_enc\tint8\tCategorical feature indicating which city hosts the shop',\n","#                   'shop_federal_district_enc\tint8\tCategorical feature indicating which federal district the shop is in',\n","#                   'price_med_by_item            int8',\n","#                   'sales_by_item                int16',\n","#                   'price_med_by_shop            int8',\n","#                   'sales_by_shop                int16',\n","#                   'price_med_by_item_cat        int8',\n","#                   'sales_by_item_cat            int16',\n","#                   'price_med_by_shop_item       int8',\n","#                   'sales_by_shop_item           int16']\n","\n","# def reset_dtypes(df, dtype_list=DESIRED_DTYPES):\n","#     \"\"\"\n","#     function used to set the columns of dataframe df to the dtypes desired,\n","#     as given by list of strings where the first two whitespace-separated string\n","#     elements are the column name and the desired np dtype (not including np)\n","#     example: dtype_list = ['shop_id int8 some random descriptive text if you want', 'item_id int16 blah blah']\n","#     This gives you finer control over setting column dtypes as you would like, and\n","#     easily choosing which columns to perform this on.\n","#     Drawbacks of using this function: you need to create the dtype_list, and this function does no \n","#     error checking to see if your desired dtype is inconsistent with column values (e.g., if you desire int8,\n","#     but your data actually exceeds +128, you could end up with a negative number during the type conversion.\n","#     The built-in pandas function seems to do a good job of checking so you don't underspecify the dtype.)\n","#     \"\"\"\n","#     for i in dtype_list:\n","#         wds = re.findall(r\"[\\w]+\", i)\n","#         if wds[1] != ('bool' | 'str' | 'object'): \n","#             wds[1] = 'np.' + wds[1]  # prepend numerical datatypes with 'np.' (not comprehensive; only ignores bool, str, object dtypes)\n","#         if wds[0] in df.columns:\n","#             df[wds[0]] = df[wds[0]].astype(eval(wds[1]))\n","#     return df\n","# stt = reset_dtypes(stt)\n","\n","# Alternative: instead of manually checking and setting dtypes, pandas function seems to work pretty well; unsigned, signed, integer, float...\n","#  see:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html#pandas.to_numeric\n","# stt = stt.apply(pd.to_numeric, downcast='integer')\n","# print_col_info(stt,5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIngJXJYSTAW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1589993541314,"user_tz":240,"elapsed":5561,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"aed0fb34-e7af-43d5-9f60-c4ac8e3f3e92"},"source":["%%time\n","# starter DF (for merging with stats by month for broader category groupings)\n","#    monthly_stt = stt with shop-item pair item_cnt_day summed and grouped by month\n","#    (i.e., rows are the smallest divisions of the dataset by month, as we use the most specific shop and item \"categories\")\n","#  use median to keep integers as integers\n","\n","monthly_stt = stt.groupby(['month','shop_id','item_id']).agg({  'shop_typeA':['median'], \n","                                                                'shop_typeB':['median'], \n","                                                                'item_cat0':['median'], \n","                                                                'item_catA':['median'], \n","                                                                'item_cat3':['median'], \n","                                                                'item_cluster':['median'], \n","                                                                'shop_test':['median'], \n","                                                                'item_test':['median'], \n","                                                                'shop_item_test':['median'],\n","                                                                'sales':['sum']\n","                                                                }).reset_index()\n","monthly_stt.columns = monthly_stt.columns.droplevel(1)\n","monthly_stt.rename({'sales':'sales_by_shop_item'}, axis='columns', inplace=True)\n","\n","monthly_stt.sales_by_shop_item = monthly_stt.sales_by_shop_item.clip(0,255) # clip the sales/month aggregate sum to uint8\n","\n","MONTHLY_STT_LENGTH = len(monthly_stt)\n","\n","print(f'\\nmonthly_stt dataframe total memory usage before downcast: {monthly_stt.memory_usage(deep=True).sum()/1e6:.0f} MBytes\\n')\n","#Downcast\n","monthly_stt = monthly_stt.apply(pd.to_numeric, downcast='unsigned') #'integer')\n","print('monthly_stt dataframe memory usage after downcast:')\n","print_col_info(monthly_stt,6)\n","print(f'\\n{monthly_stt.head(3)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","monthly_stt dataframe total memory usage before downcast: 65 MBytes\n","\n","monthly_stt dataframe memory usage after downcast:\n","  Column Name     DType MBytes                 Column Name     DType MBytes       \n","        Index     int64    0.0                   item_cat3     uint8    1.8       \n","        month     uint8    1.8                   item_cat4     uint8    1.8       \n","      shop_id     uint8    1.8                item_cluster    uint16    3.6       \n","      item_id    uint16    3.6                   shop_test     uint8    1.8       \n","   shop_typeA     uint8    1.8                   item_test     uint8    1.8       \n","   shop_typeB     uint8    1.8              shop_item_test     uint8    1.8       \n","    item_cat0     uint8    1.8          sales_by_shop_item     uint8    1.8       \n","\n","Number of rows in DataFrame: 1,809,624\n","DataFrame total memory usage: 27 MB\n","\n","   month  shop_id  item_id  shop_typeA  shop_typeB  item_cat0  item_cat3  item_cat4  item_cluster  shop_test  item_test  shop_item_test  sales_by_shop_item\n","0      0        2       27          30          60         19          4          6          1433          1          0               0                   1\n","1      0        2       33          30          60         37          7          3          1669          1          1               1                   1\n","2      0        2      317          30          60         45          1          1           110          1          0               0                   1\n","CPU times: user 4.85 s, sys: 71 ms, total: 4.93 s\n","Wall time: 4.93 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rZu3cckxjqDV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"error","timestamp":1589800873270,"user_tz":240,"elapsed":462,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"89ca57a6-2ec2-44d1-b666-e573c014339d"},"source":["# Create artificial features as combinations of the above, to favor those items / shops in the test set\n","# by_shop_L1*shop_test, by_item_L1*item_test, by_shop_item_L1*shop_item_test\n","#   Let's assume we are going to train the model using month=33 as the validation set\n","#      and, we'll make a second training run using months 32 and 33 as the validation set\n","#   So, we need shop_test = 1 if shop in month=33.unique (and item_test, and shop_item_test)\n","#      and, another column if shop in months 32,33 (and item and shop_item)\n","shop_33_u = dfL.query(\"(month == 33) & (shop_test == 1)\").shop_id.unique()\n","item_33_u = dfL.query(\"(month == 33) & (item_test == 1)\").item_id.unique()\n","shop_3233_u = dfL.query(\"((month == 33) | (month == 32)) & (shop_test == 1)\").shop_id.unique()\n","item_3233_u = dfL.query(\"((month == 33) | (month == 32)) & (item_test == 1)\").item_id.unique()\n","dfL['s_i_pair'] = zip(dfL.shop_id.to_list(), dfL.item_id.to_list())\n","pair_33_u = dfL.query(\"(month == 33) & (shop_item_test == 1)\").s_i_pair.unique()\n","pair_3233_u = dfL.query(\"((month == 33) | (month == 32)) & (shop_item_test == 1)\").s_i_pair.unique()\n","\n","\n","# @numba.vectorize\n","# def multiply_columns_by_2(x):  # noqa E501\n","#     return x * 2\n","\n","# dfL['shop_x_test_L1'] = dfL.eval('sales_by_shop_L1 * shop_test if shop_id in @shop_33_u else 0')\n","# dfL['item_x_test_L1'] = dfL.eval('sales_by_item_L1 * item_test if item_id in @item_33_u else 0')\n","# dfL['shop_item_x_test_L1'] = dfL.eval('sales_by_shop_item_L1 * shop_item_test if s_i_pair in @pair_33_u else 0')\n","# dfL['shop_x_test_L1L2'] = dfL.eval('(sales_by_shop_L1 + sales_by_shop_L2) * shop_test if shop_id in @shop_3233_u else 0')\n","# dfL['item_x_test_L1L2'] = dfL.eval('(sales_by_item_L1 + sales_by_item_L2) * item_test if item_id in @item_3233_u else 0')\n","# dfL['shop_item_x_test_L1L2'] = dfL.eval('(sales_by_shop_item_L1 + sales_by_shop_item_L2) * shop_item_test if s_i_pair in @pair_3233_u else 0')\n","\n","\n","dfL['shop_x_test_L1'] = dfL.sales_by_shop_L1\n","print(dfL.shop_x_test_L1.sum())\n","dfL.shop_x_test_L1 = dfL.query(\"shop_id not in @shop_33_u\").shop_x_test_L1.apply(lambda x: 0) # = 0 #dfL.sales_by_shop_L1 #dfL.apply(lambda x: x.sales_by_shop_L1 * x.shop_test if shop_id in @shop_33_u else 0')\n","print(dfL.shop_x_test_L1.sum())\n","# dfL['item_x_test_L1'] = dfL.eval('sales_by_item_L1 * item_test if item_id in @item_33_u else 0')\n","# dfL['shop_item_x_test_L1'] = dfL.eval('sales_by_shop_item_L1 * shop_item_test if s_i_pair in @pair_33_u else 0')\n","# dfL['shop_x_test_L1L2'] = dfL.eval('(sales_by_shop_L1 + sales_by_shop_L2) * shop_test if shop_id in @shop_3233_u else 0')\n","# dfL['item_x_test_L1L2'] = dfL.eval('(sales_by_item_L1 + sales_by_item_L2) * item_test if item_id in @item_3233_u else 0')\n","# dfL['shop_item_x_test_L1L2'] = dfL.eval('(sales_by_shop_item_L1 + sales_by_shop_item_L2) * shop_item_test if s_i_pair in @pair_3233_u else 0')\n","\n","dfL.s_i_pair = dfL.s_i_pair.astype('category')\n","dfL.s_i_pair = dfL.s_i_pair.cat.codes\n","dfL = dfL.apply(pd.to_numeric, downcast='integer')\n","print('Cartesian-product with lagged and combined features dfL (after downcast):')\n","print_col_info(dfL,8)\n","print(f'\\ndfL.head:\\n{df.head()}')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-63fba1174e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#   So, we need shop_test = 1 if shop in month=33.unique (and item_test, and shop_item_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#      and, another column if shop in months 32,33 (and item and shop_item)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mshop_33_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(month == 33) & (shop_test == 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshop_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mitem_33_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(month == 33) & (item_test == 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mshop_3233_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"((month == 33) | (month == 32)) & (shop_test == 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshop_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dfL' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"X-qeKYp1j5aQ","colab_type":"text"},"source":["###Encoding categoricals"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T85wILmYUukG","colab":{}},"source":["'''\n","think about this later... probably want to do something like sqrt() on shop_sales and item_cat0_sales\n","but log() or sqrt(log) of x+1 => log1p() for item_sales and item_cluster_sales\n","and no expansion/compression for catA or cat3 sales...\n","\n","%%time\n","# Scale the values of the different columns so they have similar (or properly weighted, based on importance) value magnitudes\n","#  Note, y_sales (= prediction target) is about 10x (or more) less than the grouped category sales\n","\n","# I don't want to apply any additive or multiplicative transformation to y_sales, as this is directly related to what we want to predict\n","#  However, what I can do is clip it to some value sufficiently higher than the final clipping value of 20\n","#  Let's clip to ITEM_CNT_TRAIN_CLIP = 250 , as this fits into a uint8\n","# Then let's do histogram-like binning to force the various group-by-xx stats features into the same storage range, so all stats features will be in range(0,250)\n","#  --> the binning will cause loss of some information, but it will keep roughly the same relative spacing between the different categories\n","pred_target_colname = stats_col_names[0]  # put this in a variable name in case we change 'y_sales' to something different in the future\n","bin_cols = stats_col_names.copy()\n","bin_cols.remove(pred_target_colname)\n","monthly_stt2 = monthly_stt.copy(deep=True) # don't mess up monthly_stt while I'm developing this code\n","monthly_stt2[pred_target_colname] = monthly_stt2[pred_target_colname].clip(0,ITEM_CNT_TRAIN_CLIP)\n","\n","before_bin_zero_item_sales = len(monthly_stt2[monthly_stt2.item_sales ==0])\n","#nps= np.vectorize(np.sqrt)  # np.sqrt(x/scale1) = 30s\n","for bc in bin_cols:\n","    #scale1 = monthly_stt2[bc].max() / 2000  # scale all columns to similar range before applying expansion to highlight lower values of sales\n","    #monthly_stt2[bc] = monthly_stt2[bc].apply(lambda x: np.sqrt(np.log1p(x)/scale1))    #np.log(np.sqrt(x)+1)) #(lambda x: np.log1p(x))  # compress the entries with huge numbers, so the linear scaling before binning keeps the finer info of small, but nonzero, values\n","    scale2 = monthly_stt2[bc].max() / ITEM_CNT_TRAIN_CLIP\n","    monthly_stt2[bc] = monthly_stt2[bc].apply(lambda x: 1+x/scale2 if x>0 else 0)  # add in the +1 and special case for 0, so we don't lose fractional stuff\n","    monthly_stt2[bc] = pd.cut(monthly_stt2[bc],ITEM_CNT_TRAIN_CLIP+1, precision=0, duplicates='drop', labels=False) #, include_lowest=True)\n","\n","after_bin_zero_item_sales = len(monthly_stt2[monthly_stt2.item_sales ==0])\n","\n","print(monthly_stt2.head())\n","print('\\n')\n","print(monthly_stt2.describe())\n","print('\\n')\n","print(f'Before binning, n_rows with item_sales == 0: {before_bin_zero_item_sales:,d}, and after binning: {after_bin_zero_item_sales:,d}')\n","print('\\n')\n","# pandas describe(include='all') function has poor handling of numerical values when computing nunique for a column; however, using explicit nunique() works OK, so here's the following table:\n","co = 'Column Name'\n","nu = 'N Unique Values'\n","mx = 'Maximum Value'\n","mn = 'Minimum Value'\n","print(f'{co:>19}  {nu:>16}  {mx:>14}  {mn:>14}')\n","for c in monthly_stt2.columns:\n","    nu = monthly_stt2[c].nunique()\n","    mx = monthly_stt2[c].max()\n","    mn = monthly_stt2[c].min()\n","    print(f'{c:>19}  {nu:16d}  {mx:14d}  {mn:14d}')\n","\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6qBIRRAtY5b","colab_type":"code","colab":{}},"source":["'''\n","this ties in with the above code cell\n","ignore for now\n","\n","# Demonstration of binning giving results quite similar to the (linearly scaled) original\n","\n","# Also, interesting plots for each different shop's sales by month... several shops have no recent sales\n","# cat0, shop, item, itemcluster\n","pltcol = 'item_cluster'\n","cliptop = 100250\n","plotcolmincounts = 0\n","month = 20 # (and up)\n","monthly_stt3 = monthly_stt.copy(deep=True)\n","# monthly_stt3['shop_sales_scaled'] = monthly_stt3['shop_sales'] / (16338/250)\n","# monthly_stt3 = monthly_stt3.groupby(['month','shop_id']).agg({'shop_sales_scaled':['median'],'shop_sales_bin':['median']})\n","# # monthly_stt3.columns = ['shop_sales_scaled','shop_sales_bin']\n","# monthly_stt3 = monthly_stt3.groupby(['month','shop_id']).agg({'shop_sales':['median']})\n","# monthly_stt3.columns = ['shop_sales']\n","# monthly_stt3 = monthly_stt3.reset_index()\n","# print(monthly_stt3.head())\n","# for s in monthly_stt3.shop_id.unique()[20:25]:\n","#     dfplot = monthly_stt3[monthly_stt3.shop_id == s]\n","#     ax = dfplot.plot(x='month',y='shop_sales',kind='line',color='orange',figsize=(20,5),grid=True)\n","#     #ax2 = dfplot.plot(x='month',y='shop_sales_bin',kind='scatter',color='black',ax=ax)\n","\n","\n","monthly_stt3 = monthly_stt3.groupby(['month','item_id']).agg({pltcol:['median']})\n","monthly_stt3.columns = [pltcol]\n","monthly_stt3 = monthly_stt3.reset_index()\n","dfplot = monthly_stt3[monthly_stt3.month >= month].copy(deep=True)\n","print(dfplot.head())\n","dfplot[pltcol] = dfplot[dfplot[pltcol] >= plotcolmincounts][pltcol].clip(0,cliptop)\n","ax = dfplot.plot(x='month',y=pltcol,kind='hist',bins= 50,color='orange',figsize=(20,8),grid=True)\n","    \n","# for i in monthly_stt3.item_id.unique()[2000:2005]:\n","#     dfplot = monthly_stt3[monthly_stt3.item_id == i]\n","#     ax = dfplot.plot(x='month',y='item_sales',kind='line',color='orange',figsize=(20,10),grid=True)\n","#     #ax2 = dfplot.plot(x='month',y='shop_sales_bin',kind='scatter',color='black',ax=ax)\n","\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOP5mr1sHT5Z","colab_type":"code","colab":{}},"source":["'''\n","# go back to using monthly_stt, because all of the following code uses that name, and I don't want to change all of it\n","\n","monthly_stt = monthly_stt2.copy(deep=True)\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BlpasBnrxWI4","colab_type":"text"},"source":["##**Determine the Strategy for Adding Cartesian Product Rows**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"stLcT9JY1Yzv"},"source":["###Cartesian-Product Thoughts\n","It benefits us to expand the train/val data with additional rows corresponding to certain missing shop-item pairs, so our model has a better chance of accurately predicting for the shop-item pairs test set. This is primarily because categorical groupings give certain shop-item pairs relevance even if they are not in the train or test sets. </br>\n","\n","* Because we have shops and items categorically grouped, we can infer certain things about a previously-unseen shop-item pair, by using the behavior of the shops and items in the same categories.\n","* To train in anticipation of being able to predict all test set shop-item pairs, the model needs to be scored on a train dataset that has all of the test set's shop-item pairs in each time period, with proper estimates of values that may need to be interpolated.  \n","** If we make the simplest assumption of zero sales for any shop-item pair not present in the sales_train dataset, we can just fill with 0 for any of the sales_by columns for the new cartesian product rows.\n","** If we use 'price' or one of its functional aggregates as a feature, things get more complicated, as it probably is not ideal to set price = 0 when adding the new cartesian product rows.  We need to infer or interpolate if we plan to use price-based features in our model.\n","** An alternative to manually interpolating is to train a preliminary model for months \\< 34, and use the preliminary model(s) to make predictions for what sales counts should be used for the new cartesian product rows.  You might have one model for every aggregate feature, for example, or you could combine several of these features as \"target\" predictions in a single model.\n","* Similarly, it is important for the validation set to be scored based on predictions for all relevant shop-item pairs, and not just the shop-item pairs present in the sales_train dataset.\n","* We do not need to add cartesian product rows to month 34, because the model only considers single row inputs, and not chunks of rows as inputs. (Although this is a possible model variant... feeding it a group of correlated rows that are not already correlated by aggregate features... then the model has nrows times as many \"feature inputs\" to deal with)\n","\n","</br>\n","\n","What makes a shop-item pair relevant to add using cartesian product?:\n","* Shop focus:\n","* 1. Any and all shop_ids in the test set should be present in the train and validation sets</br>\n","\n","</br>\n","\n","* Item focus:\n","* 2. Any and all item_ids in the test set should be present in the train and validation sets\n","* 3. Any items that have the same item_category_id as any of the items in the test set\n","* 4. Any items that have the same item_cluster as any of the items in the test set</br>\n","\n","</br>\n","\n","* Date focus:\n","* 5. Recent months appear to be much more valuable than early months\n","* 6. Look for shops or items with zero sales in the future and also zero sales in the past xx months, and assume they are closed or no longer selling.  Set up some method of forcing the model prediction to be zero for the following month.\n","\n","</br>\n","\n","The cartesian product is going to create a huge number of extra rows, and will dramatically increase memory requirements and running time.  So, we need to be judicious in our choice of what months to expand in cartesian-land, and if any months should be dropped or can somehow manage without full cartesian product expansion."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GnRD9aQF-aMp"},"source":["####Inspect data to find a memory-friendly way of incorporating cartesian product rows"]},{"cell_type":"code","metadata":{"id":"96lecgS6LGK5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590285997159,"user_tz":240,"elapsed":85183,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"a1725d3a-0137-418b-86de-6361fc709a85"},"source":["# Populate the train/test dataframe with cartesian products to inform the model explicitly on behavior of shop-item pairs in previous months\n","\n","# First, consider the following:\n","#  to help keep the dataframe memory requirements lower, let's only cartesian product rows for the most important features:\n","#  shop_id present in test, or item_id present in test, or item_cat0 present in test, or item_cluster present in test\n","\n","test_shops_u = test_augmented.shop_id.unique()\n","test_items_u = test_augmented.item_id.unique()\n","test_item_cat_u = test_augmented.item_cat0.unique()\n","test_item_cluster_u = test_augmented.item_cluster.unique()\n","print(f'Unique test... shops = {len(test_shops_u)}, items = {len(test_items_u)}, item_cat0s = {len(test_item_cat_u)}, item_clusters = {len(test_item_cluster_u)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Unique test... shops = 42, items = 5100, item_cat0s = 62, item_clusters = 1218\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YylVayCmmTvS","colab_type":"code","colab":{}},"source":["# See how many rows conform to either shop_id in test, item_id in test, item_cat0 in test, or item_clusters in test\n","# reduced_data = sales_train_test.query(\"(shop_id in @test_shops_u) | (item_id in @test_items_u) | (item_cat0 in @test_item_cat_u) | (item_cluster in @test_item_cluster_u)\")\n","# print(f'Number of rows in reduced_data month 34 = {len(reduced_data[reduced_data.date_block_num == 34]):,d} (note, number of rows in test data set = {TEST_LENGTH:,d})')\n","# print(f'Unique reduced_data... shops = {reduced_data.shop_id.nunique()}, items = {reduced_data.item_id.nunique()}, item_cat0s = {reduced_data.item_cat0.nunique()}, item_clusters = {reduced_data.item_cluster.nunique()}')\n","# print(f'Number of rows in reduced_data: {len(reduced_data):,d}')\n","# not really worth it to filter down train data to just those that are closely related to test\n","\n","# let's see what happens if we only consider as useful the shops / items / item_cats / item_clusters in months 20 to 34\n","CART_FILL_MO_START = CARTESIAN_FILL_MONTH_START # fixed value set above, just after loading data files (presently = 10)\n","CART_CORR_MO_START = CARTESIAN_CORRELATION_START_MONTH # (present value = 23)\n","\n","nrows_stt = len(stt)\n","stt_month34_nrows = len(stt[stt.month == 34])\n","\n","def find_correlated_shops_items(start_month = CART_CORR_MO_START, end_month = 34,\n","                                querystr = \"(shop_id in @test_shops_u) | (item_id in @test_items_u) | (item_cat0 in @test_item_cat_u) | (item_cluster in @test_item_cluster_u)\"):\n","    \"\"\"\n","    The idea behind this function is to reduce computer memory requirements by reducing the number of shops and items from which we create our cartesian product...\n","        Instead of taking all unique shops (60) and items (22700) and applying them to form the rows present for every month in our train/val data,\n","        we only take the shops and items that have presence in a certain month range in the sales_train_test dataset,\n","        and, only take those that are closely correlated to test rows \n","        (e.g. rows in sales_train_test that have the same shop_id as any of the test shops, or that have the same item_id, or same item_cat0, or same item_cluster code)\n","    Note that using intuition suggesting more-recent months will give more valuable information, we can limit the queried months in sales_train_test by adjusting start_month and/or end_month\n","        this will further reduce the numbers of \"test-correlated\" shop_ids and item_ids, to a point where our cartesian product size may be less than half that of the full version\n","    returns: dict with info on the sales_train_test rows matching query conditions, along with lists and list_lengths of the unique shops and unique items found by the query\n","    \"\"\"\n","    reduced_dataframe = stt.query(\"(month >= @start_month) & (month <= @end_month)\").query(querystr)\n","    cp = {}  # cartesian product info is held in this dict\n","    cp['shop_id_list'] = reduced_dataframe.shop_id.unique()\n","    cp['n_shop_ids'] = len(cp['shop_id_list'])\n","    cp['item_id_list'] = reduced_dataframe.item_id.unique()\n","    cp['n_item_ids'] = len(cp['item_id_list'])\n","    cp['item_cat0_list'] = reduced_dataframe.item_cat0.unique()\n","    cp['n_item_cat0s'] = len(cp['item_cat0_list'])\n","    cp['item_cluster_list'] = reduced_dataframe.item_cluster.unique()\n","    cp['n_item_clusters'] = len(cp['item_cluster_list'])\n","    cp['start_month'] = start_month\n","    cp['end_month'] = end_month\n","    cp['query_conditions'] = [x.split(\" \")[0] for x in querystr.split(\"(\")][1:]\n","    return cp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"leMOB16-0f5u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"executionInfo":{"status":"ok","timestamp":1590286077663,"user_tz":240,"elapsed":165673,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"f8d5f064-9709-458d-c90b-c6e7706e9055"},"source":["%%time\n","\n","cart_prod = find_correlated_shops_items()\n","\n","# all test items are in the cartesian product, if we include month 34 when doing our query\n","# let's see how many of the shops and items are covered if we don't include month 34\n","# (this gives us an idea of how many of the test items (or their correlated categories) are not present in sales_train, and thus\n","#  an idea of how many of the cartesian product rows will have no original training information to interpolate values from)\n","# (note: when # uncovered shops = 0, then total number of test rows not present in cartesian product = 42 shops * n_uncovered_items)\n","for start_month in [15,17,19,21,23,25,27,29,CART_CORR_MO_START]:\n","    cart_prod_33 = find_correlated_shops_items(start_month, end_month=33)\n","    n_uncovered_test_shops33 = len(test_shops_u) - len([x for x in test_shops_u if x in cart_prod_33['shop_id_list']])\n","    n_uncovered_test_items33 = len(test_items_u) - len([x for x in test_items_u if x in cart_prod_33['item_id_list']])\n","    n_uncovered_test_item_cat0s33 = len(test_item_cat_u) - len([x for x in test_item_cat_u if x in cart_prod_33['item_cat0_list']])\n","    n_uncovered_test_item_clusters33 = len(test_item_cluster_u) - len([x for x in test_item_cluster_u if x in cart_prod_33['item_cluster_list']])\n","    print(f'\\nFor query terms {cart_prod_33[\"query_conditions\"]}, for {cart_prod_33[\"start_month\"]:2d} <= month <= {cart_prod_33[\"end_month\"]:2d}:',end='')\n","    print(f' n cartesian product rows = {cart_prod_33[\"n_shop_ids\"]:2d} x {cart_prod_33[\"n_item_ids\"]:<5d} = {(cart_prod_33[\"n_shop_ids\"] * cart_prod_33[\"n_item_ids\"]):,d}')\n","    print(f'    test_missing: shops = {n_uncovered_test_shops33:2d} / {len(test_shops_u):2d}, items = {n_uncovered_test_items33:>3d} / {len(test_items_u):4d}, ',end='')\n","    print(f'item_category_ids = {n_uncovered_test_item_cat0s33:1d} / {len(test_item_cat_u):2d}, item_clusters ={n_uncovered_test_item_clusters33:3d} / {len(test_item_cluster_u):4d}',end='')\n","    if n_uncovered_test_shops33 == 0:\n","        print(f', n test rows = {n_uncovered_test_items33:>4d} x {len(test_shops_u):2d} = {(len(test_shops_u)*n_uncovered_test_items33):,d} / {(len(test_shops_u)*len(test_items_u)):,d}')\n","    else:\n","        print('')\n","    \n","\n","stt_rows_by_month = {}\n","stt_rows_in_cp = {}\n","cp_rows_in_stt = {}\n","cp_rows_not_in_stt = {}\n","total_rows_after_cp_merge = {}\n","stt_rolling_totals_before_cp_merge = {0:0}\n","stt_rolling_totals_after_cp_merge = {0:0}\n","cpshops = cart_prod['shop_id_list']\n","cpitems = cart_prod['item_id_list']\n","n_cptuples = cart_prod['n_shop_ids'] * cart_prod['n_item_ids']\n","print(\"\\nComputation completed for month:\",end='')\n","for m in range(35):\n","    stt_rows_by_month[m] = len(stt[stt.month == m])\n","    m_stt_in_cp = stt[stt.month == m].query(\"(shop_id in @cpshops) & (item_id in @cpitems)\")\n","    stt_rows_in_cp[m] = len(m_stt_in_cp)\n","    m_unique_shop_item_pairs_in_STTandCP = set(m_stt_in_cp.apply(lambda row: (row.shop_id, row.item_id), axis = 1).to_list())\n","    cp_rows_in_stt[m] = len(m_unique_shop_item_pairs_in_STTandCP)\n","    cp_rows_not_in_stt[m] = (n_cptuples - cp_rows_in_stt[m]) * (m < 34)  # we won't be merging cartesian product into month 34\n","    total_rows_after_cp_merge[m] = stt_rows_in_cp[m] + cp_rows_not_in_stt[m]\n","    stt_rolling_totals_before_cp_merge[m+1] = stt_rolling_totals_before_cp_merge[m] + stt_rows_by_month[m]\n","    stt_rolling_totals_after_cp_merge[m+1] = stt_rolling_totals_after_cp_merge[m] + total_rows_after_cp_merge[m]\n","    print(f' {m},',end='')\n","print(' done')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 15 <= month <= 33: n cartesian product rows = 52 x 15545 = 808,340\n","    test_missing: shops =  0 / 42, items = 393 / 5100, item_category_ids = 1 / 62, item_clusters =  8 / 1218, n test rows =  393 x 42 = 16,506 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 17 <= month <= 33: n cartesian product rows = 52 x 14628 = 760,656\n","    test_missing: shops =  0 / 42, items = 405 / 5100, item_category_ids = 1 / 62, item_clusters =  8 / 1218, n test rows =  405 x 42 = 17,010 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 19 <= month <= 33: n cartesian product rows = 52 x 13472 = 700,544\n","    test_missing: shops =  0 / 42, items = 430 / 5100, item_category_ids = 1 / 62, item_clusters =  9 / 1218, n test rows =  430 x 42 = 18,060 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 21 <= month <= 33: n cartesian product rows = 52 x 12573 = 653,796\n","    test_missing: shops =  0 / 42, items = 454 / 5100, item_category_ids = 1 / 62, item_clusters = 10 / 1218, n test rows =  454 x 42 = 19,068 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 23 <= month <= 33: n cartesian product rows = 52 x 11726 = 609,752\n","    test_missing: shops =  0 / 42, items = 466 / 5100, item_category_ids = 1 / 62, item_clusters = 12 / 1218, n test rows =  466 x 42 = 19,572 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 25 <= month <= 33: n cartesian product rows = 49 x 10718 = 525,182\n","    test_missing: shops =  0 / 42, items = 493 / 5100, item_category_ids = 1 / 62, item_clusters = 19 / 1218, n test rows =  493 x 42 = 20,706 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 27 <= month <= 33: n cartesian product rows = 48 x 9389  = 450,672\n","    test_missing: shops =  0 / 42, items = 535 / 5100, item_category_ids = 1 / 62, item_clusters = 28 / 1218, n test rows =  535 x 42 = 22,470 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 29 <= month <= 33: n cartesian product rows = 45 x 8368  = 376,560\n","    test_missing: shops =  0 / 42, items = 600 / 5100, item_category_ids = 1 / 62, item_clusters = 31 / 1218, n test rows =  600 x 42 = 25,200 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 23 <= month <= 33: n cartesian product rows = 52 x 11726 = 609,752\n","    test_missing: shops =  0 / 42, items = 466 / 5100, item_category_ids = 1 / 62, item_clusters = 12 / 1218, n test rows =  466 x 42 = 19,572 / 214,200\n","\n","Computation completed for month: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, done\n","CPU times: user 1min 20s, sys: 84.1 ms, total: 1min 20s\n","Wall time: 1min 20s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pCyzZ8jskoW8","colab_type":"text"},"source":["####As seen above, we only reduce the cartesian product size significantly if we restrict ourselves to selecting only recent-month attributes to evaluate for correlation with test shops and items.  I'm going to choose months 23-34 for determining what shops and items will make up the cartesian product.  It seems like a good range of months for compromise between size of eventual dataset and the number of test items that match with a correlated feature present in the original sales_train dataset."]},{"cell_type":"code","metadata":{"id":"bfSXA7FO8c_x","colab_type":"code","colab":{}},"source":["# compute aggregate values\n","total_additional_rows = sum(cp_rows_not_in_stt.values())\n","total_additional_rows_from_fillstart = sum(dict((key, cp_rows_not_in_stt[key]) for key in range(CART_FILL_MO_START,35)).values())\n","total_pre_merge_rows_from_fillstart = sum(dict((key, stt_rows_by_month[key]) for key in range(CART_FILL_MO_START,35)).values())\n","total_post_merge_rows_from_fillstart = sum(dict((key, total_rows_after_cp_merge[key]) for key in range(CART_FILL_MO_START,35)).values())\n","all_months_post_merge_rows = sum(total_rows_after_cp_merge.values())\n","merged_size_vs_start_month = dict((key, all_months_post_merge_rows - stt_rolling_totals_after_cp_merge[key]) for key in stt_rolling_totals_after_cp_merge)\n","# additional_rows_by_month = dict(sorted(cp_rows_not_in_stt.items()))  # if we want a nicely-sorted dict to just print the whole thing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"woCVG2amj_Ey","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"status":"ok","timestamp":1590286077888,"user_tz":240,"elapsed":165883,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"c113a4b7-3455-44fc-e4ce-ed418b890ae2"},"source":["def colprintdict(m_start,stt_rows,stt_rows_in_cp,cp_rows_in_stt,cp_rows_not_in_stt,total_rows_stt_cp_merge,stt_before_m,merged_before_m,merged_nrows_ge_m):\n","    idx_names = ['month:','stt (k)','stt in cp (k)','cp in stt (k)','cp not in stt (k)',\n","                 'stt&cp (k)','stt lt.m (k)','stt&cp lt.m (k)','stt&cp ge.m (k)']\n","    idx_width = len(max(idx_names, key = len))\n","    numbers = [list(range(35)),stt_rows,stt_rows_in_cp,cp_rows_in_stt,cp_rows_not_in_stt,total_rows_stt_cp_merge,stt_before_m,merged_before_m,merged_nrows_ge_m]\n","    col_width = 6\n","    for rowdx in range(len(idx_names)):\n","        print_row = f'  {idx_names[rowdx]:>{idx_width}}'\n","        for i in range(m_start,35):\n","            div = 999 * (rowdx>0) + 1  # convert everything except month number to thousands, for tighter printing\n","            print_row += f'  {(numbers[rowdx][i]//div):>{col_width},d}'\n","        print(print_row)\n","\n","print(f'\\nUnique sales_train_test... shops = {stt.shop_id.nunique()}, items = {stt.item_id.nunique()}, item_cat0s = {stt.item_cat0.nunique()}, item_clusters = {stt.item_cluster.nunique()}')\n","print(f'Number of rows in original sales_train_test dataframe: {nrows_stt:,d}, and for month 34 only, n_rows = {stt_month34_nrows:,d}')\n","\n","print(f'\\nNumber of unique \"values correlated with test set\" as computed from months {CART_CORR_MO_START} through 34:')\n","print(f'    n_unique_shops = {cart_prod[\"n_shop_ids\"]}, n_unique_items = {cart_prod[\"n_item_ids\"]}, n_unique_item_cat0s = {cart_prod[\"n_item_cat0s\"]}, n_unique_item_clusters = {cart_prod[\"n_item_clusters\"]}')\n","print(f'Cartesian product size = {cart_prod[\"n_shop_ids\"]} x {cart_prod[\"n_item_ids\"]:,d} = {(cart_prod[\"n_shop_ids\"] * cart_prod[\"n_item_ids\"]):,d}')\n","print(f'Number of rows in sales_train_test from month {CART_FILL_MO_START} through month 34, before any cartesian products:   {total_pre_merge_rows_from_fillstart:,d}')\n","print(f'Number of rows in sales_train_test from month {CART_FILL_MO_START} through month 34, after \"cartesian product\" merge: {total_post_merge_rows_from_fillstart:,d}')\n","if CART_FILL_MO_START > 0:\n","    print(f'Number of rows in sales_train_test if keeping all original stt rows, but merging cartesian product only into months {CART_FILL_MO_START} to 33: {(nrows_stt + total_additional_rows_from_fillstart):,d}\\n')\n","    print(f'Number of rows in sales_train_test if keeping original stt rows and merging cartesian product into all stt months (0 to 33): {all_months_post_merge_rows:,d}\\n')\n","print(f'Number of rows (in thousands), by month, in sales_train_test (stt) data set, and in cartesian-product (cp) set, and overlaps between the two:')\n","colprintdict(0,stt_rows_by_month, stt_rows_in_cp, cp_rows_in_stt, cp_rows_not_in_stt, total_rows_after_cp_merge, stt_rolling_totals_before_cp_merge, stt_rolling_totals_after_cp_merge, merged_size_vs_start_month)\n","print(f'\\n. ')\n","#print(f'\\nTotal number of \"cartesian product\" rows to be inserted in sales_train_test to fill from month {CART_FILL_MO_START} through month 33: {total_additional_rows:,d}')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Unique sales_train_test... shops = 55, items = 22041, item_cat0s = 84, item_clusters = 2146\n","Number of rows in original sales_train_test dataframe: 3,128,468, and for month 34 only, n_rows = 214,200\n","\n","Number of unique \"values correlated with test set\" as computed from months 23 through 34:\n","    n_unique_shops = 52, n_unique_items = 12192, n_unique_item_cat0s = 74, n_unique_item_clusters = 1848\n","Cartesian product size = 52 x 12,192 = 633,984\n","Number of rows in sales_train_test from month 10 through month 34, before any cartesian products:   2,112,571\n","Number of rows in sales_train_test from month 10 through month 34, after \"cartesian product\" merge: 16,261,410\n","Number of rows in sales_train_test if keeping all original stt rows, but merging cartesian product only into months 10 to 33: 17,389,108\n","\n","Number of rows in sales_train_test if keeping original stt rows and merging cartesian product into all stt months (0 to 33): 22,909,743\n","\n","Number of rows (in thousands), by month, in sales_train_test (stt) data set, and in cartesian-product (cp) set, and overlaps between the two:\n","             month:       0       1       2       3       4       5       6       7       8       9      10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31      32      33      34\n","            stt (k)     114     107     120      93      90      99      99     103      95      91      95     142      98      89      91      77      77      81      78      86      73      77      86     130      88      71      69      56      54      54      55      57      50      52     214\n","      stt in cp (k)      56      56      65      53      54      60      63      69      68      69      74     117      83      77      81      70      72      76      74      83      70      76      85     130      88      71      69      56      54      54      55      57      50      52     214\n","      cp in stt (k)      27      27      30      27      28      30      33      35      33      34      36      49      41      39      41      38      40      42      42      44      39      40      45      59      46      41      40      32      32      31      33      33      29      31     214\n","  cp not in stt (k)     606     606     603     606     605     603     600     598     600     599     597     584     592     594     592     595     593     591     591     589     594     593     588     574     587     592     593     601     601     602     600     600     604     602       0\n","         stt&cp (k)     663     662     669     659     660     663     663     668     668     668     672     701     675     672     674     665     665     668     665     673     665     669     674     705     675     664     663     657     656     656     656     657     654     655     214\n","       stt lt.m (k)       0     114     222     342     435     526     625     725     828     924   1,015   1,111   1,253   1,352   1,441   1,533   1,610   1,688   1,769   1,847   1,934   2,007   2,085   2,171   2,302   2,391   2,463   2,532   2,589   2,643   2,698   2,753   2,811   2,861   2,914\n","    stt&cp lt.m (k)       0     663   1,325   1,995   2,654   3,315   3,978   4,642   5,310   5,979   6,648   7,320   8,021   8,697   9,369  10,044  10,709  11,374  12,043  12,709  13,382  14,048  14,717  15,392  16,097  16,773  17,437  18,101  18,758  19,414  20,071  20,727  21,385  22,040  22,695\n","    stt&cp ge.m (k)  22,909  22,246  21,583  20,914  20,254  19,594  18,930  18,267  17,598  16,930  16,261  15,589  14,887  14,212  13,539  12,865  12,200  11,535  10,866  10,200   9,526   8,861   8,192   7,517   6,812   6,136   5,472   4,808   4,151   3,494   2,838   2,182   1,524     869     214\n","\n",". \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oS1-vtg2mHQ2"},"source":["####Based on the above numbers, and the desire to include at least a year of data before test month 34, for now I will choose to add the cartesian product rows only to months 20 - 33.  They are unhelpful in month 34, and to keep down the size of the train/val dataset, I'm guessing that months before 20 are not so relevant for evaluating the test set.</br>\n","\n","To keep things simple for now, I think I will just drop the early months or perhaps I might just prepend them them without cartesian product.  In the future, to assist more with training, I might want to ensure that shop-item pairs in a given month's sales_train data must be present in the previous 1 to 3 months, so we get better training with our time-lag features."]},{"cell_type":"code","metadata":{"id":"dL1ImnWQjNcq","colab_type":"code","colab":{}},"source":["# Here are the numbers as printed from code cells above, that helped me determine to\n","#   go with months 23-34 to determine cartesian product shops & items, and fill the cartesian product only for months 20-33\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 15 <= month <= 33: n cartesian product rows = 52 x 15545 = 808,340\n","#     test_missing: shops =  0 / 42, items = 393 / 5100, item_category_ids = 1 / 62, item_clusters =  8 / 1218, n test rows =  393 x 42 = 16,506 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 17 <= month <= 33: n cartesian product rows = 52 x 14628 = 760,656\n","#     test_missing: shops =  0 / 42, items = 405 / 5100, item_category_ids = 1 / 62, item_clusters =  8 / 1218, n test rows =  405 x 42 = 17,010 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 19 <= month <= 33: n cartesian product rows = 52 x 13472 = 700,544\n","#     test_missing: shops =  0 / 42, items = 430 / 5100, item_category_ids = 1 / 62, item_clusters =  9 / 1218, n test rows =  430 x 42 = 18,060 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 21 <= month <= 33: n cartesian product rows = 52 x 12573 = 653,796\n","#     test_missing: shops =  0 / 42, items = 454 / 5100, item_category_ids = 1 / 62, item_clusters = 10 / 1218, n test rows =  454 x 42 = 19,068 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 23 <= month <= 33: n cartesian product rows = 52 x 11726 = 609,752\n","#     test_missing: shops =  0 / 42, items = 466 / 5100, item_category_ids = 1 / 62, item_clusters = 12 / 1218, n test rows =  466 x 42 = 19,572 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 25 <= month <= 33: n cartesian product rows = 49 x 10718 = 525,182\n","#     test_missing: shops =  0 / 42, items = 493 / 5100, item_category_ids = 1 / 62, item_clusters = 19 / 1218, n test rows =  493 x 42 = 20,706 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 27 <= month <= 33: n cartesian product rows = 48 x 9389  = 450,672\n","#     test_missing: shops =  0 / 42, items = 535 / 5100, item_category_ids = 1 / 62, item_clusters = 28 / 1218, n test rows =  535 x 42 = 22,470 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 29 <= month <= 33: n cartesian product rows = 45 x 8368  = 376,560\n","#     test_missing: shops =  0 / 42, items = 600 / 5100, item_category_ids = 1 / 62, item_clusters = 31 / 1218, n test rows =  600 x 42 = 25,200 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 23 <= month <= 33: n cartesian product rows = 52 x 11726 = 609,752\n","#     test_missing: shops =  0 / 42, items = 466 / 5100, item_category_ids = 1 / 62, item_clusters = 12 / 1218, n test rows =  466 x 42 = 19,572 / 214,200\n","\n","# Unique sales_train_test... shops = 55, items = 22041, item_cat0s = 84, item_clusters = 2146\n","# Number of rows in original sales_train_test dataframe: 3,128,468, and for month 34 only, n_rows = 214,200\n","\n","# Number of unique \"values correlated with test set\" as computed from months 23 through 34:\n","#     n_unique_shops = 52, n_unique_items = 12192, n_unique_item_cat0s = 74, n_unique_item_clusters = 1848\n","# Cartesian product size = 52 x 12,192 = 633,984\n","# Number of rows in sales_train_test from month 20 through month 34, before any cartesian products:   1,194,091\n","# Number of rows in sales_train_test from month 20 through month 34, after \"cartesian product\" merge: 9,526,935\n","# Number of rows in sales_train_test if keeping all original stt rows, but merging cartesian product only into months 20 to 33: 11,466,424\n","\n","# Number of rows in sales_train_test if keeping original stt rows and merging cartesian product into all stt months (0 to 33): 22,909,743\n","\n","# Number of rows (in thousands), by month, in sales_train_test (stt) data set, and in cartesian-product (cp) set, and overlaps between the two:\n","#                    month       0       1       2       3       4       5       6       7       8       9      10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31      32      33      34\n","#          rows in stt (k)     114     107     120      93      90      99      99     103      95      91      95     142      98      89      91      77      77      81      78      86      73      77      86     130      88      71      69      56      54      54      55      57      50      52     214\n","#       rows stt in cp (k)      56      56      65      53      54      60      63      69      68      69      74     117      83      77      81      70      72      76      74      83      70      76      85     130      88      71      69      56      54      54      55      57      50      52     214\n","#       rows cp in stt (k)      27      27      30      27      28      30      33      35      33      34      36      49      41      39      41      38      40      42      42      44      39      40      45      59      46      41      40      32      32      31      33      33      29      31     214\n","#   rows cp not in stt (k)     606     606     603     606     605     603     600     598     600     599     597     584     592     594     592     595     593     591     591     589     594     593     588     574     587     592     593     601     601     602     600     600     604     602       0\n","#          rows stt&cp (k)     663     662     669     659     660     663     663     668     668     668     672     701     675     672     674     665     665     668     665     673     665     669     674     705     675     664     663     657     656     656     656     657     654     655     214\n","#        rows stt lt.m (k)       0     114     222     342     435     526     625     725     828     924   1,015   1,111   1,253   1,352   1,441   1,533   1,610   1,688   1,769   1,847   1,934   2,007   2,085   2,171   2,302   2,391   2,463   2,532   2,589   2,643   2,698   2,753   2,811   2,861   2,914\n","#     rows stt&cp lt.m (k)       0     663   1,325   1,995   2,654   3,315   3,978   4,642   5,310   5,979   6,648   7,320   8,021   8,697   9,369  10,044  10,709  11,374  12,043  12,709  13,382  14,048  14,717  15,392  16,097  16,773  17,437  18,101  18,758  19,414  20,071  20,727  21,385  22,040  22,695\n","#     rows stt&cp ge.m (k)  22,909  22,246  21,583  20,914  20,254  19,594  18,930  18,267  17,598  16,930  16,261  15,589  14,887  14,212  13,539  12,865  12,200  11,535  10,866  10,200   9,526   8,861   8,192   7,517   6,812   6,136   5,472   4,808   4,151   3,494   2,838   2,182   1,524     869     214\n","\n","# If I want to cartesian-productize the lagged months, then a start month of #20 implies I need to c-p fill down through month 17 if I use 3-month lag features, or to 14 if I use 6-month\n","# The respective dataset number of rows for 14, 17, 20 are: 13.5M, 11.5M, 9.5M"],"execution_count":null,"outputs":[]}]}