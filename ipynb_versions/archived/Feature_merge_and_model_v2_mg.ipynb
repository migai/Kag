{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Feature_merge_and_model_v2_mg.ipynb","provenance":[{"file_id":"12KA-rL8-rk29NOHJN8-DbZ8fGUESsfgV","timestamp":1589287670669},{"file_id":"1nzPRIdf4UB-3biwx8fCJlTnx8bL126aO","timestamp":1588242465890},{"file_id":"https://github.com/migai/Kag/blob/master/template_Kaggle_Coursera_Final_Assignment.ipynb","timestamp":1587141076973}],"collapsed_sections":["YPp_Nesy2yxn","hoz_AWn9XXG1","Isean25B9FjA","W7uoRFv-uSC2","dYgR5n3W9XTO","nLmjmqw1oihf","b5sECVIITIlK","Xce3Fw4tU3P9","aWEbp9hBVIqd","4kjKndgDM8Wi","PYrRXBR7S27q","nVew2KThVzWw","HprRItOZV8o6","jvSOoCGTvi1D","VvQ_hOR88pVo","oqC_Y9nHrNmy","kiRO8mgIk7nR","-yaXpG71QxcW","V_kNfg6lCCHv","eMUj_QJP1Vur","au82dd3m59n0","HNJknAGqN1K9","X-qeKYp1j5aQ","BlpasBnrxWI4","GnRD9aQF-aMp","pCyzZ8jskoW8","oS1-vtg2mHQ2"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ufy-J0xC2efV","colab_type":"text"},"source":["## First things first\n","* Click **File -> Save a copy in Drive** and click **Open in new tab** in the pop-up window to save your progress in Google Drive.\n","* Click **Runtime -> Change runtime type** and select **GPU** in Hardware accelerator box to enable faster GPU training."]},{"cell_type":"markdown","metadata":{"id":"YPp_Nesy2yxn","colab_type":"text"},"source":["#**Final Project for Coursera's 'How to Win a Data Science Competition'**\n","April, 2020\n","\n","Andreas Theodoulou and Michael Gaidis\n","\n","(Competition Info last updated:  3 years ago)"]},{"cell_type":"markdown","metadata":{"id":"r_Oe76PW3aoN","colab_type":"text"},"source":["##**About this Competition**\n","\n","You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.\n","\n","Evaluation: root mean squared error (RMSE). True target values are clipped into [0,20] range.\n","\n",".\n","\n","##**File descriptions**\n","\n","***sales_train.csv*** - the training set. Daily historical data from January 2013 to October 2015.\n","\n","***test.csv*** - the test set. You need to forecast the sales for these shops and products for November 2015.\n","\n","***sample_submission.csv*** - a sample submission file in the correct format.\n","\n","***items.csv*** - supplemental information about the items/products.\n","\n","***item_categories.csv***  - supplemental information about the items categories.\n","\n","***shops.csv***- supplemental information about the shops.\n","\n",".\n","\n","##**Data fields**\n","\n","***ID*** - an Id that represents a (Shop, Item) tuple within the test set\n","\n","***shop_id*** - unique identifier of a shop\n","\n","***item_id*** - unique identifier of a product\n","\n","***item_category_id*** - unique identifier of item category\n","\n","***item_cnt_day*** - number of products sold. You are predicting a monthly amount of this measure\n","\n","***item_price*** - current price of an item\n","\n","***date*** - date in format dd/mm/yyyy\n","\n","***month*** - a consecutive month number. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n","\n","***item_name*** - name of item\n","\n","***shop_name*** - name of shop\n","\n","***item_category_name*** - name of item category"]},{"cell_type":"markdown","metadata":{"id":"LyLQLqBcOnLt","colab_type":"text"},"source":["#**Set Up Environment and Load Files**\n","Load competition data files, import python modules, and set up pandas environment options"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RHbcGFx1sp-g"},"source":["###Name the files you wish to load"]},{"cell_type":"code","metadata":{"id":"dy5i7jl00oX-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593522273399,"user_tz":240,"elapsed":1063,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}}},"source":["# List of the *data* files (path relative to GitHub branch), to be loaded into pandas DataFrames\n","data_files = [  \n","                \"data_output/items_enc.csv\",\n","                \"data_output/shops_enc.csv\",\n","                \"data_output/date_adjustments.csv\",\n","                \"data_output/train_test_base.csv.gz\",\n","                \"readonly/final_project_data/test.csv.gz\"\n","             ]\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RKFDOiOwtJPg"},"source":["###Import Modules, Set Up Environment"]},{"cell_type":"code","metadata":{"id":"naC94KtXOnLt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593520682468,"user_tz":240,"elapsed":592,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"7c202952-a8b9-4295-f6eb-6dfe10907963"},"source":["# General python libraries/modules used throughout the notebook\n","import os\n","import feather   # this is 3x to 8x faster than pd.read_csv and pd.to_hdf, but file size is 2x hdf and 10x csv.gz\n","from itertools import product\n","from collections import OrderedDict\n","import re\n","import time\n","import datetime\n","from time import sleep, localtime, strftime, tzset, strptime\n","os.environ['TZ'] = 'EST+05EDT,M4.1.0,M10.5.0'   # allows user to simply print a formatted version of the local date and time; helps keep track of what cells were run, and when\n","tzset()   # set the time zone\n","\n","# Helpful packages for EDA, cleaning, data manipulation\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from numba import jit      # speedup for appropriate functions and datatypes (no sets, lists, dictionaries, string functions; use np arrays rather than pandas)\n","from numba import vectorize  # speed up row-wise operations like .apply() --> https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html\n","\n","# ML packages\n","from lightgbm import LGBMRegressor\n","\n","# Pandas additional enhancements / formatting\n","pd.set_option('compute.use_bottleneck', False)  # speed up operation when using NaNs\n","pd.set_option('compute.use_numexpr', False)     # speed up boolean operations, large dataframes; DataFrame.query() and pandas.eval() will evaluate the subexpressions that can be evaluated by numexpr\n","pd.set_option(\"display.max_rows\",100)     # Override pandas choice of how many rows to show, so we can see the full 84-row item_category df instead of '...' in the middle\n","pd.set_option(\"display.max_columns\",30)   # Similar to row code above, we can show more columns than default\n","pd.set_option(\"display.width\", 220)       # Tune this to our monitor window size to avoid horiz scroll bars in output windows (but, will get output text wrapping)\n","pd.set_option(\"max_colwidth\", None)       # This is done, for example, so we can see full item name and not '...' in the middle\n","# Tell pandas to print without decimal places if a number is actually an integer, and use 3 decimals if a float (helps keep column width down, and highlights data types)\n","pd.options.display.float_format = lambda x : '{:.0f}'.format(x) if round(x,0) == x else '{:,.3f}'.format(x)\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Done: Tue 08:38:01 06/30/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MY4tx3FwtVq7"},"source":["###Mount Google Drive for access to Google Drive local repo"]},{"cell_type":"code","metadata":{"id":"CUIE1PVjSAmg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593519381733,"user_tz":240,"elapsed":28305,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"ae467b05-0909-4431-f540-0c8dd8e97fcd"},"source":["# click on the URL link presented to you by this command, get your authorization code from Google, then paste it into the input box and hit 'enter' to complete mounting of the drive\n","from google.colab import drive  \n","drive.mount('/content/drive')\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hoz_AWn9XXG1"},"source":["###Load the files into pandas dataframes, from Google Drive local repo"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KD_yNYM2AE3Q","colab":{"base_uri":"https://localhost:8080/","height":680},"executionInfo":{"status":"ok","timestamp":1593522649936,"user_tz":240,"elapsed":2379,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"de2eee10-afe1-420c-a3ea-7b7c46bdf3e7"},"source":["'''\n","############################################################\n","############################################################\n","'''\n","# Replace this path with the path on *your* Google Drive where the repo master branch is stored\n","#   (on GitHub, the remote repo is located at github.com/migai/Kag --> below is my cloned repo location)\n","GDRIVE_REPO_PATH = \"/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final/Kag\"\n","'''\n","############################################################\n","############################################################\n","'''\n","\n","%cd \"{GDRIVE_REPO_PATH}\"\n","\n","print(\"Loading Files from Google Drive repo into Colab...\\n\")\n","\n","# Loop to load the data files into appropriately-named pandas DataFrames\n","for path_name in data_files:\n","    filename = path_name.rsplit(\"/\")[-1]\n","    data_frame_name = filename.split(\".\")[0]\n","    exec(data_frame_name + \" = pd.read_csv(path_name)\")\n","    print(f'Data Frame: {data_frame_name}; n_rows = {len(eval(data_frame_name))}, n_cols = ',end=\"\")\n","    print(f'{len(eval(data_frame_name).columns)}') #\\nData Types: {eval(data_frame_name).dtypes}\\n')\n","    print(f'Column Names: {eval(data_frame_name).columns.to_list()}')\n","    print(eval(data_frame_name).head(2))\n","    print(\"\\n\")\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final/Kag\n","Loading Files from Google Drive repo into Colab...\n","\n","Data Frame: items_enc; n_rows = 22170, n_cols = 10\n","Column Names: ['item_id', 'item_tested', 'item_cluster', 'item_category_id', 'item_cat_tested', 'item_group', 'item_category1', 'item_category2', 'item_category3', 'item_category4']\n","   item_id  item_tested  item_cluster  item_category_id  item_cat_tested  item_group  item_category1  item_category2  item_category3  item_category4\n","0        0            0           100                40                1           6               8               3               7               3\n","1        1            0           105                76                1           6              11               6              10               5\n","\n","\n","Data Frame: shops_enc; n_rows = 60, n_cols = 9\n","Column Names: ['shop_id', 'shop_tested', 'shop_group', 'shop_type', 's_type_broad', 'shop_federal_district', 'fd_popdens', 'fd_gdp', 'shop_city']\n","   shop_id  shop_tested  shop_group  shop_type  s_type_broad  shop_federal_district  fd_popdens  fd_gdp  shop_city\n","0        0            0           7          5             2                      1           3       1         26\n","1        1            0           7          1             0                      1           3       1         26\n","\n","\n","Data Frame: date_adjustments; n_rows = 35, n_cols = 8\n","Column Names: ['month', 'year', 'season', 'MoY', 'days_in_M', 'weekday_weight', 'retail_sales', 'week_retail_weight']\n","   month  year  season  MoY  days_in_M  weekday_weight  retail_sales  week_retail_weight\n","0      0  2013       2    1         31           0.979         1.052               1.030\n","1      1  2013       3    2         28           1.069         1.072               1.146\n","\n","\n","Data Frame: train_test_base; n_rows = 3150043, n_cols = 9\n","Column Names: ['day', 'week', 'qtr', 'season', 'month', 'price', 'sales', 'shop_id', 'item_id']\n","   day  week  qtr  season  month  price  sales  shop_id  item_id\n","0    0     0    0       2      0     99      1        2      991\n","1    0     0    0       2      0   2599      1        2     1472\n","\n","\n","Data Frame: test; n_rows = 214200, n_cols = 3\n","Column Names: ['ID', 'shop_id', 'item_id']\n","   ID  shop_id  item_id\n","0   0        5     5037\n","1   1        5     5320\n","\n","\n","Done: Tue 09:10:48 06/30/20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZA5YyPKB7QAt","colab_type":"text"},"source":["##**Define Various 'Constants' that Determine Feature Creation, Model Params, etc.**"]},{"cell_type":"code","metadata":{"id":"zLChKkFHC30j","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593526665995,"user_tz":240,"elapsed":576,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}}},"source":["# Name of file model substring to save data submission to (= False if user to input it below)\n","# model_name = 'LGBMv1p4mg_30'\n","model_name = False\n","\n","\n","# Optional list of shops to delete from training data (possibly harmful or irrelevant during training); set to False if no extra deletions:\n","SHOPS_TO_DELETE = False\n","# SHOPS_TO_DELETE = [8, 13, 23, 32, 33, 40]  # these are early-termination shops;  also, perhaps can delete [9, 20] 'online' shops\n","\n","# Optional list of item_category_ids to delete from training data (possibly harmful or irrelevant during training); set to False if no extra deletions:\n","ITEM_CATS_TO_DELETE = False\n","# ITEM_CATS_TO_DELETE = [8, 80, 81, 82]  # untested, and not closely related to other item categories;  8, 80 (= 'tickets') and probably 81,82 (= 'net carriers')\n","\n","# Optional multiplier to scale sales/month for unequal days per month, weekends per month, Russia depression; set to False if no scaling\n","SCALE_MONTH = False\n","# # SCALE_MONTH = 30/date_adjustments.days_in_M\n","# SCALE_MONTH = 'week_retail_weight'\n","\n","# Define various constants that drive the attributes of the various features\n","# not used; power-law scaling applied... ITEM_CNT_TRAIN_CLIP = 250                   # will clip item_cnt_month predictions to 20 after the model runs\n","CARTESIAN_FILL_MONTH_START = 10             # month number + max lag to start adding Cartesian product rows (i.e., maxlag=6mo and start=10 will cartesian fill from 4 to 33)\n","TRAIN_START_MONTH = CARTESIAN_FILL_MONTH_START # CART_FILL_MO_START == 24 ==> less than a year of data, but avoids December 'outlier' of 2014\n","TRAIN_FINAL_MONTH = 32   # validation data is all months after this, up to and including month 33\n","TARGET_SALES_CLIP = 20   # prediction is clipped prior to submission, per instructions\n","LAGS = [1,2] #,3,4,5,6]  # month lags to include in model \n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C-FF20AVBgih","colab_type":"text"},"source":["####**Selection of Initial Features, Enhanced Readability of DataFrames**"]},{"cell_type":"code","metadata":{"id":"1c8M1ONK7txo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593526671157,"user_tz":240,"elapsed":583,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}}},"source":["# Reduce size of DF a bit; remove features I think may not be as helpful as others\n","#    (saves memory, and makes it make it easier to read the DF when printing)\n","\n","# # column names of the loaded dataframes:\n","# items_enc_cols = ['item_id', 'item_tested', 'item_cluster', 'item_category_id', 'item_cat_tested', 'item_group', 'item_category1', 'item_category2', 'item_category3', 'item_category4']\n","# shops_enc_cols = ['shop_id', 'shop_tested', 'shop_group', 'shop_type', 's_type_broad', 'shop_federal_district', 'fd_popdens', 'fd_gdp', 'shop_city']\n","# date_adj_cols =  ['month', 'year', 'season', 'MoY', 'days_in_M', 'weekday_weight', 'retail_sales', 'week_retail_weight']\n","# train_test_base_cols = ['day', 'week', 'qtr', 'season', 'month', 'price', 'sales', 'shop_id', 'item_id']\n","# test_cols =      ['ID', 'shop_id', 'item_id']\n","\n","# columns to keep for this round of modeling (dropping some of the less important features to save memory):\n","ITEMS_KEEP_LIST = ['item_id', 'item_tested', 'item_cluster', 'item_category_id', 'item_cat_tested', 'item_group', 'item_category3']\n","SHOPS_KEEP_LIST = ['shop_id', 'shop_tested', 'shop_group', 's_type_broad', 'shop_federal_district']\n","DATE_KEEP_LIST =  ['month', 'days_in_M', 'weekday_weight', 'retail_sales', 'week_retail_weight']\n","STT_KEEP_LIST = ['month', 'price', 'sales', 'shop_id', 'item_id']  # sales-train-test dataset\n","\n","# rename columns for readability in the various dataframes\n","ITEMS_COLUMN_RENAME = { 'item_tested':'item_test', \n","                        'item_category_id':'item_cat0',\n","                        'item_cat_tested':'item_cat_test',\n","                        'item_group':'item_catA',\n","                        'item_category3_enc':'item_cat3'}\n","SHOPS_COLUMN_RENAME = { 'shop_tested':'shop_test',\n","                        'shop_group':'shop_typeA',\n","                        's_type_broad':'shop_typeB',\n","                        'shop_federal_district':'shop_fd'}\n","\n","# re-order columns for organized readability, for the (to be created) combined sales-train-test (stt) dataset\n","#    note extra column for shop_item_test will need to be created\n","STT_COLUMN_ORDER = ['month', 'shop_id', 'item_id', 'sales', 'shop_typeA', 'shop_typeB', 'shop_fd',\n","                'item_cat0', 'item_catA', 'item_cat3', 'item_cluster', 'shop_test', 'item_test','shop_item_test']\n","\n","# these columns are merged with time-lagged statistics columns\n","PRE_LAG_COLUMNS = ['month','shop_id','item_id','shop_typeA', 'shop_typeB', 'shop_fd', 'item_cat0', 'item_catA', 'item_cat3', 'item_cluster', 'shop_test', 'item_test', 'shop_item_test']\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Isean25B9FjA","colab_type":"text"},"source":["###**Helper Functions**"]},{"cell_type":"code","metadata":{"id":"tCWGzR4vl8TW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593524543862,"user_tz":240,"elapsed":599,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}}},"source":["# helper function to print out column datatypes and memory usage, using multiple columns so we don't have to scroll so much\n","def print_col_info(df,nrows=5):\n","    \"\"\"\n","    instead of the usual single column (plus index) series printout of dtypes and memory use in a dataframe,\n","    this function combines dtypes and memory use so they use the same index,\n","    and then prints out multiple columns of length \"nrows\", where each column is like: \"column_dtype \\t column_memory_use(MB) \\t column_name\"\n","        df = dataframe of interest\n","            col_dtypes = pd.Series, type obj, index = column_name, values = dtype  (e.g., from the command \"df.dtypes\")\n","            col_mem = pd.Series, type int64, index = column_name, values = column memory use (bytes) (e.g., from the command \"df.memory_usage(deep=True)\")\n","        nrows = int, tells how many rows of (type/mem/name) to print before moving to a new printout column for the next triplet (type/mem/name)\n","                if nrows == 0, print all triplets in just one column, with no \"wrapping\"\n","    finishes with a printout of total df memory usage\n","    \"\"\"\n","    col_mem = df.memory_usage(deep=True)\n","    col_mem = col_mem/1e6  #change to MB\n","    total_mem = col_mem.sum()\n","\n","    col_dtypes = pd.Series([df.index.dtype], index = ['Index'])  # df.memory_usage includes Index, but df.dtypes does not include Index, so we have to add it\n","    col_dtypes = pd.concat([col_dtypes,df.dtypes], axis=0)\n","\n","    col_info_df = pd.concat([col_dtypes, col_mem], axis=1).reset_index().rename(columns={'index':'Column Name', 0:'DType', 1:'MBytes'})\n","\n","\n","    if nrows == 0:\n","        print(col_info_df)\n","    else:\n","        col_info_df.MBytes = col_info_df.MBytes.apply(lambda x: str(f'{x:.1f}'))\n","        #col_info_df.DType = col_info_df.DType.apply(lambda x: str(x))\n","        info_df_len = len(col_info_df)\n","        cnames = col_info_df.columns\n","        n_info_cols = len(cnames)\n","        between_cols = 6  # spaces separating the info-group columns (e.g., between \"ColName Dtype Mem\" and next column \"ColName Dtype Mem\")\n","\n","        # adjust number of rows such that we don't have nasty column with just one or a few rows\n","        stragglers = info_df_len % nrows\n","        n_print_cols = info_df_len // nrows\n","        if (stragglers > nrows/2):\n","            n_print_cols += 1\n","        elif (stragglers > 0):\n","            nrows = info_df_len // n_print_cols\n","            if info_df_len % n_print_cols > 0:\n","                nrows += 1\n","\n","        df_list = []\n","        for pc in range(n_print_cols):\n","            df_list.append(col_info_df.shift(periods = -nrows*pc))\n","        df_print = pd.concat(df_list, axis = 1)\n","        df_print = df_print.iloc[:nrows][:].fillna(\" \")\n","        col_headers = df_print.columns\n","        n_df_cols = len(col_headers)\n","        \n","        # find max string length in each column\n","        columnLengths = np.vectorize(len)\n","        maxColumnLengths = columnLengths(df_print.values.astype(str)).max(axis=0)\n","        col_widths = np.add(maxColumnLengths,3)\n","\n","        for r in range(nrows+1):\n","            if r==0:\n","                string_list = col_headers\n","            else:\n","                string_list = df_print.iloc[r-1][:]\n","            print_row = ''\n","            c_count = 0\n","            for c in range(n_df_cols):\n","                print_row = print_row + f'{str(string_list[c]):>{col_widths[c]}} '\n","                c_count += 1\n","                if c_count == n_info_cols:\n","                    c_count = 0\n","                    print_row += \" \" * between_cols  # extra space between columns of common data\n","\n","            print(print_row)\n","\n","    print(f'\\nNumber of rows in DataFrame: {len(df):,d}')\n","    print(f'DataFrame total memory usage: {total_mem:.0f} MB')\n","    \n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"NnitDghzH7ni","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1593524545721,"user_tz":240,"elapsed":634,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"a9556377-37dc-45e9-e338-b521ce6d7af8"},"source":["print_col_info(train_test_base,8)  #example use of the above helper function"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Column Name      DType  MBytes       \n","     Index      int64     0.0       \n","       day      int64    25.2       \n","      week      int64    25.2       \n","       qtr      int64    25.2       \n","    season      int64    25.2       \n","     month      int64    25.2       \n","     price    float64    25.2       \n","     sales    float64    25.2       \n","   shop_id      int64    25.2       \n","   item_id      int64    25.2       \n","\n","Number of rows in DataFrame: 3,150,043\n","DataFrame total memory usage: 227 MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_Ldvqgyw0_Hw","colab_type":"text"},"source":["#**Data Preparation, Including Feature Merging and Feature Generation**"]},{"cell_type":"markdown","metadata":{"id":"fz81jlrrjz55","colab_type":"text"},"source":["##**Initial data prep, formatting**"]},{"cell_type":"markdown","metadata":{"id":"W7uoRFv-uSC2","colab_type":"text"},"source":["###**Clean up the data, drop undesirable columns, merge shops and items info into train/test dataframe**"]},{"cell_type":"code","metadata":{"id":"seucVyaI90Mt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1593527241432,"user_tz":240,"elapsed":1105,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"83220ae8-5e48-4de4-de05-3287d43b2d77"},"source":["# Clean up the shops and items dataframes\n","#    1) remove columns with features that we don't use at this time\n","#    2) rename columns to be shorter, for easier printing\n","\n","shops_purged = shops_enc[SHOPS_KEEP_LIST].rename(columns = SHOPS_COLUMN_RENAME)\n","items_purged = items_enc[ITEMS_KEEP_LIST].rename(columns = ITEMS_COLUMN_RENAME)\n","date_adj_purged = date_adjustments[DATE_KEEP_LIST].copy(deep=True)\n","stt = train_test_base[STT_KEEP_LIST].copy(deep=True)\n","\n","print(f'shops_purged dataframe length: {len(shops_purged)}\\n{shops_purged.head(2)}\\n')\n","print(f'items_purged dataframe length: {len(items_purged)}\\n{items_purged.head(2)}\\n')\n","print(f'date_adj_purged dataframe length: {len(date_adj_purged)}\\n{date_adj_purged.head(2)}\\n')\n","print(f'stt dataframe length: {len(stt)}\\n{stt.head(2)}\\n')\n","\n","del shops_enc\n","del items_enc\n","del date_adjustments\n","del train_test_base\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["shops_purged dataframe length: 60\n","   shop_id  shop_test  shop_typeA  shop_typeB  shop_fd\n","0        0          0           7           2        1\n","1        1          0           7           0        1\n","\n","items_purged dataframe length: 22170\n","   item_id  item_test  item_cluster  item_cat0  item_cat_test  item_catA  item_category3\n","0        0          0           100         40              1          6               7\n","1        1          0           105         76              1          6              10\n","\n","date_adj_purged dataframe length: 35\n","   month  days_in_M  weekday_weight  retail_sales  week_retail_weight\n","0      0         31           0.979         1.052               1.030\n","1      1         28           1.069         1.072               1.146\n","\n","stt dataframe length: 3150043\n","   month  price  sales  shop_id  item_id\n","0      0     99      1        2      991\n","1      0   2599      1        2     1472\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XA00nAC7IfWl","colab_type":"code","colab":{}},"source":["# 'stt' will be the dataframe for (S)ales of (T)rain appended with (T)est\n","\n","# Merge shops and items into stt\n","stt = stt.merge(shops_purged, on='shop_id', how='left')\n","stt = stt.merge(items_purged, on='item_id', how='left')\n","\n","# drop undesirable shops and item categories\n","# abc\n","\n","# scale by date_adjustments as desired\n","# abc\n","\n","# Add shop_item_test column to train data\n","stt['shop_item_test'] = stt.item_test * stt.shop_test\n","\n","stt = stt[STT_COLUMN_ORDER]\n","\n","# downcast to reduce memory footprint; use helper function to print the memory usage info\n","stt = stt.reset_index(drop=True).apply(pd.to_numeric,  downcast='integer')  #reset index saves 25MB\n","print('stt dataframe:')\n","print_col_info(stt,5)\n","display(stt.head(2))\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dYgR5n3W9XTO"},"source":["###**Make Adjustments to Feature Encoding**"]},{"cell_type":"code","metadata":{"id":"9AouAv5GMRwy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1590285975684,"user_tz":240,"elapsed":63793,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"344b8012-e46b-42fe-967d-db0d0d4e6172"},"source":["# Clip the values of item sales per day (will clip again after grouping by month, and then clip at 20 just before submission of results for grading)\n","# going to compress instead of clip at this time (see below)\n","#stt.sales = stt.sales.clip(0, ITEM_CNT_TRAIN_CLIP)  # eventually want to clip sales/month at 20, but it probably makes sense to let it go higher during feature generation to better separate the categories\n","\n","print(stt.describe())\n","# Let's compress \"sales\" before entering the \"group-by-month\" to bring it more in line with the final clip value\n","# basically, sales<=20 will stay the same... sales > 20 will become 20+sqrt(sales-20)\n","stt['sales'] = stt['sales'].apply(lambda x: x if x<21 else round(20+np.sqrt(x-20))).astype(np.int16)\n","print('\\n')\n","print(stt.describe())\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["        month  shop_id    item_id   sales  shop_typeA  shop_typeB  item_cat0  item_cat3  item_cat4  item_cluster  shop_test  item_test  shop_item_test\n","count 3128468  3128468    3128468 3128468     3128468     3128468    3128468    3128468    3128468       3128468    3128468    3128468         3128468\n","mean   15.930   33.334 10,237.320   1.153      38.865      54.558     40.395      5.458      4.003     2,233.285      0.845      0.528           0.461\n","std    10.335   16.215  6,321.096   2.113      10.667      15.013     17.164      2.119      1.638     2,113.508      0.362      0.499           0.498\n","min         0        2          0     -22          10          10          0          0          0            19          0          0               0\n","25%         7       22       4493       1          30          60         29          4          3           840          1          0               0\n","50%        15       31       9412       1          40          60         40          5          4          1826          1          1               0\n","75%        24       48      15705       1          50          60         55          7          5          3096          1          1               1\n","max        34       59      22169     669          50          60         83         11          7         34420          1          1               1\n","\n","\n","        month  shop_id    item_id   sales  shop_typeA  shop_typeB  item_cat0  item_cat3  item_cat4  item_cluster  shop_test  item_test  shop_item_test\n","count 3128468  3128468    3128468 3128468     3128468     3128468    3128468    3128468    3128468       3128468    3128468    3128468         3128468\n","mean   15.930   33.334 10,237.320   1.136      38.865      54.558     40.395      5.458      4.003     2,233.285      0.845      0.528           0.461\n","std    10.335   16.215  6,321.096   1.203      10.667      15.013     17.164      2.119      1.638     2,113.508      0.362      0.499           0.498\n","min         0        2          0     -22          10          10          0          0          0            19          0          0               0\n","25%         7       22       4493       1          30          60         29          4          3           840          1          0               0\n","50%        15       31       9412       1          40          60         40          5          4          1826          1          1               0\n","75%        24       48      15705       1          50          60         55          7          5          3096          1          1               1\n","max        34       59      22169      45          50          60         83         11          7         34420          1          1               1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1GXED3-jyQC7"},"source":["##**Compute and Merge Statistics-Based Features on Grouped-by-Month training data**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Jhj7bbgCceh8"},"source":["###Create monthly_stt dataframe, grouping by month the (s)ales_(t)rain_(t)est dataframe"]},{"cell_type":"code","metadata":{"id":"AghbBFHC_ljc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"ok","timestamp":1590285995202,"user_tz":240,"elapsed":83284,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"3d0ebdee-d753-4d94-a3a8-f0951e143b76"},"source":["# Compute values in real time, then in a later code cell we will compute shifted versions\n","#   With feature aggregations of sales, only using the 'sum' aggregate function (without mean or std, for example) helps to minimize memory requirements, keeping things as integers\n","\n","monthly_stt = pd.DataFrame()\n","def compute_stats(df=stt, monthly_df=monthly_stt, no_merge=True, group=['month','item_id'], stats={'sales':['sum']}, aggcolnames=['sales_by_item']):\n","    \"\"\"\n","    function for computing statistics-based features, in an attempt to be flexible if\n","    we wish to add in extra statistics or extra group-by categories\n","    \"\"\"\n","    group_df = df.groupby(group).agg(stats)\n","    group_df.columns = aggcolnames\n","    group_df.reset_index(inplace=True)\n","    if no_merge:  # this creates the initial monthly-grouped dataframe into which we will merge all other grouped statistics\n","        monthly_df = group_df.copy(deep=True)\n","    else:\n","        monthly_df = monthly_df.merge(group_df, on = group, how = 'left')\n","\n","    return monthly_df           # original monthly_df merged with aggregated and suitably named stats columns created from ungrouped dataframe (stt)\n","\n","# basic_stats are aggregate functions computed for the typical feature grouping\n","basic_stats = OrderedDict({'sales':['sum']})\n","# initial_stats is for first pass through the feature calculations (group by 'shop_item')... 7/1 changed from 'median' to 'first' for speed(?)\n","initial_stats = OrderedDict({\n","    'shop_typeA':['first'], 'shop_typeB':['first'], 'shop_fd':['first'], 'item_cat0':['first'], 'item_catA':['first'], 'item_cat3':['first'],\n","    'item_cluster':['first'], 'shop_test':['first'], 'item_test':['first'], 'shop_item_test':['first'], 'sales':['sum']}) \n","stats = OrderedDict()\n","# important: do 'shop_item' first, as it sets up configuration for all other categories to hold their values as needed\n","stats['shop_item'] = {'group':['shop_id','item_id'], 'aggstats':initial_stats,'aggnames':['_sales']}\n","# these stats below will get merged into the monthly dataframe created in the line above\n","for f in ['shop','shop_typeA','shop_typeB','shop_fd','item','item_cat0','item_catA','item_cat3','item_cluster','shop_test','item_test','shop_item_test']:\n","    stats[f] = {'group':[f],, 'aggstats':basic_stats, 'aggnames':['_sales']}\n","\n","no_merge = True\n","print('Completed: ',end='')\n","for k,v in stats.items():\n","    group = ['month'] + v['group']\n","    stats = v['aggstats']\n","    if k=='shop_item':\n","        aggnames = ['shop_typeA','shop_typeB','shop_fd','item_cat0','item_catA','item_cat3','item_cluster','shop_test','item_test','shop_item_test','y_sales']\n","        stats_col_names = ['y_sales']\n","    else:\n","        aggnames = [k+x for x in v['aggnames']]\n","        stats_col_names += aggnames\n","    monthly_stt = compute_stats(df=stt, monthly_df=monthly_stt, no_merge=no_merge, group=group, stats=stats, aggcolnames=aggnames).copy(deep=True)\n","    no_merge = False\n","    print(f'{k}, ',end='')\n","print('done')\n","\n","print(f'\\nmonthly_stt all aggregate column names: {stats_col_names}')\n","print(f'\\nmonthly_stt fully grouped and merged: memory usage before downcast = {monthly_stt.memory_usage(deep=True).sum()/1e6:.0f} MBytes')\n","\n","#Reset index and Downcast\n","monthly_stt = monthly_stt.reset_index(drop=True).apply(pd.to_numeric, downcast='integer')\n","print('\\nmonthly_stt (after reset_index and downcast):')\n","print_col_info(monthly_stt,6)\n","print('\\n')\n","print(monthly_stt.head())\n","\n","del stt\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Completed: shop_item, shop, item, item_cat0, item_cat3, item_cluster, done\n","\n","monthly_stt all aggregate column names: ['y_sales', 'shop_sales', 'item_sales', 'item_cat0_sales', 'item_cat3_sales', 'item_cluster_sales']\n","\n","monthly_stt fully grouped and merged: memory usage before downcast = 161 MBytes\n","\n","monthly_stt (after reset_index and downcast):\n","  Column Name    DType MBytes             Column Name    DType MBytes                 Column Name    DType MBytes       \n","        Index    int64    0.0               item_cat0     int8    1.8                     y_sales    int16    3.6       \n","        month     int8    1.8               item_cat3     int8    1.8                  shop_sales    int16    3.6       \n","      shop_id     int8    1.8            item_cluster    int16    3.6                  item_sales    int16    3.6       \n","      item_id    int16    3.6               shop_test     int8    1.8             item_cat0_sales    int32    7.2       \n","   shop_typeA     int8    1.8               item_test     int8    1.8             item_cat3_sales    int32    7.2       \n","   shop_typeB     int8    1.8          shop_item_test     int8    1.8          item_cluster_sales    int16    3.6       \n","\n","Number of rows in DataFrame: 1,809,624\n","DataFrame total memory usage: 52 MB\n","\n","\n","   month  shop_id  item_id  shop_typeA  shop_typeB  item_cat0  item_cat3  item_cluster  shop_test  item_test  shop_item_test  y_sales  shop_sales  item_sales  item_cat0_sales  item_cat3_sales  item_cluster_sales\n","0      0        2       27          30          60         19          4          1433          1          0               0        1        1146           7             8983            46390                 110\n","1      0        2       33          30          60         37          7          1669          1          1               1        1        1146          61             6058            42307                 354\n","2      0        2      317          30          60         45          1           110          1          0               0        1        1146           3              324             2561                  82\n","3      0        2      438          30          60         45          1           110          1          0               0        1        1146           5              324             2561                  82\n","4      0        2      471          30          60         49          1          1425          1          0               0        2        1146          31              939             2561                 236\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nLmjmqw1oihf"},"source":["##**Add Cartesian Product rows to the training data:**\n","Idea is to help the model by informing it that we explicitly have no information about certain relevant shop_item pairs in certain months."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b5sECVIITIlK"},"source":["###*Use numpy to create Cartesian Product:*\n","Each month in train data will have additional rows such that the Cartesian Product of all shops and items ALREADY PRESENT IN THAT MONTH will be included.</br>\n","\n","When we merge lagged features below, we will only forward-shift the shop-item pairs that are present in the later month.</br>\n","*(Might revisit later, if memory requirements not too big, can forward-shift all shop-item pairs.)*"]},{"cell_type":"code","metadata":{"id":"YW5giGxfrv5-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1590288307045,"user_tz":240,"elapsed":3772,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"7aa6b71b-a70a-4962-815f-e4ceb0551f07"},"source":["# Create cartesian product so model has info to look at for every relevant shop-item-month combination in the months desired\n","# add enough months of cartesian product that after time-LAGS, we end up with CartProds in months CART_FILL_MO_START through 33 (don't need to fill month 34)\n","matrix = []\n","cols = ['month','shop_id','item_id']\n","for i in range(max(CART_FILL_MO_START-max(LAGS),0),34):\n","    sales = monthly_stt[monthly_stt.month == i]\n","    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))    \n","\n","df = pd.DataFrame(np.vstack(matrix), columns=cols)\n","\n","# merge in the rows from training set with month < (CART_FILL_MO_START-max(LAGS))\n","if CART_FILL_MO_START > max(LAGS):\n","    df = monthly_stt[monthly_stt.month < (CART_FILL_MO_START-max(LAGS))][['month','shop_id','item_id']].append(df, ignore_index=True)\n","# now merge in the rows for the test set, month 34\n","df = df.append(monthly_stt[monthly_stt.month ==34][['month','shop_id','item_id']], ignore_index=True)\n","\n","df.sort_values(cols,inplace=True).reset_index(drop=True)\n","df = df.apply(pd.to_numeric, downcast='integer') # Downcast to save memory\n","\n","print(f'Column Data Types: \\n{df.dtypes}\\n')\n","print(f'Number of months: {df.month.nunique():,d}')\n","print(f'Number of shops: {df.shop_id.nunique():,d}')\n","print(f'Number of items: {df.item_id.nunique():,d}')\n","print(f'DataFrame length: {len(df):,d}\\n')\n","print(f'df memory usage: {df.memory_usage(deep=True).sum()/1e6:.0f} MBytes')\n","\n","print(f'\\nDone: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Column Data Types: \n","month       int8\n","shop_id     int8\n","item_id    int16\n","dtype: object\n","\n","Number of months: 35\n","Number of shops: 55\n","Number of items: 20,346\n","DataFrame length: 17,735,962\n","\n","df memory usage: 71 MBytes\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xce3Fw4tU3P9"},"source":["###*Merge feature info into Cartesian Product dataframe:*"]},{"cell_type":"code","metadata":{"id":"9m4TV9gY0BvP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1590288318502,"user_tz":240,"elapsed":8250,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"9991dd50-8f23-4288-d3a9-82183d6416c3"},"source":["# First, merge the shops_purged dataframe: (can't just merge with monthly_stt, because cartesian product df has more shop-item pairs)\n","df = df.merge(shops_purged, how='left', on='shop_id')\n","# Next, merge the items_purged dataframe to be sure we cover all items in the cartesian product df\n","df = df.merge(items_purged, how='left', on='item_id')\n","df['shop_item_test'] = df.shop_test * df.item_test\n","\n","df = df.reset_index(drop=True)\n","df = df.apply(pd.to_numeric, downcast='integer')\n","\n","print('Cartesian-product df (after downcast):')\n","print_col_info(df,6)\n","print(f'\\nDone: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cartesian-product df (after downcast):\n","  Column Name    DType  MBytes             Column Name    DType  MBytes       \n","        Index    int64     0.0               item_cat0     int8    17.7       \n","        month     int8    17.7            item_cluster    int16    35.5       \n","      shop_id     int8    17.7               item_cat3     int8    17.7       \n","      item_id    int16    35.5               item_cat4     int8    17.7       \n","   shop_typeA     int8    17.7               item_test     int8    17.7       \n","   shop_typeB     int8    17.7          shop_item_test     int8    17.7       \n","    shop_test     int8    17.7                                                \n","\n","Number of rows in DataFrame: 17,735,962\n","DataFrame total memory usage: 248 MB\n","CPU times: user 7.88 s, sys: 38 ms, total: 7.92 s\n","Wall time: 7.92 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aWEbp9hBVIqd"},"source":["###*Merge real-time statistics info into Cartesian Product dataframe:*"]},{"cell_type":"code","metadata":{"id":"Sv1FtGXOIhgY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1590288340665,"user_tz":240,"elapsed":14857,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"d178a732-2ef9-4e81-9b36-9fd6371bfaff"},"source":["# Now we merge in the real-time block-month data and see if memory requirements aren't overloading Colab:\n","\n","# df = df.merge(monthly_stt, how='left',on=PRE_LAG_COLUMNS).fillna(0).reset_index(drop=True) \n","df = df.merge(monthly_stt, how='left',on=PRE_LAG_COLUMNS).reset_index(drop=True)   # leave cartesian product row unknowns as N/A\n","\n","del monthly_stt\n","\n","df = df.apply(pd.to_numeric, downcast='integer')\n","\n","print('Cartesian-product df (after downcast):')\n","print_col_info(df,6)\n","print(f'\\ndf.head:\\n{df.head()}')\n","print(f'\\ndf.tail:\\n{df.tail()}')\n","\n","print(f'\\nDone: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cartesian-product df (after downcast):\n","  Column Name    DType  MBytes             Column Name    DType  MBytes                 Column Name    DType  MBytes       \n","        Index    int64     0.0               item_cat0     int8    17.7                  shop_sales    int16    35.5       \n","        month     int8    17.7            item_cluster    int16    35.5                  item_sales    int16    35.5       \n","      shop_id     int8    17.7               item_cat3     int8    17.7             item_cat0_sales    int32    70.9       \n","      item_id    int16    35.5               item_cat4     int8    17.7             item_cat3_sales    int32    70.9       \n","   shop_typeA     int8    17.7               item_test     int8    17.7          item_cluster_sales    int16    35.5       \n","   shop_typeB     int8    17.7          shop_item_test     int8    17.7                                                    \n","    shop_test     int8    17.7                 y_sales    int16    35.5                                                    \n","\n","Number of rows in DataFrame: 17,735,962\n","DataFrame total memory usage: 532 MB\n","\n","df.head:\n","   month  shop_id  item_id  shop_typeA  shop_typeB  shop_test  item_cat0  item_cluster  item_cat3  item_cat4  item_test  shop_item_test  y_sales  shop_sales  item_sales  item_cat0_sales  item_cat3_sales  item_cluster_sales\n","0      0        2       27          30          60          1         19          1433          4          6          0               0        1        1146           7             8983            46390                 110\n","1      0        2       33          30          60          1         37          1669          7          3          1               1        1        1146          61             6058            42307                 354\n","2      0        2      317          30          60          1         45           110          1          1          0               0        1        1146           3              324             2561                  82\n","3      0        2      438          30          60          1         45           110          1          1          0               0        1        1146           5              324             2561                  82\n","4      0        2      471          30          60          1         49          1425          1          1          0               0        2        1146          31              939             2561                 236\n","\n","df.tail:\n","          month  shop_id  item_id  shop_typeA  shop_typeB  shop_test  item_cat0  item_cluster  item_cat3  item_cat4  item_test  shop_item_test  y_sales  shop_sales  item_sales  item_cat0_sales  item_cat3_sales  item_cluster_sales\n","17735957     34       59    22162          40          60          1         40           278          7          3          1               1        0           0           0                0                0                   0\n","17735958     34       59    22163          40          60          1         40           278          7          3          1               1        0           0           0                0                0                   0\n","17735959     34       59    22164          40          60          1         37           278          7          3          1               1        0           0           0                0                0                   0\n","17735960     34       59    22166          40          60          1         54           848          1          5          1               1        0           0           0                0                0                   0\n","17735961     34       59    22167          40          60          1         49           848          1          1          1               1        0           0           0                0                0                   0\n","CPU times: user 14.5 s, sys: 53 ms, total: 14.5 s\n","Wall time: 14.5 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a5qlSdJFQh9H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"status":"ok","timestamp":1590288372678,"user_tz":240,"elapsed":6324,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"178a074a-4ad0-4684-9f1c-42f9997f9510"},"source":["df.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>month</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>shop_typeA</th>\n","      <th>shop_typeB</th>\n","      <th>shop_test</th>\n","      <th>item_cat0</th>\n","      <th>item_cluster</th>\n","      <th>item_cat3</th>\n","      <th>item_cat4</th>\n","      <th>item_test</th>\n","      <th>shop_item_test</th>\n","      <th>y_sales</th>\n","      <th>shop_sales</th>\n","      <th>item_sales</th>\n","      <th>item_cat0_sales</th>\n","      <th>item_cat3_sales</th>\n","      <th>item_cluster_sales</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","      <td>17735962</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>19.780</td>\n","      <td>32.192</td>\n","      <td>10,988.833</td>\n","      <td>38.500</td>\n","      <td>54.240</td>\n","      <td>0.810</td>\n","      <td>46.039</td>\n","      <td>831.484</td>\n","      <td>5.871</td>\n","      <td>3.514</td>\n","      <td>0.420</td>\n","      <td>0.342</td>\n","      <td>0.188</td>\n","      <td>267.990</td>\n","      <td>4.939</td>\n","      <td>736.689</td>\n","      <td>2,078.640</td>\n","      <td>55.890</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>8.223</td>\n","      <td>16.644</td>\n","      <td>6,446.151</td>\n","      <td>12.105</td>\n","      <td>14.419</td>\n","      <td>0.392</td>\n","      <td>16.487</td>\n","      <td>592.821</td>\n","      <td>2.238</td>\n","      <td>1.516</td>\n","      <td>0.494</td>\n","      <td>0.474</td>\n","      <td>2.094</td>\n","      <td>1,150.183</td>\n","      <td>64.416</td>\n","      <td>3,450.810</td>\n","      <td>8,115.780</td>\n","      <td>412.315</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-13</td>\n","      <td>-1</td>\n","      <td>-12</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>13</td>\n","      <td>19</td>\n","      <td>5262</td>\n","      <td>30</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>37</td>\n","      <td>296</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>20</td>\n","      <td>33</td>\n","      <td>10997</td>\n","      <td>40</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>40</td>\n","      <td>779</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>27</td>\n","      <td>47</td>\n","      <td>16398</td>\n","      <td>50</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>1313</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>34</td>\n","      <td>59</td>\n","      <td>22168</td>\n","      <td>50</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>83</td>\n","      <td>2146</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>746</td>\n","      <td>15723</td>\n","      <td>10089</td>\n","      <td>35643</td>\n","      <td>64106</td>\n","      <td>10348</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         month  shop_id    item_id  shop_typeA  shop_typeB  shop_test  item_cat0  item_cluster  item_cat3  item_cat4  item_test  shop_item_test  y_sales  shop_sales  item_sales  item_cat0_sales  item_cat3_sales  item_cluster_sales\n","count 17735962 17735962   17735962    17735962    17735962   17735962   17735962      17735962   17735962   17735962   17735962        17735962 17735962    17735962    17735962         17735962         17735962            17735962\n","mean    19.780   32.192 10,988.833      38.500      54.240      0.810     46.039       831.484      5.871      3.514      0.420           0.342    0.188     267.990       4.939          736.689        2,078.640              55.890\n","std      8.223   16.644  6,446.151      12.105      14.419      0.392     16.487       592.821      2.238      1.516      0.494           0.474    2.094   1,150.183      64.416        3,450.810        8,115.780             412.315\n","min          0        2          5          10          10          0          0             0          0          0          0               0      -13          -1         -12               -1               -1                  -1\n","25%         13       19       5262          30          60          1         37           296          4          3          0               0        0           0           0                0                0                   0\n","50%         20       33      10997          40          60          1         40           779          7          3          0               0        0           0           0                0                0                   0\n","75%         27       47      16398          50          60          1         58          1313          7          5          1               1        0           0           0                0                0                   0\n","max         34       59      22168          50          60          1         83          2146         11          7          1               1      746       15723       10089            35643            64106               10348"]},"metadata":{"tags":[]},"execution_count":310}]},{"cell_type":"markdown","metadata":{"id":"4kjKndgDM8Wi","colab_type":"text"},"source":["##**Compute and Merge the Time-Lag Features into Train + Test data sets**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PYrRXBR7S27q"},"source":["###*Set up lag options before merging:*"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3bdpJsWZW04v","colab":{}},"source":["#############################################################################\n","# This code cell determines which time-lag features we will use for each of the lags we choose (e.g., month 1 lag might use all stats, and month 6 lag might use only shop_item_sales stats)\n","#\n","# Actual choices of what month lags to use is defined above with other \"constants\" in the variable list LAGS\n","#############################################################################\n","\n","columns_to_lag = {}\n","lagged_col_names = {}\n","\n","for i in range(1,13):  # for now, just set up for possible lags from 1 month to 12 months\n","    columns_to_lag[i] = stats_col_names  # include all stats columns in all lag months for simplicity now; can in future reduce this list for longer delays, e.g., to reduce memory requirements\n","    suffix = '_L'+str(i)\n","    lagged_col_names[i] = [x + suffix for x in columns_to_lag[i]]\n","\n","lag_merge_on_cols = ['month','shop_id','item_id']\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nVew2KThVzWw"},"source":["###*Merge lag stats and check dataframe memory requirements:*"]},{"cell_type":"code","metadata":{"id":"i4SxT9QYbkWK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":768},"executionInfo":{"status":"ok","timestamp":1590288417670,"user_tz":240,"elapsed":41377,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"9d2563b3-c745-4986-fc19-bdb1484aca17"},"source":["%%time\n","# shift the stuff and merge into df\n","#   drop any rows in t-lag that don't have matching shop-item pair at time t\n","print(f'Unlagged DataFrame length: {len(df):,d}\\n')\n","dfL = df.copy(deep=True)\n","dfL['y_target'] = df.y_sales.copy(deep=True)  # keep an unlagged version of shop_item sales per month as our training / test target value\n","for L in LAGS:\n","    cols_to_shift = lag_merge_on_cols + columns_to_lag[L]\n","    lag_df = df[cols_to_shift].copy(deep=True)  \n","    lag_df.eval('month = month + @L', inplace=True)\n","    lag_df = lag_df.rename(columns = lagged_col_names[L]).reset_index(drop=True)\n","    (print(f'Column names for lag = {L}: {lag_df.columns}'))\n","    # # Downcast to conserve memory\n","    # lag_df = lag_df.apply(pd.to_numeric, downcast='integer')\n","    dfL = dfL.merge(lag_df, on = lag_merge_on_cols, how = 'left')  # 'left' serves to discard rows from earlier month if there is no match with later month\n","\n","del df\n","\n","print(f'Lagged {L} DataFrame length: {len(dfL):,d}\\n')\n","dfL.drop(stats_col_names, axis=1, inplace=True) # remove real-time stats, as we won't have this while doing predictions\n","dfL = dfL[dfL.month >= CART_FILL_MO_START]      # remove early months that don't have full complement of lagged cartesian product info\n","dfL = dfL.reset_index(drop=True)\n","dfL = dfL.apply(pd.to_numeric, downcast='integer')  #'unsigned')\n","print('Cartesian-product with lagged features dfL (after downcast):')\n","print_col_info(dfL,8)\n","print(f'\\ndfL.head():\\n{dfL.head()}')\n","\n","print(f'\\nDone: {strftime(\"%a %X %x\")}\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Unlagged DataFrame length: 17,735,962\n","\n","Column names for lag = 1: Index(['month', 'shop_id', 'item_id', 'y_sales_L1', 'shop_sales_L1', 'item_sales_L1', 'item_cat0_sales_L1', 'item_cat3_sales_L1', 'item_cluster_sales_L1'], dtype='object')\n","Lagged 1 DataFrame length: 16,876,086\n","\n","Column names for lag = 2: Index(['month', 'shop_id', 'item_id', 'y_sales_L2', 'shop_sales_L2', 'item_sales_L2', 'item_cat0_sales_L2', 'item_cat3_sales_L2', 'item_cluster_sales_L2'], dtype='object')\n","Lagged 2 DataFrame length: 16,183,541\n","\n","Column names for lag = 3: Index(['month', 'shop_id', 'item_id', 'y_sales_L3', 'shop_sales_L3', 'item_sales_L3', 'item_cat0_sales_L3', 'item_cat3_sales_L3', 'item_cluster_sales_L3'], dtype='object')\n","Lagged 3 DataFrame length: 15,525,879\n","\n","Cartesian-product with lagged features dfL (after downcast):\n","  Column Name     DType  MBytes             Column Name     DType  MBytes                    Column Name     DType  MBytes                    Column Name     DType  MBytes       \n","        Index     int64     0.0            item_cluster    uint16    30.9                  item_sales_L1     int16    30.9             item_cat3_sales_L2    uint16    30.9       \n","        month     uint8    15.4               item_cat3     uint8    15.4             item_cat0_sales_L1    uint16    30.9          item_cluster_sales_L2     int16    30.9       \n","      shop_id     uint8    15.4               item_cat4     uint8    15.4             item_cat3_sales_L1    uint16    30.9                     y_sales_L3     int16    30.9       \n","      item_id    uint16    30.9               item_test     uint8    15.4          item_cluster_sales_L1     int16    30.9                  shop_sales_L3     int16    30.9       \n","   shop_typeA     uint8    15.4          shop_item_test     uint8    15.4                     y_sales_L2     int16    30.9                  item_sales_L3     int16    30.9       \n","   shop_typeB     uint8    15.4                y_target     int16    30.9                  shop_sales_L2     int16    30.9             item_cat0_sales_L3    uint16    30.9       \n","    shop_test     uint8    15.4              y_sales_L1     int16    30.9                  item_sales_L2     int16    30.9             item_cat3_sales_L3    uint16    30.9       \n","    item_cat0     uint8    15.4           shop_sales_L1     int16    30.9             item_cat0_sales_L2    uint16    30.9          item_cluster_sales_L3     int16    30.9       \n","\n","Number of rows in DataFrame: 15,429,816\n","DataFrame total memory usage: 802 MB\n","\n","dfL.head:\n","   month  shop_id  item_id  shop_typeA  shop_typeB  shop_test  item_cat0  item_cluster  item_cat3  item_cat4  item_test  shop_item_test  y_target  y_sales_L1  shop_sales_L1  ...  item_cat0_sales_L1  item_cat3_sales_L1  item_cluster_sales_L1  \\\n","0     10       42    17279          50          60          1         37             4          7          3          1               1         0           0              0  ...                   0                   0                      0   \n","1     10       42    17315          50          60          1         40          2006          7          3          0               0         0           0              0  ...                   0                   0                      0   \n","2     10       42    17302          50          60          1         37             4          7          3          1               1         0           1           4304  ...                6883               32884                    840   \n","3     10       42    17717          50          60          1         79          1448          0          0          1               1         0           3           4304  ...                  57                2654                    177   \n","4     10       42    17322          50          60          1         40             5          7          3          0               0         2           2           4304  ...               23682               32884                   3157   \n","\n","   y_sales_L2  shop_sales_L2  item_sales_L2  item_cat0_sales_L2  item_cat3_sales_L2  item_cluster_sales_L2  y_sales_L3  shop_sales_L3  item_sales_L3  item_cat0_sales_L3  item_cat3_sales_L3  item_cluster_sales_L3  \n","0           0              0              0                   0                   0                      0           1           4032              7                8592               34839                   1689  \n","1           0              0              0                   0                   0                      0           0              0              0                   0                   0                      0  \n","2           1           4754             12                7583               32644                   1327           0              0              0                   0                   0                      0  \n","3           2           4754             52                  52                2609                    229           0              0              0                   0                   0                      0  \n","4           0              0              0                   0                   0                      0           1           4032             47               23711               34839                   4102  \n","\n","[5 rows x 31 columns]\n","CPU times: user 41 s, sys: 176 ms, total: 41.2 s\n","Wall time: 41.1 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jtZ0iBdUCD-Z","colab_type":"text"},"source":["#**Modeling**\n","*   Train/Val/Test split\n","*   Model Fit & Validate\n","*   Test/Submission Results\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9TJk9bzeCjqF","colab_type":"text"},"source":["##**Train/Test split**"]},{"cell_type":"code","metadata":{"id":"9YCzNW7-oHsF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1590289280388,"user_tz":240,"elapsed":58945,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"9e916578-ea2a-4a7f-ccf3-c94fc97b61d8"},"source":["data = dfL.copy(deep=True) \n","#data = data.drop(['shop_typeB','shop_test','item_test','shop_item_test','item_cat3'], axis=1)\n","data.y_target = data.y_target.clip(0,TARGET_SALES_CLIP)\n","\n","train = data.query('(month >= @TRAIN_START_MONTH) & (month <= @TRAIN_FINAL_MONTH)')\n","y_train = train['y_target']\n","y_train = y_train.reset_index(drop=True)\n","y_train = y_train.apply(pd.to_numeric, downcast='integer')\n","X_train = train.drop(['y_target'], axis=1)\n","X_train = X_train.reset_index(drop=True)\n","X_train = X_train.apply(pd.to_numeric, downcast='integer')\n","\n","val = data.query('month > 32') #'(month > (@TRAIN_FINAL_MONTH)) & (month < 34)') #\n","y_val = val['y_target']\n","y_val = y_val.reset_index(drop=True)\n","y_val = y_val.apply(pd.to_numeric, downcast='integer')\n","X_val = val.drop(['y_target'], axis=1)\n","X_val = X_val.reset_index(drop=True)\n","X_val = X_val.apply(pd.to_numeric, downcast='integer')\n","\n","X_test = data.query('month == 34').drop(['y_target'], axis=1)\n","X_test = X_test.reset_index(drop=True)\n","X_test = X_test.apply(pd.to_numeric, downcast='integer')\n","\n","print(f'y_train dtype = {y_train.dtype}')\n","print(f'y_val dtype = {y_val.dtype}\\n')\n","print('X_train:')\n","print_col_info(X_train)\n","print('\\nX_val:')\n","print_col_info(X_val)\n","print('\\nX_test:')\n","print_col_info(X_test)\n","\n","feature_names = X_train.columns\n","X_train_np = X_train.to_numpy() #(dtype = np.float16)\n","X_val_np = X_val.to_numpy() #(dtype = np.float16)\n","X_test_np = X_test.to_numpy() #(dtype = np.float16)\n","\n","print(f'\\nsize of X_train_np = {X_train_np.nbytes/(10**6):0.1f} MB')\n","\n","del X_train\n","del X_val\n","del data\n","del train\n","del val\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["y_train dtype = int64\n","y_val dtype = int64\n","\n","X_train:\n","  Column Name    DType  MBytes                 Column Name    DType  MBytes                    Column Name     DType  MBytes                    Column Name     DType  MBytes                    Column Name     DType  MBytes       \n","        Index    int64     0.0                item_cluster    int16    30.4             item_cat3_sales_L1    uint16    30.4             item_cat3_sales_L2    uint16    30.4             item_cat3_sales_L3    uint16    30.4       \n","        month     int8    15.2                   item_cat3     int8    15.2          item_cluster_sales_L1     int16    30.4          item_cluster_sales_L2     int16    30.4          item_cluster_sales_L3     int16    30.4       \n","      shop_id     int8    15.2                  y_sales_L1    int16    30.4                     y_sales_L2     int16    30.4                     y_sales_L3     int16    30.4                                                        \n","      item_id    int16    30.4               shop_sales_L1    int16    30.4                  shop_sales_L2     int16    30.4                  shop_sales_L3     int16    30.4                                                        \n","   shop_typeA     int8    15.2               item_sales_L1    int16    30.4                  item_sales_L2     int16    30.4                  item_sales_L3     int16    30.4                                                        \n","    item_cat0     int8    15.2          item_cat0_sales_L1    int16    30.4             item_cat0_sales_L2     int16    30.4             item_cat0_sales_L3     int16    30.4                                                        \n","\n","Number of rows in DataFrame: 15,215,616\n","DataFrame total memory usage: 685 MB\n","\n","X_val:\n","  Column Name    DType MBytes                 Column Name    DType MBytes                    Column Name    DType MBytes                    Column Name    DType MBytes                    Column Name    DType MBytes       \n","        Index    int64    0.0                item_cluster    int16    1.7             item_cat3_sales_L1    int16    1.7             item_cat3_sales_L2    int16    1.7             item_cat3_sales_L3    int16    1.7       \n","        month     int8    0.8                   item_cat3     int8    0.8          item_cluster_sales_L1    int16    1.7          item_cluster_sales_L2    int16    1.7          item_cluster_sales_L3    int16    1.7       \n","      shop_id     int8    0.8                  y_sales_L1    int16    1.7                     y_sales_L2    int16    1.7                     y_sales_L3    int16    1.7                                                      \n","      item_id    int16    1.7               shop_sales_L1    int16    1.7                  shop_sales_L2    int16    1.7                  shop_sales_L3    int16    1.7                                                      \n","   shop_typeA     int8    0.8               item_sales_L1    int16    1.7                  item_sales_L2    int16    1.7                  item_sales_L3    int16    1.7                                                      \n","    item_cat0     int8    0.8          item_cat0_sales_L1    int16    1.7             item_cat0_sales_L2    int16    1.7             item_cat0_sales_L3    int16    1.7                                                      \n","\n","Number of rows in DataFrame: 848,184\n","DataFrame total memory usage: 38 MB\n","\n","X_test:\n","  Column Name    DType MBytes                 Column Name    DType MBytes                    Column Name    DType MBytes                    Column Name    DType MBytes                    Column Name    DType MBytes       \n","        Index    int64    0.0                item_cluster    int16    0.4             item_cat3_sales_L1    int16    0.4             item_cat3_sales_L2    int16    0.4             item_cat3_sales_L3    int16    0.4       \n","        month     int8    0.2                   item_cat3     int8    0.2          item_cluster_sales_L1    int16    0.4          item_cluster_sales_L2    int16    0.4          item_cluster_sales_L3    int16    0.4       \n","      shop_id     int8    0.2                  y_sales_L1    int16    0.4                     y_sales_L2    int16    0.4                     y_sales_L3    int16    0.4                                                      \n","      item_id    int16    0.4               shop_sales_L1    int16    0.4                  shop_sales_L2    int16    0.4                  shop_sales_L3    int16    0.4                                                      \n","   shop_typeA     int8    0.2               item_sales_L1    int16    0.4                  item_sales_L2    int16    0.4                  item_sales_L3    int16    0.4                                                      \n","    item_cat0     int8    0.2          item_cat0_sales_L1    int16    0.4             item_cat0_sales_L2    int16    0.4             item_cat0_sales_L3    int16    0.4                                                      \n","\n","Number of rows in DataFrame: 214,200\n","DataFrame total memory usage: 10 MB\n","\n","size of X_train_np = 1521.6 MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HprRItOZV8o6","colab_type":"text"},"source":["##**LightGBM - Lightweight Gradient-Boosted Decision Tree**"]},{"cell_type":"code","metadata":{"id":"CyAnC6q2qG6w","colab_type":"code","colab":{}},"source":["%%time\n","\n","# Adjust LGBM Parameters to see if we can get a better result\n","model_lgbm = LGBMRegressor(\n","    objective='regression', \n","    boosting='gbdt',\n","    metric='rmse',\n","    device_type='cpu',\n","    verbosity=2,\n","    #output_freq=10,\n","    learning_rate=0.1,\n","    num_iterations=1000,\n","    early_stopping_round=50,\n","    feature_fraction=0.8,\n","    #min_data_per_group=100,\n","    #max_cat_to_onehot=8,\n","    #top_k=20,\n","    #max_bin=255,\n","    #min_data_in_bin=3,\n","    seed=420\n",")\n","\n","# categorical_feature=1,2,3,4,5,6  LGBM doesn't like this as a parameter\n","\n","model_lgbm.fit(X_train_np, y_train,\n","               eval_set=[(X_val_np, y_val)])\n","     \n","\n","y_pred_train, y_pred_val, y_pred_test =  model_lgbm.predict(X_train_np).clip(0,20), model_lgbm.predict(X_val_np).clip(0,20), model_lgbm.predict(X_test_np).clip(0,20)\n","train_score, val_score = sklearn.metrics.r2_score(y_train, y_pred_train), sklearn.metrics.r2_score(y_val, y_pred_val)\n","train_rmse, val_rmse = np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(sklearn.metrics.mean_squared_error(y_val, y_pred_val))\n","print(f'R^2 train =  {train_score:.4f}    R^2 val =  {val_score:.4f}')\n","print(f'RMSE train = {train_rmse:.4f}    RMSE val = {val_rmse:.4f}')\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jvSOoCGTvi1D","colab_type":"text"},"source":["#####Feature Importance"]},{"cell_type":"code","metadata":{"id":"LbszXTq0vhZ-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590287889473,"user_tz":240,"elapsed":1253,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"1e409de4-caf1-4009-aa08-c57f299a686a"},"source":["# Plot feature importance - Results Visualization\n","feature_importance = model_lgbm.feature_importances_\n","# make importances relative to max importance\n","feature_importance = 100.0 * (feature_importance / feature_importance.max())\n","sorted_idx = np.arange(feature_importance.shape[0])\n","pos = np.arange(sorted_idx.shape[0]) + .5\n","plt.figure(figsize=(14,20)) \n","plt.barh(pos, feature_importance[sorted_idx], align='center')\n","plt.yticks(pos, feature_names[sorted_idx])\n","plt.xlabel('Relative Importance')\n","plt.title('Variable Importance')\n","plt.tick_params(axis='y', which='major', labelsize = 13)\n","plt.show()\n","# plt.savefig('LGBM_feature_importance_v1.4_mg.png')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1008x1440 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"VvQ_hOR88pVo","colab_type":"text"},"source":["#####Submission prep"]},{"cell_type":"code","metadata":{"id":"YtId88q4FDPB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1590287912375,"user_tz":240,"elapsed":285,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"9cbb07f2-6ef4-4d2e-fcaf-fbe5fc1ca937"},"source":["# Merge the test predictions with IDs from the original test dataset, and keep only columns \"ID\" and \"item_cnt_month\"\n","y_pr_test_mrg = pd.DataFrame.from_dict({'item_cnt_month':y_pred_test,'shop_id':X_test.shop_id,'item_id':X_test.item_id})\n","y_pr_test_mrg = test.merge(y_pr_test_mrg, on=['shop_id','item_id'], how= 'left').reset_index(drop=True)\n","y_submission = y_pr_test_mrg.drop(['shop_id','item_id'],axis=1)\n","print(len(y_submission))\n","print(y_submission.head())\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["214200\n","   ID  item_cnt_month\n","0   0           1.203\n","1   1           1.026\n","2   2           1.384\n","3   3           1.072\n","4   4           1.051\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UpSqGEJd8oqo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590287952520,"user_tz":240,"elapsed":1016,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"c0e84f29-4784-4ab0-e30a-2a5cb1237740"},"source":["if user_input_submission_model_name:\n","    model_name = input(\"Enter the Model Name Substring for Output File Naming (like: LGBMv2mg_01 )\")\n","    \n","%cd \"{GDRIVE_REPO_PATH}\"\n","\n","y_submission.to_csv(\"./models_and_predictions/\" + model_name + '_submission.csv', index=False)\n","\n","print(f'Done: {strftime(\"%a %X %x\")}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final/Kag\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hma9PfJGRCHk","colab_type":"code","colab":{}},"source":["# Dummy cell to stop the execution so we don't run any of the random code below (if we select \"Run All\", e.g.)\n","b4 = b5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oqC_Y9nHrNmy","colab_type":"text"},"source":["#**Miscellaneous Code Snippets and Thoughts for Future Work**"]},{"cell_type":"code","metadata":{"id":"30rP_K48EY4s","colab_type":"code","colab":{}},"source":["# # save predictions for an ensemble\n","# pickle.dump(y_pred_train, open(\"./models_and_predictions/\" + model_name + '_pred_train.pickle', 'wb'))\n","# pickle.dump(y_pred_val, open(\"./models_and_predictions/\" + model_name + '_pred_val.pickle', 'wb'))\n","# pickle.dump(y_pred_test, open(\"./models_and_predictions/\" + model_name + '_pred_test.pickle', 'wb'))\n","\n","# # save the model to disk\n","# pickle.dump(model, open(\"./models_and_predictions/\" + model_name + '_model.sav', 'wb'))\n","\n"," \n","# # load the model from disk\n","# loaded_model = pickle.load(open(model_file_name, 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kiRO8mgIk7nR"},"source":["###**Force predictions = 0 for shops that have closed**"]},{"cell_type":"code","metadata":{"id":"_qwYN3cCJyRh","colab_type":"code","colab":{}},"source":["'''\n","# It looks like the average prediction for items that haven't sold in the previous 6 months before month 34\n","#   is roughly 1647 / 23982 = 0.07\n","#\n","# Let's try setting these items' predictions to 0 and see if the grader is happy\n","'''\n","\n","# Nope, this actually made things slightly worse per the coursera grader\n","\n","'''\n","nosales = y_pr_test_mrg.loc[y_pr_test_mrg['item_id'].isin(items_6mo_in_test)]\n","print(len(nosales))\n","print(nosales.item_cnt_month.sum())\n","nosales['item_cnt_month'] = 0\n","y_pr_test_mrg = y_pr_test_mrg.merge(nosales[['shop_id','item_id','item_cnt_month']], on=['shop_id','item_id'], how='left').fillna(1)\n","print(len(y_pr_test_mrg))\n","print(y_pr_test_mrg.head())\n","y_pr_test_mrg['item_cnt_month'] = 0\n","y_pr_test_mrg = y_pr_test_mrg.eval('item_cnt_month = item_cnt_month_x * item_cnt_month_y')\n","print(len(y_pr_test_mrg))\n","print(y_pr_test_mrg.head())\n","nosales = y_pr_test_mrg.loc[y_pr_test_mrg['item_id'].isin(items_6mo_in_test)]\n","print(len(nosales))\n","print(nosales.item_cnt_month.sum())\n","\n","y_submission = y_pr_test_mrg.drop(['shop_id','item_id','item_cnt_month_x','item_cnt_month_y'],axis=1)\n","print(len(y_submission))\n","print(y_submission.head())\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-yaXpG71QxcW","colab_type":"text"},"source":["####Model-Specific Feature Set\n","* Recode Ordinal-Encoded Categorical Features for similar value ranges between the features, so they will have similar weight as inputs to the model\n","* However, StandardScaler will not remove the undesired \"ordinality\" of the category coding.  In future, we need to do something like mean encoding, one-hot encoding, or dense one-hot (embedded) encoding."]},{"cell_type":"code","metadata":{"id":"8a0v1BXjRcGJ","colab_type":"code","colab":{}},"source":["#Remove categorical features unless encoded (e.g one-hot encoding) for basically any method other than a tree method (Linear Regresion, Neural Networks etc)\n","# from sklearn.preprocessing import StandardScaler\n","LinRegFeaturesToDrop= ['month', 'shop_id', 'item_id', 'item_cat0']\n","scaler =  StandardScaler()\n","\n","X_train_LinReg = scaler.fit_transform(X_train.drop(LinRegFeaturesToDrop, axis = 1))\n","X_val_LinReg = scaler.transform(X_val.drop(LinRegFeaturesToDrop, axis = 1))\n","X_test_LinReg = scaler.transform(X_test.drop(LinRegFeaturesToDrop, axis = 1))\n","feature_names_LinReg = X_train.drop(LinRegFeaturesToDrop, axis = 1).columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-Z8YXnTghQL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1589152641499,"user_tz":-60,"elapsed":5468,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"11777f06-1d1e-4519-e31d-435950719551"},"source":["feature_names = X_train.columns\n","X_train_np = X_train.to_numpy(dtype = np.float16)\n","del X_train\n","X_val_np = X_val.to_numpy(dtype = np.float16)\n","del X_val\n","X_test_np = X_test.to_numpy(dtype = np.float16)\n","del X_test\n","X_train_np.nbytes/(10**6)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["638.256072"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"markdown","metadata":{"id":"V_kNfg6lCCHv","colab_type":"text"},"source":["###**XGBoost - Gradient-Boosted Decision Tree**"]},{"cell_type":"code","metadata":{"id":"X8zOwfReTlVs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1589145927916,"user_tz":-60,"elapsed":96458,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"dd1ed91a-e025-4210-9259-873d3fde6845"},"source":["%%time\n","X_train_model, X_val_model, X_test_model = X_train_np, X_val_np, X_test_np\n","\n","model = XGBRegressor()\n","model.fit(X_train_model, y_train)\n","\n","y_pred_train, y_pred_val, y_pred_test =  model.predict(X_train_model).clip(0,20), model.predict(X_val_model).clip(0,20), model.predict(X_test_model).clip(0,20)\n","train_score, val_score = sklearn.metrics.r2_score(y_train, y_pred_train), sklearn.metrics.r2_score(y_val, y_pred_val)\n","train_rmse, val_rmse = np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(sklearn.metrics.mean_squared_error(y_val, y_pred_val))\n","print('R^2 train_score is ' + str(train_score) + 'R^2 val_score is ' + str(val_score))\n","print('RMSE train_score is ' + str(train_rmse) + 'RMSE val_score is ' + str(val_rmse))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[21:24:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","R^2 train_score is 0.09796589353051244R^2 val_score is 0.06403915444253994\n","RMSE train_score is 8.607288197126733RMSE val_score is 10.750826813311914\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DwbakC5XvxQg","colab_type":"text"},"source":["####Feature Importance and Submission of Results for XGBoost"]},{"cell_type":"code","metadata":{"id":"bkGLTm-yCQ4h","colab_type":"code","colab":{}},"source":["# Plot feature importance - Results Visualization\n","feature_importance = model.feature_importances_\n","# make importances relative to max importance\n","feature_importance = 100.0 * (feature_importance / feature_importance.max())\n","sorted_idx = np.argsort(feature_importance)\n","pos = np.arange(sorted_idx.shape[0]) + .5\n","plt.figure(figsize=(14,20)) \n","plt.barh(pos, feature_importance[sorted_idx], align='center')\n","plt.yticks(pos, feature_names[sorted_idx])\n","plt.xlabel('Relative Importance')\n","plt.title('Variable Importance')\n","plt.tick_params(axis='y', which='major', labelsize = 13)\n","plt.show()\n","plt.savefig('gbt_feature_importance_mg.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Su5SgInLCFTM","colab_type":"text"},"source":["Sumbission prep"]},{"cell_type":"code","metadata":{"id":"NdyG1LThCKu_","colab_type":"code","colab":{}},"source":["model_name = 'XGBv2'\n","\n","submission = pd.DataFrame({\n","    \"ID\": test.index, \n","    \"item_cnt_month\": y_pred_test\n","})\n","submission.to_csv(model_name + '_submission.csv', index=False)\n","\n","# save predictions for an ensemble\n","pickle.dump(y_pred_train, open(model_name + '_pred_train.pickle', 'wb'))\n","pickle.dump(y_pred_val, open(model_name + '_pred_val.pickle', 'wb'))\n","pickle.dump(y_pred_test, open(model_name + '_pred_test.pickle', 'wb'))\n","\n","# save the model to disk\n","pickle.dump(model, open(model_name + '_model.sav', 'wb'))\n","\n"," \n","# # load the model from disk\n","# loaded_model = pickle.load(open(model_file_name, 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eMUj_QJP1Vur","colab_type":"text"},"source":["###**To-Do List**"]},{"cell_type":"markdown","metadata":{"id":"YQ7tffMSSfn7","colab_type":"text"},"source":["####1. **Test/Train Split**\n","* **Don't Shuffle for now** ... Time-series data generally benefits from being fed to model without shuffling (Andreas).</br>\n","Although, I'm curious about shuffling the training/val data rows, within a given month at least, and after split.  I definitely think the val data should come from the last xx months, where xx= 1 to 6, depending on size of dataset, and month range of truncated data set.\n","* **Possible Model Split or Additional Feature**... Consider sales variance by_year or by_2years (instead of by_month) for items with low price, vs. variance for items with high price... (or, low/high sales)... sales trends could be different enough that we might benefit from adding such a feature, or from training multiple models with training/val/test data split according to the focus of each model. </br> Based on the graphics of feature importance generated by Andreas, I'm not sure this is a big issue, but if I'm understanding correctly, the std is only calculated on a monthly grouping, and not on the entire sales_train set.  The std might be more important if mean or median of 6, 12, 18, or 24 months is made into a feature.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K_Rfgp-vIkAP"},"source":["####2. **Weighting of shops and items based on recent behavior**\n","* **Explicit Forcing of Predictions = 0** for items or shops that have zero sales in the past 3, 6, or 12 months (as if the shop closed, or as if the item is no longer being sold).  Need to first check the months at 11, 12, 13 before the test month, to make sure shop opening, or item for sale is not a seasonal thing.\n","* **Weighting for shops based on integral of sales**... The thought is that Andreas' feature importance plot shows trend-based features to be of minor importance, so it may be more relevant to look at trend-based features where final month (or two or three) have zero sales vs. those that have trends without zero sales. (e.g., if zero sales for months 30-33, or if 500 sales for months 30-33, you have same trend, but would want to make very different predictions... so trend may be more relevant when combining with some knowledge about number of sales, like a feature = \"trend x total sales.\"  (i.e., the integral of sales rather than the slope of sales).  This might be simply done with pandas' \"rolling\" method.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"88vnjiHjIk5k"},"source":["####3. **Feature Adjustment**\n","* **Re-Scale the Stats-Based Features**... perhaps not important for decision tree models, but other models will probably benefit by scaling everything to the same range (perhaps int16 or uint16). Or, scale to slightly different ranges, based on intuition of feature importance.  Sales by shop_item pair per month is likely more important than sales by item_cat3 per month, yet the latter is presently substantially larger than the former.\n","* **Better encoding for categorical features**... instead of a random-ordinal encoding or a pure ordinal encoding, we should reduce the influence of encoding on feature behavior. Consider mean-encoding or sklearn.feature_extraction.FeatureHasher or TensorFlow embedded categorization to keep number of features down? Could be more memory-friendly than one-hot encoding.\n","* **Workdays and Holidays per month** ... Adjust item_cnt_day by number of days in month block; also adjust for holidays and weekends, if it is clear there are no sales on such days.  Or, give different weight to sales on weekends or holidays if we see these dominate the sales vs. if they have very few sales. (Scale by number of weekends/holidays in each month vs. Nov. 2015).  Need to do further EDA first, to see if there really is a deviation of sales on these non-standard days, probably using original dataset grouped by shop_id.</br>\n","Also need to check on monthly behavior... months like December, January, and February may behave differently than other months because of Christmas and because of the large concentration of Russian holidays.  It could make sense to scale the sales of these months so they fit better the overall trends of sales from October to March.  In this way, we feed the model a better-behaved dataset that is not overly influenced by crazy months (particularly, since we are given November as test, and will validate on \"smooth\" months like October, or Sept+Oct, or Aug+Sept+Oct... and won't be doing any test/val on crazy months)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9gjvmWf3Ilmu"},"source":["####4. **Data Memory Requirements and Model Training Time**\n","* **Expanding the Number of Rows in Test/Val**... Consider expansion of cartesian-product size and number of dataframe months being kept for test/val, if things are running quickly and without huge memory requirements.\n","* **More Categ. Features**... Consider expansion of the number of categorical generated features that are included.  I so far have only chosen a few, which I though matched with Andreas' output of feature importance.\n","* **More Stats Features**... Consider expansion of the number of stats features to be included.  I chose to use only the sum() aggregation function because it was simple to implement and understand, and matched well with Andreas' feature importance.  I could add in other stats like std, or (as described above) something like a rolling integral, or some other stat aggregation where instead of \"by_month\", it could be \"by_3mo\" or \"by_season\"\n","* **Interpolating Price for Cartesian-Product Rows**... Consider inclusion of price in the train/val/test data, where some sort of interpolation is used to fill the empty values after cartesian-product merge.  Maybe something simple like ffill or a fast algorithm.\n","* **Interpolating Sales for Cartesian-Product Rows**... Consider the case where sales_train doesn't represent *all* sales over that time period... some shop-item combinations may have nonzero sales, but were not included in the sales_train dataset for some reason.  (I don't think we were given any guarantees that sales_train was a complete representation of all sales.)  We may want to run training/val after cartesian-product merge, and see if it gives nonzero sales predictions for any of the newly-merged rows.  Then, we use these predictions, re-generate the features, and re-train the model.  Repeat as long as the model keeps getting better.  (This could also be a way to refine or interpolate for *price* if we choose to use it as a feature or feature generator.)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CuRc3tgI2BzU","colab_type":"text"},"source":["####Done:\n","* pd.cut or pd.qcut to reduce complexity of item price feature --> int16\n","* When grouping by month, use sum() for item_cnt_day, but use median() for other integer type features so the feature column will also be an integer (not sure if this is going to be strictly true, after watching how pandas behaves... I believe I saw one time where pandas gave the median as something like 100.5, to show that values 100 and 101 were equally centered in the data.  So instead of choosing one of these integer values, it may return a float.... I need to check if this can be set in the median() parameters, or if downcasting to an integer forces it to round the float properly vs. generating a crazy number or a NaN)\n","* Temporarily merge test rows into training data set before performing feature generation, so that where desirable, the feature generation is applied in a way that gives minimal \"special treatment\" to test or train sets.\n","* Convert data types and category encodings so as to use minimal memory (int8 or int16 better than int32, int64, float32, string).\n","* Similarly, focus on most important features (as determined from earlier modeling experiments by Andreas), and delete less-helpful columns to reduce memory requirements.\n","* Also, discard features (luckily mostly of secondary importance) that need to be stored with 4 or more bytes, as these features rapidly grow the dataset size.\n","* Be sure to reset_index(drop=True) as this can save many Megabytes if it had changed to the default int64. (I don't know yet exactly when pandas decides to do this... probably after something like a merge or group operation that can influence the index.  Anyhow... just be sure to reset the index when memory is of importance.)\n","* Keep dataset size down by judiciously choosing shops/items to use in cartesian-product when filling out the sparse sales_train data to better match the test set shop/item pairs.\n","* Keep number of lag features relatively small, and the number of months in the biggest lag to be reasonably small, so we can drop a significant number of early months from the training data.\n"]},{"cell_type":"markdown","metadata":{"id":"au82dd3m59n0","colab_type":"text"},"source":["###**Using Feathering to Save / Load Large Datafiles More Quickly**"]},{"cell_type":"code","metadata":{"id":"j83GHWtrz_Gy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1592357042844,"user_tz":240,"elapsed":7512,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"bda835b2-4e46-4673-a412-dbc6254617d6"},"source":["\n","import feather   # this is 3x to 8x faster than pd.read_csv and pd.to_hdf, but file size is 2x hdf and 10x csv.gz\n","\n","if not traintest_loaded:\n","    print(f'traintest dataframe creation started: {strftime(\"%a %X %x\")}\\n')\n","    traintest = clean_merge_augment()\n","\n","    # optional save file as feather type (big file; don't store inside repo) and/or csv.gz type (inside repo)\n","    %cd \"{OUT_OF_REPO_PATH}\"\n","    traintest.to_feather('traintest.ftr')\n","    print(\"traintest.ftr feather file stored on google drive, outside repo\")\n","    %cd \"{GDRIVE_REPO_PATH}\"\n","    # alternative, or, in addition, can save as csv.gz for < 100 MB storage and sync with GitHub\n","    compression_opts = dict(method='gzip',\n","                            archive_name='traintest.csv')  \n","    traintest.to_csv('data_output/traintest.csv.gz', index=False, compression=compression_opts)\n","    print(\"traintest.csv.gz file stored on google drive in data_output directory\")\n","    print(f'traintest file save done: {strftime(\"%a %X %x\")}')\n","\n","display(traintest[traintest.week == 102].tail(2))\n","\n","\n","# Reading in the feather file:\n","#  Except for fast-loading (large filesize) feather format files, \n","#   the data is coming from a public repo on GitHub at github.com/migai/Kag that has been synced to my local repo on Google Drive\n","\n","'''\n","############################################################\n","############################################################\n","'''\n","# Replace this path with the path on *your* Google Drive where the repo master branch is stored\n","#   (on GitHub, the remote repo is located at github.com/migai/Kag --> below is my cloned repo location)\n","GDRIVE_REPO_PATH = \"/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final/Kag\"\n","OUT_OF_REPO_PATH = \"/content/drive/My Drive/Colab Notebooks/NRUHSE_2_Kaggle_Coursera/final\"   # place > 100MB files here, because they won't sync with GitHub\n","\n","traintest_loaded = True   # set this to True if you plan to load the .ftr or the .csv.gz version of the traintest dataframe, and skip the calculations below that generated it\n","ftr_file_load_employed = True #False #True  # set to True if you wish to load the .ftr version or the .csv.gz version... it's faster, but its a 10x larger file, and won't work in the GitHub repo push\n","\n","\n","# if using large feather file for fast loading, use the routine here\n","#   note that this is too large to push to GitHub, so if you want to go this route, \n","#   you'll first have to load (more slowly) the 'data_output/traintest.csv.gz' file \n","#   with pandas read_csv, and then store the file as feather type (outside your local GitHub repo)\n","#   Or, you can just recreate the dataframe by running the first few code cells that do merging and data manipulation\n","# load feather files manually for now\n","if (traintest_loaded and ftr_file_load_employed):\n","    print('ftr files source directory: ', end='')\n","    %cd \"{OUT_OF_REPO_PATH}\"\n","    traintest = pd.read_feather('traintest.ftr', columns=None, use_threads=True)\n","    print(\"Loading ftr Files from Google Drive (outside repo) into Colab... \\n\\nData Frame: traintest (from ftr)\")\n","    print(traintest.head(2))\n","\n","'''\n","############################################################\n","############################################################\n","'''"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>day</th>\n","      <th>DoW</th>\n","      <th>DoM</th>\n","      <th>week</th>\n","      <th>qtr</th>\n","      <th>season</th>\n","      <th>month</th>\n","      <th>price</th>\n","      <th>sales</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_name</th>\n","      <th>it_test</th>\n","      <th>item_category_id</th>\n","      <th>item_category_name</th>\n","      <th>it_cat_test</th>\n","      <th>item_cat3</th>\n","      <th>item_cat4</th>\n","      <th>shop_name</th>\n","      <th>sh_cat</th>\n","      <th>sh_test</th>\n","      <th>district</th>\n","      <th>city</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2257039</th>\n","      <td>718</td>\n","      <td>Sat</td>\n","      <td>20</td>\n","      <td>102</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>399</td>\n","      <td>1</td>\n","      <td>59</td>\n","      <td>21970</td>\n","      <td>shar predictor soccer ball</td>\n","      <td>False</td>\n","      <td>69</td>\n","      <td>Gifts - Souvenirs</td>\n","      <td>True</td>\n","      <td>Gifts</td>\n","      <td>Gifts</td>\n","      <td>Yaroslavl shopping center \"Altair\"</td>\n","      <td>SEC</td>\n","      <td>True</td>\n","      <td>Central</td>\n","      <td>Yaroslavl</td>\n","    </tr>\n","    <tr>\n","      <th>2257040</th>\n","      <td>718</td>\n","      <td>Sat</td>\n","      <td>20</td>\n","      <td>102</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>499</td>\n","      <td>1</td>\n","      <td>59</td>\n","      <td>22060</td>\n","      <td>epic bluray dvd</td>\n","      <td>True</td>\n","      <td>37</td>\n","      <td>Movie - Blu-Ray</td>\n","      <td>True</td>\n","      <td>Movies</td>\n","      <td>Movies</td>\n","      <td>Yaroslavl shopping center \"Altair\"</td>\n","      <td>SEC</td>\n","      <td>True</td>\n","      <td>Central</td>\n","      <td>Yaroslavl</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         day  DoW  DoM  week  qtr  season  month  price  sales  shop_id  item_id                   item_name  it_test  item_category_id item_category_name  it_cat_test item_cat3 item_cat4                           shop_name  \\\n","2257039  718  Sat   20   102    8       1     23    399      1       59    21970  shar predictor soccer ball    False                69  Gifts - Souvenirs         True     Gifts     Gifts  Yaroslavl shopping center \"Altair\"   \n","2257040  718  Sat   20   102    8       1     23    499      1       59    22060             epic bluray dvd     True                37    Movie - Blu-Ray         True    Movies    Movies  Yaroslavl shopping center \"Altair\"   \n","\n","        sh_cat  sh_test district       city  \n","2257039    SEC     True  Central  Yaroslavl  \n","2257040    SEC     True  Central  Yaroslavl  "]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","traintest done: Tue 21:24:00 06/16/20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qLM6IieFK_DM","colab_type":"code","colab":{}},"source":["# import pandas as pd\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# import os\n","# data_gdrive_repo_path = '/content/drive/My Drive/Colab Notebooks'\n","# os.chdir(data_gdrive_repo_path)\n","\n","data_folder = 'models_and_predictions/'\n","filename = 'TS_Stats-Features-for-Modelling-v3_mg.feather'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8GbWiS6Ms4f","colab_type":"code","colab":{}},"source":["data = matrix[matrix['month'] >= 14]\n","data.reset_index().astype('float32').to_feather(data_folder + filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swBPhtAcM5gX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1589109267790,"user_tz":-60,"elapsed":40694,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"0183ed56-c7b6-4b28-c643-0717c155508d"},"source":["data = pd.read_feather(data_folder + filename, columns=None, use_threads=True)\n","data = data.astype({'index': np.int32}).set_index('index')\n","cols_by_types = infer_variable_types(matrix)\n","data = sort_variable_types(data, categorical_cols = cols_by_types['categorical'], numerical_cols = cols_by_types['numerical'])\n","data.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","      <th>price_mean_by_item_lag_1</th>\n","      <th>price_mean_by_item_lag_2</th>\n","      <th>price_mean_by_item_lag_3</th>\n","      <th>price_mean_by_item_lag_6</th>\n","      <th>price_mean_by_item_lag_12</th>\n","      <th>sales_mean_by_item_lag_1</th>\n","      <th>sales_mean_by_item_lag_2</th>\n","      <th>sales_mean_by_item_lag_3</th>\n","      <th>sales_mean_by_item_lag_6</th>\n","      <th>sales_mean_by_item_lag_12</th>\n","      <th>price_mean_by_shop_lag_1</th>\n","      <th>price_mean_by_shop_lag_2</th>\n","      <th>price_mean_by_shop_lag_3</th>\n","      <th>price_mean_by_shop_lag_6</th>\n","      <th>price_mean_by_shop_lag_12</th>\n","      <th>sales_mean_by_shop_lag_1</th>\n","      <th>sales_mean_by_shop_lag_2</th>\n","      <th>sales_mean_by_shop_lag_3</th>\n","      <th>sales_mean_by_shop_lag_6</th>\n","      <th>sales_mean_by_shop_lag_12</th>\n","      <th>price_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_category_lag_2</th>\n","      <th>price_mean_by_item_category_lag_3</th>\n","      <th>price_mean_by_item_category_lag_6</th>\n","      <th>price_mean_by_item_category_lag_12</th>\n","      <th>sales_mean_by_item_category_lag_1</th>\n","      <th>sales_mean_by_item_category_lag_2</th>\n","      <th>sales_mean_by_item_category_lag_3</th>\n","      <th>sales_mean_by_item_category_lag_6</th>\n","      <th>sales_mean_by_item_category_lag_12</th>\n","      <th>price_std_by_item_lag_1</th>\n","      <th>price_median_by_item_lag_1</th>\n","      <th>sales_std_by_item_lag_1</th>\n","      <th>sales_median_by_item_lag_1</th>\n","      <th>price_std_by_shop_lag_1</th>\n","      <th>price_median_by_shop_lag_1</th>\n","      <th>sales_std_by_shop_lag_1</th>\n","      <th>sales_median_by_shop_lag_1</th>\n","      <th>price_std_by_item_category_lag_1</th>\n","      <th>price_median_by_item_category_lag_1</th>\n","      <th>sales_std_by_item_category_lag_1</th>\n","      <th>sales_median_by_item_category_lag_1</th>\n","      <th>trend_price_mean_by_item_lag_1</th>\n","      <th>trend_price_mean_by_item_lag_3</th>\n","      <th>trend_price_mean_by_item_lag_6</th>\n","      <th>trend_price_mean_by_item_lag_12</th>\n","      <th>trend_sales_mean_by_item_lag_1</th>\n","      <th>trend_sales_mean_by_item_lag_3</th>\n","      <th>trend_sales_mean_by_item_lag_6</th>\n","      <th>trend_sales_mean_by_item_lag_12</th>\n","      <th>trend_price_mean_by_shop_lag_1</th>\n","      <th>trend_price_mean_by_shop_lag_3</th>\n","      <th>trend_price_mean_by_shop_lag_6</th>\n","      <th>trend_price_mean_by_shop_lag_12</th>\n","      <th>trend_sales_mean_by_shop_lag_1</th>\n","      <th>trend_sales_mean_by_shop_lag_3</th>\n","      <th>trend_sales_mean_by_shop_lag_6</th>\n","      <th>trend_sales_mean_by_shop_lag_12</th>\n","      <th>trend_price_mean_by_item_category_lag_1</th>\n","      <th>trend_price_mean_by_item_category_lag_3</th>\n","      <th>trend_price_mean_by_item_category_lag_6</th>\n","      <th>trend_price_mean_by_item_category_lag_12</th>\n","      <th>trend_sales_mean_by_item_category_lag_1</th>\n","      <th>trend_sales_mean_by_item_category_lag_3</th>\n","      <th>trend_sales_mean_by_item_category_lag_6</th>\n","      <th>trend_sales_mean_by_item_category_lag_12</th>\n","      <th>above_12m_mean_price_mean_by_item</th>\n","      <th>above_12m_mean_sales_mean_by_item</th>\n","      <th>above_12m_mean_price_mean_by_shop</th>\n","      <th>above_12m_mean_sales_mean_by_shop</th>\n","      <th>above_12m_mean_price_mean_by_item_category</th>\n","      <th>above_12m_mean_sales_mean_by_item_category</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11128045</th>\n","      <td>34</td>\n","      <td>46</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>193773</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11128046</th>\n","      <td>34</td>\n","      <td>41</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>198873</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11128047</th>\n","      <td>34</td>\n","      <td>44</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>203973</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11128048</th>\n","      <td>34</td>\n","      <td>39</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>209073</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11128049</th>\n","      <td>34</td>\n","      <td>45</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>214173</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          date_block_num  ...  above_12m_mean_sales_mean_by_item_category\n","index                     ...                                            \n","11128045              34  ...                                         1.0\n","11128046              34  ...                                         1.0\n","11128047              34  ...                                         1.0\n","11128048              34  ...                                         1.0\n","11128049              34  ...                                         1.0\n","\n","[5 rows x 78 columns]"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"markdown","metadata":{"id":"VgzkOq08BH3l","colab_type":"text"},"source":["### **Feature Generation/Engineering (Andreas' Early Work)**\n","\n","Time series features\n","*   Statistics of previous months (e.g. mean of item_price for a specific item/shop in previous months)\n","*   Trends of previous months - rate of change of the above statistics based features (e.g. rate of change of mean item_price from today to the past 3 months for a specific shop/item)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E-yulvUJukr7"},"source":["####1.2) Statistics-Based Features -- Time Lag\n","\n","> Lag them (put them in the same row/month as the one you'll be using them to predict - e.g e.g if going to use 6 month ago mean of item_price to predict item_cnt of next month, put 6 month ago mean of item_price in the same row as current month's values, used to predict next month)\n"]},{"cell_type":"code","metadata":{"id":"qNf5zht40R6f","colab_type":"code","colab":{}},"source":["for i in range(len(Stats_features_second)):\n","  matrix_lagged = lag_feature(matrix, Stats_lags, Stats_features_second[i])\n","  matrix = pd.merge(matrix, matrix_lagged, on=['month','shop_id','item_id'], how='left')\n","del matrix_lagged"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8adt0-u0UF0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1589152323916,"user_tz":-60,"elapsed":185201,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"7c878d30-ad65-40e7-c37a-a9dc6dae2530"},"source":["for i in range(len(Stats_features_third)):\n","  matrix_lagged = lag_feature(matrix, Stats_lags, Stats_features_third[i])\n","  matrix = pd.merge(matrix, matrix_lagged, on=['month','shop_id','item_id'], how='left')\n","del matrix_lagged\n","\n","fetures_to_drop = TS_features + Stats_features #features are renamed and added as a new column within the lag_features functions, so remove these one\n","matrix = matrix.drop(fetures_to_drop, axis = 1)\n","matrix = matrix.fillna(0)\n","matrix[matrix['month']==13].head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","      <th>price_mean_by_item_lag_1</th>\n","      <th>price_mean_by_item_lag_2</th>\n","      <th>price_mean_by_item_lag_3</th>\n","      <th>price_mean_by_item_lag_6</th>\n","      <th>price_mean_by_item_lag_12</th>\n","      <th>sales_sum_by_item_lag_1</th>\n","      <th>sales_sum_by_item_lag_2</th>\n","      <th>sales_sum_by_item_lag_3</th>\n","      <th>sales_sum_by_item_lag_6</th>\n","      <th>sales_sum_by_item_lag_12</th>\n","      <th>price_mean_by_shop_lag_1</th>\n","      <th>price_mean_by_shop_lag_2</th>\n","      <th>price_mean_by_shop_lag_3</th>\n","      <th>price_mean_by_shop_lag_6</th>\n","      <th>price_mean_by_shop_lag_12</th>\n","      <th>sales_sum_by_shop_lag_1</th>\n","      <th>sales_sum_by_shop_lag_2</th>\n","      <th>sales_sum_by_shop_lag_3</th>\n","      <th>sales_sum_by_shop_lag_6</th>\n","      <th>sales_sum_by_shop_lag_12</th>\n","      <th>price_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_category_lag_2</th>\n","      <th>price_mean_by_item_category_lag_3</th>\n","      <th>price_mean_by_item_category_lag_6</th>\n","      <th>price_mean_by_item_category_lag_12</th>\n","      <th>sales_sum_by_item_category_lag_1</th>\n","      <th>sales_sum_by_item_category_lag_2</th>\n","      <th>sales_sum_by_item_category_lag_3</th>\n","      <th>sales_sum_by_item_category_lag_6</th>\n","      <th>sales_sum_by_item_category_lag_12</th>\n","      <th>price_std_by_item_lag_1</th>\n","      <th>price_median_by_item_lag_1</th>\n","      <th>sales_std_by_item_lag_1</th>\n","      <th>sales_median_by_item_lag_1</th>\n","      <th>price_std_by_shop_lag_1</th>\n","      <th>price_median_by_shop_lag_1</th>\n","      <th>sales_std_by_shop_lag_1</th>\n","      <th>sales_median_by_shop_lag_1</th>\n","      <th>price_std_by_item_category_lag_1</th>\n","      <th>price_median_by_item_category_lag_1</th>\n","      <th>sales_std_by_item_category_lag_1</th>\n","      <th>sales_median_by_item_category_lag_1</th>\n","      <th>sales_mean_by_item_lag_1</th>\n","      <th>sales_mean_by_shop_lag_1</th>\n","      <th>sales_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_and_shop_lag_1</th>\n","      <th>price_std_by_item_and_shop_lag_1</th>\n","      <th>price_median_by_item_and_shop_lag_1</th>\n","      <th>sales_sum_by_item_and_shop_lag_1</th>\n","      <th>sales_mean_by_item_and_shop_lag_1</th>\n","      <th>sales_std_by_item_and_shop_lag_1</th>\n","      <th>sales_median_by_item_and_shop_lag_1</th>\n","      <th>price_mean_by_month_lag_1</th>\n","      <th>price_std_by_month_lag_1</th>\n","      <th>price_median_by_month_lag_1</th>\n","      <th>sales_sum_by_month_lag_1</th>\n","      <th>sales_mean_by_month_lag_1</th>\n","      <th>sales_std_by_month_lag_1</th>\n","      <th>sales_median_by_month_lag_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2293</th>\n","      <td>13</td>\n","      <td>2</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>1208.0</td>\n","      <td>1730.0</td>\n","      <td>1351.0</td>\n","      <td>1063.0</td>\n","      <td>1062.0</td>\n","      <td>890.0</td>\n","      <td>1322.0</td>\n","      <td>862.0</td>\n","      <td>875.0</td>\n","      <td>488.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>1419.0</td>\n","      <td>899.0</td>\n","      <td>0.528809</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.072266</td>\n","      <td>1.105469</td>\n","      <td>119.0</td>\n","      <td>0.0</td>\n","      <td>119.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2294</th>\n","      <td>13</td>\n","      <td>3</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>936.0</td>\n","      <td>1117.0</td>\n","      <td>906.0</td>\n","      <td>636.5</td>\n","      <td>724.0</td>\n","      <td>968.0</td>\n","      <td>1134.0</td>\n","      <td>970.0</td>\n","      <td>890.0</td>\n","      <td>798.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>1384.0</td>\n","      <td>598.5</td>\n","      <td>0.320557</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.057617</td>\n","      <td>1.105469</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2295</th>\n","      <td>13</td>\n","      <td>4</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>1060.0</td>\n","      <td>1129.0</td>\n","      <td>918.5</td>\n","      <td>689.0</td>\n","      <td>752.5</td>\n","      <td>1430.0</td>\n","      <td>2248.0</td>\n","      <td>1486.0</td>\n","      <td>1713.0</td>\n","      <td>2025.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>2436.0</td>\n","      <td>499.0</td>\n","      <td>0.667480</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.120117</td>\n","      <td>1.105469</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2296</th>\n","      <td>13</td>\n","      <td>5</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>885.0</td>\n","      <td>1025.0</td>\n","      <td>821.5</td>\n","      <td>580.0</td>\n","      <td>591.5</td>\n","      <td>1639.0</td>\n","      <td>2224.0</td>\n","      <td>1390.0</td>\n","      <td>1510.0</td>\n","      <td>877.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>1991.0</td>\n","      <td>399.0</td>\n","      <td>0.442139</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.099609</td>\n","      <td>1.105469</td>\n","      <td>149.0</td>\n","      <td>0.0</td>\n","      <td>149.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2297</th>\n","      <td>13</td>\n","      <td>6</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>144.75</td>\n","      <td>148.0</td>\n","      <td>144.375</td>\n","      <td>340.25</td>\n","      <td>337.75</td>\n","      <td>84.0</td>\n","      <td>89.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>208.0</td>\n","      <td>998.0</td>\n","      <td>971.0</td>\n","      <td>790.5</td>\n","      <td>657.0</td>\n","      <td>703.0</td>\n","      <td>3024.0</td>\n","      <td>5468.0</td>\n","      <td>3938.0</td>\n","      <td>3702.0</td>\n","      <td>4008.0</td>\n","      <td>252.875</td>\n","      <td>257.75</td>\n","      <td>253.25</td>\n","      <td>234.5</td>\n","      <td>252.125</td>\n","      <td>22064.0</td>\n","      <td>28592.0</td>\n","      <td>25440.0</td>\n","      <td>24128.0</td>\n","      <td>31648.0</td>\n","      <td>16.890625</td>\n","      <td>149.0</td>\n","      <td>0.349365</td>\n","      <td>1.0</td>\n","      <td>2380.0</td>\n","      <td>399.0</td>\n","      <td>0.582031</td>\n","      <td>1.0</td>\n","      <td>121.0625</td>\n","      <td>199.0</td>\n","      <td>0.457764</td>\n","      <td>1.0</td>\n","      <td>1.105469</td>\n","      <td>1.106445</td>\n","      <td>1.105469</td>\n","      <td>149.0</td>\n","      <td>0.0</td>\n","      <td>149.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>863.0</td>\n","      <td>1703.0</td>\n","      <td>399.0</td>\n","      <td>116899.0</td>\n","      <td>1.176758</td>\n","      <td>1.15918</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      date_block_num  ...  sales_median_by_month_lag_1\n","2293              13  ...                          1.0\n","2294              13  ...                          1.0\n","2295              13  ...                          1.0\n","2296              13  ...                          1.0\n","2297              13  ...                          1.0\n","\n","[5 rows x 65 columns]"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"hgmFHyzKX0EM","colab_type":"text"},"source":["####2.1) Trend-Based Features\n","\n","> Rate of change of Time series based features (mean of price or item count at past lags/months). Rates of change are calclulated for the past 1m, 3m, 6m, 12m\n","\n"]},{"cell_type":"code","metadata":{"id":"MvqHzOWVWbwv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1589152480965,"user_tz":-60,"elapsed":3045,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"2e4e8627-f7d7-4ccd-f863-9a85d295ea81"},"source":["ts = time.time()\n","trend_lags = [2, \n","              #4, 7, 13\n","              ]\n","for TS_feature in TS_features:\n","  for i in trend_lags:\n","    matrix['trend_' + TS_feature + '_lag_'+str(i-1)] = \\\n","        (matrix[TS_feature +'_lag_'+str(i)] - matrix[TS_feature + '_lag_1']) / matrix[TS_feature + '_lag_1']\n","print(time.time()-ts)\n","matrix.tail()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.1509287357330322\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","      <th>price_mean_by_item_lag_1</th>\n","      <th>price_mean_by_item_lag_2</th>\n","      <th>price_mean_by_item_lag_3</th>\n","      <th>price_mean_by_item_lag_6</th>\n","      <th>price_mean_by_item_lag_12</th>\n","      <th>sales_sum_by_item_lag_1</th>\n","      <th>sales_sum_by_item_lag_2</th>\n","      <th>sales_sum_by_item_lag_3</th>\n","      <th>sales_sum_by_item_lag_6</th>\n","      <th>sales_sum_by_item_lag_12</th>\n","      <th>price_mean_by_shop_lag_1</th>\n","      <th>price_mean_by_shop_lag_2</th>\n","      <th>price_mean_by_shop_lag_3</th>\n","      <th>price_mean_by_shop_lag_6</th>\n","      <th>price_mean_by_shop_lag_12</th>\n","      <th>sales_sum_by_shop_lag_1</th>\n","      <th>sales_sum_by_shop_lag_2</th>\n","      <th>sales_sum_by_shop_lag_3</th>\n","      <th>sales_sum_by_shop_lag_6</th>\n","      <th>sales_sum_by_shop_lag_12</th>\n","      <th>price_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_category_lag_2</th>\n","      <th>price_mean_by_item_category_lag_3</th>\n","      <th>price_mean_by_item_category_lag_6</th>\n","      <th>price_mean_by_item_category_lag_12</th>\n","      <th>sales_sum_by_item_category_lag_1</th>\n","      <th>sales_sum_by_item_category_lag_2</th>\n","      <th>sales_sum_by_item_category_lag_3</th>\n","      <th>sales_sum_by_item_category_lag_6</th>\n","      <th>sales_sum_by_item_category_lag_12</th>\n","      <th>price_std_by_item_lag_1</th>\n","      <th>price_median_by_item_lag_1</th>\n","      <th>sales_std_by_item_lag_1</th>\n","      <th>sales_median_by_item_lag_1</th>\n","      <th>price_std_by_shop_lag_1</th>\n","      <th>price_median_by_shop_lag_1</th>\n","      <th>sales_std_by_shop_lag_1</th>\n","      <th>sales_median_by_shop_lag_1</th>\n","      <th>price_std_by_item_category_lag_1</th>\n","      <th>price_median_by_item_category_lag_1</th>\n","      <th>sales_std_by_item_category_lag_1</th>\n","      <th>sales_median_by_item_category_lag_1</th>\n","      <th>sales_mean_by_item_lag_1</th>\n","      <th>sales_mean_by_shop_lag_1</th>\n","      <th>sales_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_and_shop_lag_1</th>\n","      <th>price_std_by_item_and_shop_lag_1</th>\n","      <th>price_median_by_item_and_shop_lag_1</th>\n","      <th>sales_sum_by_item_and_shop_lag_1</th>\n","      <th>sales_mean_by_item_and_shop_lag_1</th>\n","      <th>sales_std_by_item_and_shop_lag_1</th>\n","      <th>sales_median_by_item_and_shop_lag_1</th>\n","      <th>price_mean_by_month_lag_1</th>\n","      <th>price_std_by_month_lag_1</th>\n","      <th>price_median_by_month_lag_1</th>\n","      <th>sales_sum_by_month_lag_1</th>\n","      <th>sales_mean_by_month_lag_1</th>\n","      <th>sales_std_by_month_lag_1</th>\n","      <th>sales_median_by_month_lag_1</th>\n","      <th>trend_price_mean_by_item_lag_1</th>\n","      <th>trend_sales_sum_by_item_lag_1</th>\n","      <th>trend_price_mean_by_shop_lag_1</th>\n","      <th>trend_sales_sum_by_shop_lag_1</th>\n","      <th>trend_price_mean_by_item_category_lag_1</th>\n","      <th>trend_sales_sum_by_item_category_lag_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11128045</th>\n","      <td>34</td>\n","      <td>46</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>193773</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11128046</th>\n","      <td>34</td>\n","      <td>41</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>198873</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11128047</th>\n","      <td>34</td>\n","      <td>44</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>203973</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11128048</th>\n","      <td>34</td>\n","      <td>39</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>209073</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11128049</th>\n","      <td>34</td>\n","      <td>45</td>\n","      <td>12470</td>\n","      <td>0.0</td>\n","      <td>214173</td>\n","      <td>58</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          date_block_num  ...  trend_sales_sum_by_item_category_lag_1\n","11128045              34  ...                                     NaN\n","11128046              34  ...                                     NaN\n","11128047              34  ...                                     NaN\n","11128048              34  ...                                     NaN\n","11128049              34  ...                                     NaN\n","\n","[5 rows x 71 columns]"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"7QrJ-MPsv8c7","colab_type":"text"},"source":["####3.0) Inspection of Data"]},{"cell_type":"markdown","metadata":{"id":"LnTL2HwA3Kyb","colab_type":"text"},"source":["Understanding dataframe created (\"matrix\")"]},{"cell_type":"code","metadata":{"id":"wQOL4w4XhqSB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1589152504290,"user_tz":-60,"elapsed":19340,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"7ea17cb6-d60c-4a64-ec18-5dde56e682b6"},"source":["matrix = matrix.replace([np.inf, -np.inf], np.nan)\n","matrix.fillna(0, inplace=True)\n","matrix.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","      <th>price_mean_by_item_lag_1</th>\n","      <th>price_mean_by_item_lag_2</th>\n","      <th>price_mean_by_item_lag_3</th>\n","      <th>price_mean_by_item_lag_6</th>\n","      <th>price_mean_by_item_lag_12</th>\n","      <th>sales_sum_by_item_lag_1</th>\n","      <th>sales_sum_by_item_lag_2</th>\n","      <th>sales_sum_by_item_lag_3</th>\n","      <th>sales_sum_by_item_lag_6</th>\n","      <th>sales_sum_by_item_lag_12</th>\n","      <th>price_mean_by_shop_lag_1</th>\n","      <th>price_mean_by_shop_lag_2</th>\n","      <th>price_mean_by_shop_lag_3</th>\n","      <th>price_mean_by_shop_lag_6</th>\n","      <th>price_mean_by_shop_lag_12</th>\n","      <th>sales_sum_by_shop_lag_1</th>\n","      <th>sales_sum_by_shop_lag_2</th>\n","      <th>sales_sum_by_shop_lag_3</th>\n","      <th>sales_sum_by_shop_lag_6</th>\n","      <th>sales_sum_by_shop_lag_12</th>\n","      <th>price_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_category_lag_2</th>\n","      <th>price_mean_by_item_category_lag_3</th>\n","      <th>price_mean_by_item_category_lag_6</th>\n","      <th>price_mean_by_item_category_lag_12</th>\n","      <th>sales_sum_by_item_category_lag_1</th>\n","      <th>sales_sum_by_item_category_lag_2</th>\n","      <th>sales_sum_by_item_category_lag_3</th>\n","      <th>sales_sum_by_item_category_lag_6</th>\n","      <th>sales_sum_by_item_category_lag_12</th>\n","      <th>price_std_by_item_lag_1</th>\n","      <th>price_median_by_item_lag_1</th>\n","      <th>sales_std_by_item_lag_1</th>\n","      <th>sales_median_by_item_lag_1</th>\n","      <th>price_std_by_shop_lag_1</th>\n","      <th>price_median_by_shop_lag_1</th>\n","      <th>sales_std_by_shop_lag_1</th>\n","      <th>sales_median_by_shop_lag_1</th>\n","      <th>price_std_by_item_category_lag_1</th>\n","      <th>price_median_by_item_category_lag_1</th>\n","      <th>sales_std_by_item_category_lag_1</th>\n","      <th>sales_median_by_item_category_lag_1</th>\n","      <th>sales_mean_by_item_lag_1</th>\n","      <th>sales_mean_by_shop_lag_1</th>\n","      <th>sales_mean_by_item_category_lag_1</th>\n","      <th>price_mean_by_item_and_shop_lag_1</th>\n","      <th>price_std_by_item_and_shop_lag_1</th>\n","      <th>price_median_by_item_and_shop_lag_1</th>\n","      <th>sales_sum_by_item_and_shop_lag_1</th>\n","      <th>sales_mean_by_item_and_shop_lag_1</th>\n","      <th>sales_std_by_item_and_shop_lag_1</th>\n","      <th>sales_median_by_item_and_shop_lag_1</th>\n","      <th>price_mean_by_month_lag_1</th>\n","      <th>price_std_by_month_lag_1</th>\n","      <th>price_median_by_month_lag_1</th>\n","      <th>sales_sum_by_month_lag_1</th>\n","      <th>sales_mean_by_month_lag_1</th>\n","      <th>sales_std_by_month_lag_1</th>\n","      <th>sales_median_by_month_lag_1</th>\n","      <th>trend_price_mean_by_item_lag_1</th>\n","      <th>trend_sales_sum_by_item_lag_1</th>\n","      <th>trend_price_mean_by_shop_lag_1</th>\n","      <th>trend_sales_sum_by_shop_lag_1</th>\n","      <th>trend_price_mean_by_item_category_lag_1</th>\n","      <th>trend_sales_sum_by_item_category_lag_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   date_block_num  ...  trend_sales_sum_by_item_category_lag_1\n","0               0  ...                                     0.0\n","1               0  ...                                     0.0\n","2               0  ...                                     0.0\n","3               0  ...                                     0.0\n","4               0  ...                                     0.0\n","\n","[5 rows x 71 columns]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"bVaYMbcmuEb5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1589151521421,"user_tz":-60,"elapsed":731359,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"18724c80-6305-4ee3-a3b1-465a837c509a"},"source":["matrix.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_month', 'ID',\n","       'item_category_id', 'price_mean_by_item_lag_1',\n","       'price_mean_by_item_lag_2', 'price_mean_by_item_lag_3',\n","       'price_mean_by_item_lag_6', 'price_mean_by_item_lag_12',\n","       'sales_sum_by_item_lag_1', 'sales_sum_by_item_lag_2',\n","       'sales_sum_by_item_lag_3', 'sales_sum_by_item_lag_6',\n","       'sales_sum_by_item_lag_12', 'price_mean_by_shop_lag_1',\n","       'price_mean_by_shop_lag_2', 'price_mean_by_shop_lag_3',\n","       'price_mean_by_shop_lag_6', 'price_mean_by_shop_lag_12',\n","       'sales_sum_by_shop_lag_1', 'sales_sum_by_shop_lag_2',\n","       'sales_sum_by_shop_lag_3', 'sales_sum_by_shop_lag_6',\n","       'sales_sum_by_shop_lag_12', 'price_mean_by_item_category_lag_1',\n","       'price_mean_by_item_category_lag_2',\n","       'price_mean_by_item_category_lag_3',\n","       'price_mean_by_item_category_lag_6',\n","       'price_mean_by_item_category_lag_12',\n","       'sales_sum_by_item_category_lag_1', 'sales_sum_by_item_category_lag_2',\n","       'sales_sum_by_item_category_lag_3', 'sales_sum_by_item_category_lag_6',\n","       'sales_sum_by_item_category_lag_12', 'price_std_by_item_lag_1',\n","       'price_median_by_item_lag_1', 'sales_std_by_item_lag_1',\n","       'sales_median_by_item_lag_1', 'price_std_by_shop_lag_1',\n","       'price_median_by_shop_lag_1', 'sales_std_by_shop_lag_1',\n","       'sales_median_by_shop_lag_1', 'price_std_by_item_category_lag_1',\n","       'price_median_by_item_category_lag_1',\n","       'sales_std_by_item_category_lag_1',\n","       'sales_median_by_item_category_lag_1', 'sales_mean_by_item_lag_1',\n","       'sales_mean_by_shop_lag_1', 'sales_mean_by_item_category_lag_1',\n","       'price_mean_by_item_and_shop_lag_1', 'price_std_by_item_and_shop_lag_1',\n","       'price_median_by_item_and_shop_lag_1',\n","       'sales_sum_by_item_and_shop_lag_1', 'sales_mean_by_item_and_shop_lag_1',\n","       'sales_std_by_item_and_shop_lag_1',\n","       'sales_median_by_item_and_shop_lag_1', 'price_mean_by_month_lag_1',\n","       'price_std_by_month_lag_1', 'price_median_by_month_lag_1',\n","       'sales_sum_by_month_lag_1', 'sales_mean_by_month_lag_1',\n","       'sales_std_by_month_lag_1', 'sales_median_by_month_lag_1',\n","       'trend_price_mean_by_item_lag_1', 'trend_sales_sum_by_item_lag_1',\n","       'trend_price_mean_by_shop_lag_1', 'trend_sales_sum_by_shop_lag_1',\n","       'trend_price_mean_by_item_category_lag_1',\n","       'trend_sales_sum_by_item_category_lag_1'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"QBP59nqnt43y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"status":"ok","timestamp":1589151656777,"user_tz":-60,"elapsed":37533,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"outputId":"112d82e7-d609-49cc-eb39-7d072f50f00f"},"source":["df = matrix\n","df1 = df.describe(include = 'all')\n","\n","df1.loc['dtype'] = df.dtypes\n","df1.loc['size'] = len(df)\n","df1.loc['% count'] = df.isnull().mean()\n","df1.loc['%count 0'] = df.apply(lambda col: (col.count() - np.count_nonzero(col)))\n","df1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date_block_num</th>\n","      <th>shop_id</th>\n","      <th>item_id</th>\n","      <th>item_cnt_month</th>\n","      <th>ID</th>\n","      <th>item_category_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","      <td>1.11280e+07</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>15.3396</td>\n","      <td>31.196</td>\n","      <td>11303.7</td>\n","      <td>NaN</td>\n","      <td>2061.52</td>\n","      <td>44.9441</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9.7604</td>\n","      <td>17.3538</td>\n","      <td>6210.93</td>\n","      <td>0</td>\n","      <td>17033.3</td>\n","      <td>15.1401</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>7</td>\n","      <td>16</td>\n","      <td>5947</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>15</td>\n","      <td>30</td>\n","      <td>11388</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>23</td>\n","      <td>47</td>\n","      <td>16592</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>34</td>\n","      <td>59</td>\n","      <td>22169</td>\n","      <td>20</td>\n","      <td>214199</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>dtype</th>\n","      <td>int8</td>\n","      <td>int8</td>\n","      <td>int16</td>\n","      <td>float16</td>\n","      <td>int32</td>\n","      <td>int64</td>\n","    </tr>\n","    <tr>\n","      <th>size</th>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","      <td>11128050</td>\n","    </tr>\n","    <tr>\n","      <th>% count</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>%count 0</th>\n","      <td>365175</td>\n","      <td>16283</td>\n","      <td>50</td>\n","      <td>9522424</td>\n","      <td>10913851</td>\n","      <td>179</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         date_block_num      shop_id  ...           ID item_category_id\n","count       1.11280e+07  1.11280e+07  ...  1.11280e+07      1.11280e+07\n","mean            15.3396       31.196  ...      2061.52          44.9441\n","std              9.7604      17.3538  ...      17033.3          15.1401\n","min                   0            0  ...            0                0\n","25%                   7           16  ...            0               37\n","50%                  15           30  ...            0               40\n","75%                  23           47  ...            0               55\n","max                  34           59  ...       214199               83\n","dtype              int8         int8  ...        int32            int64\n","size           11128050     11128050  ...     11128050         11128050\n","% count               0            0  ...            0                0\n","%count 0         365175        16283  ...     10913851              179\n","\n","[12 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"l_RFPPPP9yr6","colab_type":"code","colab":{}},"source":["data = matrix\n","\n","use_toy_data = False #to be used just for code to run quicker when tests are needed to be made\n","if use_toy_data == True:\n","  train_start_index = 26\n","else:\n","  train_start_index = 14 #skip first 13 months - used to caclulate time series features\n","train_final_index = 28 #makes validation set to be 20% of the non-test data (threshold is surely debatable)\n","\n","data = data[data['month'] >= train_start_index]\n","\n","X_train = data[data.month <= train_final_index].drop(['item_cnt_month', 'ID'], axis=1)\n","y_train = np.array(data[data.month <= train_final_index]['item_cnt_month'])\n","\n","X_val = data[(data.month > train_final_index) & (data.month <= 33)].drop(['item_cnt_month', 'ID'], axis=1)\n","y_val = np.array(data[(data.month > train_final_index) & (data.month <= 33)]['item_cnt_month'])\n","\n","X_test = data[data.month == 34].drop(['item_cnt_month', 'ID'], axis=1)\n","X_test = pd.merge(test, X_test, on= ['month', 'item_id', 'shop_id']).drop(['ID'], axis = 1) #to ensure consistency in rows with test sumbission file\n","del data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFmSE7O4XU8r","colab_type":"code","colab":{}},"source":["#---------------------------Create Stats based features--------------------------------\n","#Stats based features = features computed based on stats of item price/cnt of shops or item for just the previous month\n","\n","ts = time.time()\n","Stats_lags = [1]\n","\n","Stats_features = [\n","                  'price_std_by_item', 'price_median_by_item',\n","                 'sales_std_by_item', 'sales_median_by_item',\n","                 'price_std_by_shop', 'price_median_by_shop',\n","                 'sales_std_by_shop', 'sales_median_by_shop',\n","                 'price_std_by_item_category', 'price_median_by_item_category',\n","                 'sales_std_by_item_category', 'sales_median_by_item_category',\n","                  'sales_mean_by_item', 'sales_mean_by_shop', 'sales_mean_by_item_category' ,\n","                  'price_mean_by_item_and_shop', 'price_std_by_item_and_shop', 'price_median_by_item_and_shop',\n","                  'sales_by_item_and_shop', 'sales_mean_by_item_and_shop', 'sales_std_by_item_and_shop', 'sales_median_by_item_and_shop',\n","                  'price_mean_by_month', 'price_std_by_month', 'price_median_by_month',\n","                  'sales_by_month', 'sales_mean_by_month', 'sales_std_by_month', 'sales_median_by_month'\n","                ]\n","                                  \n","'''\n","\n","'''\n","#Splitting Stats_features as below helped as a quick fix for the session getting crashed from running out of RAM (if GPU still crashes, use TPU for this one - has more RAM)\n","length = len(Stats_features)\n","index = length//3\n","Stats_features_first = Stats_features[:index]\n","Stats_features_second = Stats_features[index:(index*2)]\n","Stats_features_third = Stats_features[(index*2):]\n","\n","for i in range(len(Stats_features_first)):\n","  matrix_lagged = lag_feature(matrix, Stats_lags, Stats_features_first[i])\n","  matrix = pd.merge(matrix, matrix_lagged, on=['month','shop_id','item_id'], how='left')\n","del matrix_lagged\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HNJknAGqN1K9"},"source":["####4.0) Miscellaneous"]},{"cell_type":"code","metadata":{"id":"jcT_wG39WbOi","colab_type":"code","colab":{}},"source":["# Discarding price information for now, due to issues with filling cartesian product empty values\n","# # item price is overly descriptive, and requires a 4-byte storage per entry\n","# #  let's bin it down to just 127 categories, binned by quantiles, and store in int8 1-byte values\n","# #  Note: due to duplication of bin boundaries, need to set q=750 to get 200 categories (uint8); q=370 gives 127 categories (int8)\n","\n","# # # 350 --> 117, 200 --> 83 ,  500-->153,  750-->200, 370-->127\n","# # nbins, labelrange = 370, 127\n","# # i_p_binned, i_p_boundaries = pd.qcut(stt.item_price,q=nbins,precision=0,duplicates='drop',retbins=True,labels=list(range(labelrange)))\n","# # bins_table = pd.DataFrame(zip(i_p_boundaries,list(range(labelrange))),columns=['Threshold','Label'])\n","# # ipbins=i_p_binned.value_counts()\n","# # bins_table['bin_counts'] = bins_table.Label.apply(lambda x: ipbins.loc[x] if x in ipbins.index else 0)\n","# # bar = bins_table.iloc[:][:].plot.bar(x='Threshold',y='bin_counts',figsize=(20,8))\n","\n","# N_BINS = 370  # will return only 127 bins, due to data distribution causing bin overlap\n","\n","# price_binned = pd.qcut(stt.price[stt.month < 34], q=N_BINS, precision=0, duplicates='drop', labels=False)\n","# testbins = pd.Series(np.zeros((TEST_LENGTH), dtype=np.int8))\n","# price_binned = price_binned.append(testbins, ignore_index=True)\n","# stt.price = price_binned.astype(np.int8)\n","# print(stt.head(2))\n","# print(stt.tail(2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QerShYfcQXAD","colab_type":"code","colab":{}},"source":["# In future, this is some thinking on how one might interpolate prices into empty cartesian-product rows\n","# skip this; we are leaving out the \"price\" feature for now\n","\n","# Compute 'price' feature for month=34 (test set) and any cartesian-product empties\n","#  use most recent monthly 'price' median for shop_item pair = month 34 shop-item pair\n","#  use monthly 'price' median by item if shop-item pair is not in months 0-33\n","#  use monthly 'price' median by shop_item_cluster if item is not in months 0-33\n","#  use monthly 'price' median by item_cluster if shop_item_cluster is not in months 0-33\n","#  use monthly 'price' median by shop_item_cat if item_cluster is not in months 0-33\n","#  use monthly 'price' median by item_cat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"omEWIciMxBmI","colab_type":"code","colab":{}},"source":["# DESIRED_DTYPES = ['ID               int32   index value from test data set; drop before model training if desired (= 0 for all train data)',\n","#                   'month            int8\tordinal-encoded month # from start of train data',\n","#                   'shop_id\t        int8\tcategorical range(60) original shop_id values, minus 0,1,9,11,13',\n","#                   'item_id\t        int16\tcategorical range(22170) original item_id values, 21671 present in sales_train_cln_mrg',\n","#                   'price\t        int8\tcontinuous (binned) variable, downcast from float64; price is in range (0 to 59200]',\n","#                   'item_cnt_day     int8   continuous variable, items sold that day at that shop, after clipping to 120 or some other desired value',\n","#                   'sales            int8   continuous variable, items sold that day at that shop, after clipping to 120 or some other desired value',\n","#                   'item_cnt_month\tint16\tcontinuous variable, items sold during the month at that shop, max value = 120 * 31days = int16; clip to 20 after model transform is applied',\n","#                   'sales_month  \tint16\tcontinuous variable, items sold during the month at that shop, max value = 120 * 31days = int16; clip to 20 after model transform is applied',\n","#                   'shop_typeA\t    int8\tCategorical feature indicating small shop / mall / SEC / online...',\n","#                   'shop_typeB\tint8\tCategorical feature like shop_typeA_enc, but merging together mall/Mega/SEC so fewer categories',\n","#                   'item_cat0\tint8\tOriginal category codes for the items (0 to 83)',\n","#                   'item_catA\t    int8\treduction of original 84 categories, grouping primarily by item type',\n","#                   'item_cat3\t    int8\treduction of original 84 categories, grouping primarily by item brand',\n","#                   'item_cluster\t    int16\tCategorical grouping of items by name similarity; encoding weighted',\n","#                   'item_test\t    int8\tTrue(=1) if item id is in the test set',\n","#                   'shop_test\t    int8\tTrue(=1) if shop id is in the test set',\n","#                   'shop_item_test\tint8\tTrue(=1) if shop-item pair is in the test set',\n","#                   'fd_popdens_enc\tint8\tCategorical feature indicating population density of the federal district the shop is in',\n","#                   'fd_gdp_enc\t    int8\tCategorical feature indicating gdp/person for the federal district the shop is in',\n","#                   'shop_city_enc\tint8\tCategorical feature indicating which city hosts the shop',\n","#                   'shop_federal_district_enc\tint8\tCategorical feature indicating which federal district the shop is in',\n","#                   'price_med_by_item            int8',\n","#                   'sales_by_item                int16',\n","#                   'price_med_by_shop            int8',\n","#                   'sales_by_shop                int16',\n","#                   'price_med_by_item_cat        int8',\n","#                   'sales_by_item_cat            int16',\n","#                   'price_med_by_shop_item       int8',\n","#                   'sales_by_shop_item           int16']\n","\n","# def reset_dtypes(df, dtype_list=DESIRED_DTYPES):\n","#     \"\"\"\n","#     function used to set the columns of dataframe df to the dtypes desired,\n","#     as given by list of strings where the first two whitespace-separated string\n","#     elements are the column name and the desired np dtype (not including np)\n","#     example: dtype_list = ['shop_id int8 some random descriptive text if you want', 'item_id int16 blah blah']\n","#     This gives you finer control over setting column dtypes as you would like, and\n","#     easily choosing which columns to perform this on.\n","#     Drawbacks of using this function: you need to create the dtype_list, and this function does no \n","#     error checking to see if your desired dtype is inconsistent with column values (e.g., if you desire int8,\n","#     but your data actually exceeds +128, you could end up with a negative number during the type conversion.\n","#     The built-in pandas function seems to do a good job of checking so you don't underspecify the dtype.)\n","#     \"\"\"\n","#     for i in dtype_list:\n","#         wds = re.findall(r\"[\\w]+\", i)\n","#         if wds[1] != ('bool' | 'str' | 'object'): \n","#             wds[1] = 'np.' + wds[1]  # prepend numerical datatypes with 'np.' (not comprehensive; only ignores bool, str, object dtypes)\n","#         if wds[0] in df.columns:\n","#             df[wds[0]] = df[wds[0]].astype(eval(wds[1]))\n","#     return df\n","# stt = reset_dtypes(stt)\n","\n","# Alternative: instead of manually checking and setting dtypes, pandas function seems to work pretty well; unsigned, signed, integer, float...\n","#  see:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html#pandas.to_numeric\n","# stt = stt.apply(pd.to_numeric, downcast='integer')\n","# print_col_info(stt,5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIngJXJYSTAW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1589993541314,"user_tz":240,"elapsed":5561,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"aed0fb34-e7af-43d5-9f60-c4ac8e3f3e92"},"source":["%%time\n","# starter DF (for merging with stats by month for broader category groupings)\n","#    monthly_stt = stt with shop-item pair item_cnt_day summed and grouped by month\n","#    (i.e., rows are the smallest divisions of the dataset by month, as we use the most specific shop and item \"categories\")\n","#  use median to keep integers as integers\n","\n","monthly_stt = stt.groupby(['month','shop_id','item_id']).agg({  'shop_typeA':['median'], \n","                                                                'shop_typeB':['median'], \n","                                                                'item_cat0':['median'], \n","                                                                'item_catA':['median'], \n","                                                                'item_cat3':['median'], \n","                                                                'item_cluster':['median'], \n","                                                                'shop_test':['median'], \n","                                                                'item_test':['median'], \n","                                                                'shop_item_test':['median'],\n","                                                                'sales':['sum']\n","                                                                }).reset_index()\n","monthly_stt.columns = monthly_stt.columns.droplevel(1)\n","monthly_stt.rename({'sales':'sales_by_shop_item'}, axis='columns', inplace=True)\n","\n","monthly_stt.sales_by_shop_item = monthly_stt.sales_by_shop_item.clip(0,255) # clip the sales/month aggregate sum to uint8\n","\n","MONTHLY_STT_LENGTH = len(monthly_stt)\n","\n","print(f'\\nmonthly_stt dataframe total memory usage before downcast: {monthly_stt.memory_usage(deep=True).sum()/1e6:.0f} MBytes\\n')\n","#Downcast\n","monthly_stt = monthly_stt.apply(pd.to_numeric, downcast='unsigned') #'integer')\n","print('monthly_stt dataframe memory usage after downcast:')\n","print_col_info(monthly_stt,6)\n","print(f'\\n{monthly_stt.head(3)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","monthly_stt dataframe total memory usage before downcast: 65 MBytes\n","\n","monthly_stt dataframe memory usage after downcast:\n","  Column Name     DType MBytes                 Column Name     DType MBytes       \n","        Index     int64    0.0                   item_cat3     uint8    1.8       \n","        month     uint8    1.8                   item_cat4     uint8    1.8       \n","      shop_id     uint8    1.8                item_cluster    uint16    3.6       \n","      item_id    uint16    3.6                   shop_test     uint8    1.8       \n","   shop_typeA     uint8    1.8                   item_test     uint8    1.8       \n","   shop_typeB     uint8    1.8              shop_item_test     uint8    1.8       \n","    item_cat0     uint8    1.8          sales_by_shop_item     uint8    1.8       \n","\n","Number of rows in DataFrame: 1,809,624\n","DataFrame total memory usage: 27 MB\n","\n","   month  shop_id  item_id  shop_typeA  shop_typeB  item_cat0  item_cat3  item_cat4  item_cluster  shop_test  item_test  shop_item_test  sales_by_shop_item\n","0      0        2       27          30          60         19          4          6          1433          1          0               0                   1\n","1      0        2       33          30          60         37          7          3          1669          1          1               1                   1\n","2      0        2      317          30          60         45          1          1           110          1          0               0                   1\n","CPU times: user 4.85 s, sys: 71 ms, total: 4.93 s\n","Wall time: 4.93 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rZu3cckxjqDV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"error","timestamp":1589800873270,"user_tz":240,"elapsed":462,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"89ca57a6-2ec2-44d1-b666-e573c014339d"},"source":["# Create artificial features as combinations of the above, to favor those items / shops in the test set\n","# by_shop_L1*shop_test, by_item_L1*item_test, by_shop_item_L1*shop_item_test\n","#   Let's assume we are going to train the model using month=33 as the validation set\n","#      and, we'll make a second training run using months 32 and 33 as the validation set\n","#   So, we need shop_test = 1 if shop in month=33.unique (and item_test, and shop_item_test)\n","#      and, another column if shop in months 32,33 (and item and shop_item)\n","shop_33_u = dfL.query(\"(month == 33) & (shop_test == 1)\").shop_id.unique()\n","item_33_u = dfL.query(\"(month == 33) & (item_test == 1)\").item_id.unique()\n","shop_3233_u = dfL.query(\"((month == 33) | (month == 32)) & (shop_test == 1)\").shop_id.unique()\n","item_3233_u = dfL.query(\"((month == 33) | (month == 32)) & (item_test == 1)\").item_id.unique()\n","dfL['s_i_pair'] = zip(dfL.shop_id.to_list(), dfL.item_id.to_list())\n","pair_33_u = dfL.query(\"(month == 33) & (shop_item_test == 1)\").s_i_pair.unique()\n","pair_3233_u = dfL.query(\"((month == 33) | (month == 32)) & (shop_item_test == 1)\").s_i_pair.unique()\n","\n","\n","# @numba.vectorize\n","# def multiply_columns_by_2(x):  # noqa E501\n","#     return x * 2\n","\n","# dfL['shop_x_test_L1'] = dfL.eval('sales_by_shop_L1 * shop_test if shop_id in @shop_33_u else 0')\n","# dfL['item_x_test_L1'] = dfL.eval('sales_by_item_L1 * item_test if item_id in @item_33_u else 0')\n","# dfL['shop_item_x_test_L1'] = dfL.eval('sales_by_shop_item_L1 * shop_item_test if s_i_pair in @pair_33_u else 0')\n","# dfL['shop_x_test_L1L2'] = dfL.eval('(sales_by_shop_L1 + sales_by_shop_L2) * shop_test if shop_id in @shop_3233_u else 0')\n","# dfL['item_x_test_L1L2'] = dfL.eval('(sales_by_item_L1 + sales_by_item_L2) * item_test if item_id in @item_3233_u else 0')\n","# dfL['shop_item_x_test_L1L2'] = dfL.eval('(sales_by_shop_item_L1 + sales_by_shop_item_L2) * shop_item_test if s_i_pair in @pair_3233_u else 0')\n","\n","\n","dfL['shop_x_test_L1'] = dfL.sales_by_shop_L1\n","print(dfL.shop_x_test_L1.sum())\n","dfL.shop_x_test_L1 = dfL.query(\"shop_id not in @shop_33_u\").shop_x_test_L1.apply(lambda x: 0) # = 0 #dfL.sales_by_shop_L1 #dfL.apply(lambda x: x.sales_by_shop_L1 * x.shop_test if shop_id in @shop_33_u else 0')\n","print(dfL.shop_x_test_L1.sum())\n","# dfL['item_x_test_L1'] = dfL.eval('sales_by_item_L1 * item_test if item_id in @item_33_u else 0')\n","# dfL['shop_item_x_test_L1'] = dfL.eval('sales_by_shop_item_L1 * shop_item_test if s_i_pair in @pair_33_u else 0')\n","# dfL['shop_x_test_L1L2'] = dfL.eval('(sales_by_shop_L1 + sales_by_shop_L2) * shop_test if shop_id in @shop_3233_u else 0')\n","# dfL['item_x_test_L1L2'] = dfL.eval('(sales_by_item_L1 + sales_by_item_L2) * item_test if item_id in @item_3233_u else 0')\n","# dfL['shop_item_x_test_L1L2'] = dfL.eval('(sales_by_shop_item_L1 + sales_by_shop_item_L2) * shop_item_test if s_i_pair in @pair_3233_u else 0')\n","\n","dfL.s_i_pair = dfL.s_i_pair.astype('category')\n","dfL.s_i_pair = dfL.s_i_pair.cat.codes\n","dfL = dfL.apply(pd.to_numeric, downcast='integer')\n","print('Cartesian-product with lagged and combined features dfL (after downcast):')\n","print_col_info(dfL,8)\n","print(f'\\ndfL.head:\\n{df.head()}')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-63fba1174e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#   So, we need shop_test = 1 if shop in month=33.unique (and item_test, and shop_item_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#      and, another column if shop in months 32,33 (and item and shop_item)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mshop_33_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(month == 33) & (shop_test == 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshop_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mitem_33_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(month == 33) & (item_test == 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mshop_3233_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"((month == 33) | (month == 32)) & (shop_test == 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshop_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dfL' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"X-qeKYp1j5aQ","colab_type":"text"},"source":["###Encoding categoricals"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T85wILmYUukG","colab":{}},"source":["'''\n","think about this later... probably want to do something like sqrt() on shop_sales and item_cat0_sales\n","but log() or sqrt(log) of x+1 => log1p() for item_sales and item_cluster_sales\n","and no expansion/compression for catA or cat3 sales...\n","\n","%%time\n","# Scale the values of the different columns so they have similar (or properly weighted, based on importance) value magnitudes\n","#  Note, y_sales (= prediction target) is about 10x (or more) less than the grouped category sales\n","\n","# I don't want to apply any additive or multiplicative transformation to y_sales, as this is directly related to what we want to predict\n","#  However, what I can do is clip it to some value sufficiently higher than the final clipping value of 20\n","#  Let's clip to ITEM_CNT_TRAIN_CLIP = 250 , as this fits into a uint8\n","# Then let's do histogram-like binning to force the various group-by-xx stats features into the same storage range, so all stats features will be in range(0,250)\n","#  --> the binning will cause loss of some information, but it will keep roughly the same relative spacing between the different categories\n","pred_target_colname = stats_col_names[0]  # put this in a variable name in case we change 'y_sales' to something different in the future\n","bin_cols = stats_col_names.copy()\n","bin_cols.remove(pred_target_colname)\n","monthly_stt2 = monthly_stt.copy(deep=True) # don't mess up monthly_stt while I'm developing this code\n","monthly_stt2[pred_target_colname] = monthly_stt2[pred_target_colname].clip(0,ITEM_CNT_TRAIN_CLIP)\n","\n","before_bin_zero_item_sales = len(monthly_stt2[monthly_stt2.item_sales ==0])\n","#nps= np.vectorize(np.sqrt)  # np.sqrt(x/scale1) = 30s\n","for bc in bin_cols:\n","    #scale1 = monthly_stt2[bc].max() / 2000  # scale all columns to similar range before applying expansion to highlight lower values of sales\n","    #monthly_stt2[bc] = monthly_stt2[bc].apply(lambda x: np.sqrt(np.log1p(x)/scale1))    #np.log(np.sqrt(x)+1)) #(lambda x: np.log1p(x))  # compress the entries with huge numbers, so the linear scaling before binning keeps the finer info of small, but nonzero, values\n","    scale2 = monthly_stt2[bc].max() / ITEM_CNT_TRAIN_CLIP\n","    monthly_stt2[bc] = monthly_stt2[bc].apply(lambda x: 1+x/scale2 if x>0 else 0)  # add in the +1 and special case for 0, so we don't lose fractional stuff\n","    monthly_stt2[bc] = pd.cut(monthly_stt2[bc],ITEM_CNT_TRAIN_CLIP+1, precision=0, duplicates='drop', labels=False) #, include_lowest=True)\n","\n","after_bin_zero_item_sales = len(monthly_stt2[monthly_stt2.item_sales ==0])\n","\n","print(monthly_stt2.head())\n","print('\\n')\n","print(monthly_stt2.describe())\n","print('\\n')\n","print(f'Before binning, n_rows with item_sales == 0: {before_bin_zero_item_sales:,d}, and after binning: {after_bin_zero_item_sales:,d}')\n","print('\\n')\n","# pandas describe(include='all') function has poor handling of numerical values when computing nunique for a column; however, using explicit nunique() works OK, so here's the following table:\n","co = 'Column Name'\n","nu = 'N Unique Values'\n","mx = 'Maximum Value'\n","mn = 'Minimum Value'\n","print(f'{co:>19}  {nu:>16}  {mx:>14}  {mn:>14}')\n","for c in monthly_stt2.columns:\n","    nu = monthly_stt2[c].nunique()\n","    mx = monthly_stt2[c].max()\n","    mn = monthly_stt2[c].min()\n","    print(f'{c:>19}  {nu:16d}  {mx:14d}  {mn:14d}')\n","\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6qBIRRAtY5b","colab_type":"code","colab":{}},"source":["'''\n","this ties in with the above code cell\n","ignore for now\n","\n","# Demonstration of binning giving results quite similar to the (linearly scaled) original\n","\n","# Also, interesting plots for each different shop's sales by month... several shops have no recent sales\n","# cat0, shop, item, itemcluster\n","pltcol = 'item_cluster'\n","cliptop = 100250\n","plotcolmincounts = 0\n","month = 20 # (and up)\n","monthly_stt3 = monthly_stt.copy(deep=True)\n","# monthly_stt3['shop_sales_scaled'] = monthly_stt3['shop_sales'] / (16338/250)\n","# monthly_stt3 = monthly_stt3.groupby(['month','shop_id']).agg({'shop_sales_scaled':['median'],'shop_sales_bin':['median']})\n","# # monthly_stt3.columns = ['shop_sales_scaled','shop_sales_bin']\n","# monthly_stt3 = monthly_stt3.groupby(['month','shop_id']).agg({'shop_sales':['median']})\n","# monthly_stt3.columns = ['shop_sales']\n","# monthly_stt3 = monthly_stt3.reset_index()\n","# print(monthly_stt3.head())\n","# for s in monthly_stt3.shop_id.unique()[20:25]:\n","#     dfplot = monthly_stt3[monthly_stt3.shop_id == s]\n","#     ax = dfplot.plot(x='month',y='shop_sales',kind='line',color='orange',figsize=(20,5),grid=True)\n","#     #ax2 = dfplot.plot(x='month',y='shop_sales_bin',kind='scatter',color='black',ax=ax)\n","\n","\n","monthly_stt3 = monthly_stt3.groupby(['month','item_id']).agg({pltcol:['median']})\n","monthly_stt3.columns = [pltcol]\n","monthly_stt3 = monthly_stt3.reset_index()\n","dfplot = monthly_stt3[monthly_stt3.month >= month].copy(deep=True)\n","print(dfplot.head())\n","dfplot[pltcol] = dfplot[dfplot[pltcol] >= plotcolmincounts][pltcol].clip(0,cliptop)\n","ax = dfplot.plot(x='month',y=pltcol,kind='hist',bins= 50,color='orange',figsize=(20,8),grid=True)\n","    \n","# for i in monthly_stt3.item_id.unique()[2000:2005]:\n","#     dfplot = monthly_stt3[monthly_stt3.item_id == i]\n","#     ax = dfplot.plot(x='month',y='item_sales',kind='line',color='orange',figsize=(20,10),grid=True)\n","#     #ax2 = dfplot.plot(x='month',y='shop_sales_bin',kind='scatter',color='black',ax=ax)\n","\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOP5mr1sHT5Z","colab_type":"code","colab":{}},"source":["'''\n","# go back to using monthly_stt, because all of the following code uses that name, and I don't want to change all of it\n","\n","monthly_stt = monthly_stt2.copy(deep=True)\n","'''\n","nocode=True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BlpasBnrxWI4","colab_type":"text"},"source":["##**Determine the Strategy for Adding Cartesian Product Rows**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"stLcT9JY1Yzv"},"source":["###Cartesian-Product Thoughts\n","It benefits us to expand the train/val data with additional rows corresponding to certain missing shop-item pairs, so our model has a better chance of accurately predicting for the shop-item pairs test set. This is primarily because categorical groupings give certain shop-item pairs relevance even if they are not in the train or test sets. </br>\n","\n","* Because we have shops and items categorically grouped, we can infer certain things about a previously-unseen shop-item pair, by using the behavior of the shops and items in the same categories.\n","* To train in anticipation of being able to predict all test set shop-item pairs, the model needs to be scored on a train dataset that has all of the test set's shop-item pairs in each time period, with proper estimates of values that may need to be interpolated.  \n","** If we make the simplest assumption of zero sales for any shop-item pair not present in the sales_train dataset, we can just fill with 0 for any of the sales_by columns for the new cartesian product rows.\n","** If we use 'price' or one of its functional aggregates as a feature, things get more complicated, as it probably is not ideal to set price = 0 when adding the new cartesian product rows.  We need to infer or interpolate if we plan to use price-based features in our model.\n","** An alternative to manually interpolating is to train a preliminary model for months \\< 34, and use the preliminary model(s) to make predictions for what sales counts should be used for the new cartesian product rows.  You might have one model for every aggregate feature, for example, or you could combine several of these features as \"target\" predictions in a single model.\n","* Similarly, it is important for the validation set to be scored based on predictions for all relevant shop-item pairs, and not just the shop-item pairs present in the sales_train dataset.\n","* We do not need to add cartesian product rows to month 34, because the model only considers single row inputs, and not chunks of rows as inputs. (Although this is a possible model variant... feeding it a group of correlated rows that are not already correlated by aggregate features... then the model has nrows times as many \"feature inputs\" to deal with)\n","\n","</br>\n","\n","What makes a shop-item pair relevant to add using cartesian product?:\n","* Shop focus:\n","* 1. Any and all shop_ids in the test set should be present in the train and validation sets</br>\n","\n","</br>\n","\n","* Item focus:\n","* 2. Any and all item_ids in the test set should be present in the train and validation sets\n","* 3. Any items that have the same item_category_id as any of the items in the test set\n","* 4. Any items that have the same item_cluster as any of the items in the test set</br>\n","\n","</br>\n","\n","* Date focus:\n","* 5. Recent months appear to be much more valuable than early months\n","* 6. Look for shops or items with zero sales in the future and also zero sales in the past xx months, and assume they are closed or no longer selling.  Set up some method of forcing the model prediction to be zero for the following month.\n","\n","</br>\n","\n","The cartesian product is going to create a huge number of extra rows, and will dramatically increase memory requirements and running time.  So, we need to be judicious in our choice of what months to expand in cartesian-land, and if any months should be dropped or can somehow manage without full cartesian product expansion."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GnRD9aQF-aMp"},"source":["####Inspect data to find a memory-friendly way of incorporating cartesian product rows"]},{"cell_type":"code","metadata":{"id":"96lecgS6LGK5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590285997159,"user_tz":240,"elapsed":85183,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"a1725d3a-0137-418b-86de-6361fc709a85"},"source":["# Populate the train/test dataframe with cartesian products to inform the model explicitly on behavior of shop-item pairs in previous months\n","\n","# First, consider the following:\n","#  to help keep the dataframe memory requirements lower, let's only cartesian product rows for the most important features:\n","#  shop_id present in test, or item_id present in test, or item_cat0 present in test, or item_cluster present in test\n","\n","test_shops_u = test_augmented.shop_id.unique()\n","test_items_u = test_augmented.item_id.unique()\n","test_item_cat_u = test_augmented.item_cat0.unique()\n","test_item_cluster_u = test_augmented.item_cluster.unique()\n","print(f'Unique test... shops = {len(test_shops_u)}, items = {len(test_items_u)}, item_cat0s = {len(test_item_cat_u)}, item_clusters = {len(test_item_cluster_u)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Unique test... shops = 42, items = 5100, item_cat0s = 62, item_clusters = 1218\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YylVayCmmTvS","colab_type":"code","colab":{}},"source":["# See how many rows conform to either shop_id in test, item_id in test, item_cat0 in test, or item_clusters in test\n","# reduced_data = sales_train_test.query(\"(shop_id in @test_shops_u) | (item_id in @test_items_u) | (item_cat0 in @test_item_cat_u) | (item_cluster in @test_item_cluster_u)\")\n","# print(f'Number of rows in reduced_data month 34 = {len(reduced_data[reduced_data.date_block_num == 34]):,d} (note, number of rows in test data set = {TEST_LENGTH:,d})')\n","# print(f'Unique reduced_data... shops = {reduced_data.shop_id.nunique()}, items = {reduced_data.item_id.nunique()}, item_cat0s = {reduced_data.item_cat0.nunique()}, item_clusters = {reduced_data.item_cluster.nunique()}')\n","# print(f'Number of rows in reduced_data: {len(reduced_data):,d}')\n","# not really worth it to filter down train data to just those that are closely related to test\n","\n","# let's see what happens if we only consider as useful the shops / items / item_cats / item_clusters in months 20 to 34\n","CART_FILL_MO_START = CARTESIAN_FILL_MONTH_START # fixed value set above, just after loading data files (presently = 10)\n","CART_CORR_MO_START = CARTESIAN_CORRELATION_START_MONTH # (present value = 23)\n","\n","nrows_stt = len(stt)\n","stt_month34_nrows = len(stt[stt.month == 34])\n","\n","def find_correlated_shops_items(start_month = CART_CORR_MO_START, end_month = 34,\n","                                querystr = \"(shop_id in @test_shops_u) | (item_id in @test_items_u) | (item_cat0 in @test_item_cat_u) | (item_cluster in @test_item_cluster_u)\"):\n","    \"\"\"\n","    The idea behind this function is to reduce computer memory requirements by reducing the number of shops and items from which we create our cartesian product...\n","        Instead of taking all unique shops (60) and items (22700) and applying them to form the rows present for every month in our train/val data,\n","        we only take the shops and items that have presence in a certain month range in the sales_train_test dataset,\n","        and, only take those that are closely correlated to test rows \n","        (e.g. rows in sales_train_test that have the same shop_id as any of the test shops, or that have the same item_id, or same item_cat0, or same item_cluster code)\n","    Note that using intuition suggesting more-recent months will give more valuable information, we can limit the queried months in sales_train_test by adjusting start_month and/or end_month\n","        this will further reduce the numbers of \"test-correlated\" shop_ids and item_ids, to a point where our cartesian product size may be less than half that of the full version\n","    returns: dict with info on the sales_train_test rows matching query conditions, along with lists and list_lengths of the unique shops and unique items found by the query\n","    \"\"\"\n","    reduced_dataframe = stt.query(\"(month >= @start_month) & (month <= @end_month)\").query(querystr)\n","    cp = {}  # cartesian product info is held in this dict\n","    cp['shop_id_list'] = reduced_dataframe.shop_id.unique()\n","    cp['n_shop_ids'] = len(cp['shop_id_list'])\n","    cp['item_id_list'] = reduced_dataframe.item_id.unique()\n","    cp['n_item_ids'] = len(cp['item_id_list'])\n","    cp['item_cat0_list'] = reduced_dataframe.item_cat0.unique()\n","    cp['n_item_cat0s'] = len(cp['item_cat0_list'])\n","    cp['item_cluster_list'] = reduced_dataframe.item_cluster.unique()\n","    cp['n_item_clusters'] = len(cp['item_cluster_list'])\n","    cp['start_month'] = start_month\n","    cp['end_month'] = end_month\n","    cp['query_conditions'] = [x.split(\" \")[0] for x in querystr.split(\"(\")][1:]\n","    return cp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"leMOB16-0f5u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"executionInfo":{"status":"ok","timestamp":1590286077663,"user_tz":240,"elapsed":165673,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"f8d5f064-9709-458d-c90b-c6e7706e9055"},"source":["%%time\n","\n","cart_prod = find_correlated_shops_items()\n","\n","# all test items are in the cartesian product, if we include month 34 when doing our query\n","# let's see how many of the shops and items are covered if we don't include month 34\n","# (this gives us an idea of how many of the test items (or their correlated categories) are not present in sales_train, and thus\n","#  an idea of how many of the cartesian product rows will have no original training information to interpolate values from)\n","# (note: when # uncovered shops = 0, then total number of test rows not present in cartesian product = 42 shops * n_uncovered_items)\n","for start_month in [15,17,19,21,23,25,27,29,CART_CORR_MO_START]:\n","    cart_prod_33 = find_correlated_shops_items(start_month, end_month=33)\n","    n_uncovered_test_shops33 = len(test_shops_u) - len([x for x in test_shops_u if x in cart_prod_33['shop_id_list']])\n","    n_uncovered_test_items33 = len(test_items_u) - len([x for x in test_items_u if x in cart_prod_33['item_id_list']])\n","    n_uncovered_test_item_cat0s33 = len(test_item_cat_u) - len([x for x in test_item_cat_u if x in cart_prod_33['item_cat0_list']])\n","    n_uncovered_test_item_clusters33 = len(test_item_cluster_u) - len([x for x in test_item_cluster_u if x in cart_prod_33['item_cluster_list']])\n","    print(f'\\nFor query terms {cart_prod_33[\"query_conditions\"]}, for {cart_prod_33[\"start_month\"]:2d} <= month <= {cart_prod_33[\"end_month\"]:2d}:',end='')\n","    print(f' n cartesian product rows = {cart_prod_33[\"n_shop_ids\"]:2d} x {cart_prod_33[\"n_item_ids\"]:<5d} = {(cart_prod_33[\"n_shop_ids\"] * cart_prod_33[\"n_item_ids\"]):,d}')\n","    print(f'    test_missing: shops = {n_uncovered_test_shops33:2d} / {len(test_shops_u):2d}, items = {n_uncovered_test_items33:>3d} / {len(test_items_u):4d}, ',end='')\n","    print(f'item_category_ids = {n_uncovered_test_item_cat0s33:1d} / {len(test_item_cat_u):2d}, item_clusters ={n_uncovered_test_item_clusters33:3d} / {len(test_item_cluster_u):4d}',end='')\n","    if n_uncovered_test_shops33 == 0:\n","        print(f', n test rows = {n_uncovered_test_items33:>4d} x {len(test_shops_u):2d} = {(len(test_shops_u)*n_uncovered_test_items33):,d} / {(len(test_shops_u)*len(test_items_u)):,d}')\n","    else:\n","        print('')\n","    \n","\n","stt_rows_by_month = {}\n","stt_rows_in_cp = {}\n","cp_rows_in_stt = {}\n","cp_rows_not_in_stt = {}\n","total_rows_after_cp_merge = {}\n","stt_rolling_totals_before_cp_merge = {0:0}\n","stt_rolling_totals_after_cp_merge = {0:0}\n","cpshops = cart_prod['shop_id_list']\n","cpitems = cart_prod['item_id_list']\n","n_cptuples = cart_prod['n_shop_ids'] * cart_prod['n_item_ids']\n","print(\"\\nComputation completed for month:\",end='')\n","for m in range(35):\n","    stt_rows_by_month[m] = len(stt[stt.month == m])\n","    m_stt_in_cp = stt[stt.month == m].query(\"(shop_id in @cpshops) & (item_id in @cpitems)\")\n","    stt_rows_in_cp[m] = len(m_stt_in_cp)\n","    m_unique_shop_item_pairs_in_STTandCP = set(m_stt_in_cp.apply(lambda row: (row.shop_id, row.item_id), axis = 1).to_list())\n","    cp_rows_in_stt[m] = len(m_unique_shop_item_pairs_in_STTandCP)\n","    cp_rows_not_in_stt[m] = (n_cptuples - cp_rows_in_stt[m]) * (m < 34)  # we won't be merging cartesian product into month 34\n","    total_rows_after_cp_merge[m] = stt_rows_in_cp[m] + cp_rows_not_in_stt[m]\n","    stt_rolling_totals_before_cp_merge[m+1] = stt_rolling_totals_before_cp_merge[m] + stt_rows_by_month[m]\n","    stt_rolling_totals_after_cp_merge[m+1] = stt_rolling_totals_after_cp_merge[m] + total_rows_after_cp_merge[m]\n","    print(f' {m},',end='')\n","print(' done')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 15 <= month <= 33: n cartesian product rows = 52 x 15545 = 808,340\n","    test_missing: shops =  0 / 42, items = 393 / 5100, item_category_ids = 1 / 62, item_clusters =  8 / 1218, n test rows =  393 x 42 = 16,506 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 17 <= month <= 33: n cartesian product rows = 52 x 14628 = 760,656\n","    test_missing: shops =  0 / 42, items = 405 / 5100, item_category_ids = 1 / 62, item_clusters =  8 / 1218, n test rows =  405 x 42 = 17,010 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 19 <= month <= 33: n cartesian product rows = 52 x 13472 = 700,544\n","    test_missing: shops =  0 / 42, items = 430 / 5100, item_category_ids = 1 / 62, item_clusters =  9 / 1218, n test rows =  430 x 42 = 18,060 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 21 <= month <= 33: n cartesian product rows = 52 x 12573 = 653,796\n","    test_missing: shops =  0 / 42, items = 454 / 5100, item_category_ids = 1 / 62, item_clusters = 10 / 1218, n test rows =  454 x 42 = 19,068 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 23 <= month <= 33: n cartesian product rows = 52 x 11726 = 609,752\n","    test_missing: shops =  0 / 42, items = 466 / 5100, item_category_ids = 1 / 62, item_clusters = 12 / 1218, n test rows =  466 x 42 = 19,572 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 25 <= month <= 33: n cartesian product rows = 49 x 10718 = 525,182\n","    test_missing: shops =  0 / 42, items = 493 / 5100, item_category_ids = 1 / 62, item_clusters = 19 / 1218, n test rows =  493 x 42 = 20,706 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 27 <= month <= 33: n cartesian product rows = 48 x 9389  = 450,672\n","    test_missing: shops =  0 / 42, items = 535 / 5100, item_category_ids = 1 / 62, item_clusters = 28 / 1218, n test rows =  535 x 42 = 22,470 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 29 <= month <= 33: n cartesian product rows = 45 x 8368  = 376,560\n","    test_missing: shops =  0 / 42, items = 600 / 5100, item_category_ids = 1 / 62, item_clusters = 31 / 1218, n test rows =  600 x 42 = 25,200 / 214,200\n","\n","For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 23 <= month <= 33: n cartesian product rows = 52 x 11726 = 609,752\n","    test_missing: shops =  0 / 42, items = 466 / 5100, item_category_ids = 1 / 62, item_clusters = 12 / 1218, n test rows =  466 x 42 = 19,572 / 214,200\n","\n","Computation completed for month: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, done\n","CPU times: user 1min 20s, sys: 84.1 ms, total: 1min 20s\n","Wall time: 1min 20s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pCyzZ8jskoW8","colab_type":"text"},"source":["####As seen above, we only reduce the cartesian product size significantly if we restrict ourselves to selecting only recent-month attributes to evaluate for correlation with test shops and items.  I'm going to choose months 23-34 for determining what shops and items will make up the cartesian product.  It seems like a good range of months for compromise between size of eventual dataset and the number of test items that match with a correlated feature present in the original sales_train dataset."]},{"cell_type":"code","metadata":{"id":"bfSXA7FO8c_x","colab_type":"code","colab":{}},"source":["# compute aggregate values\n","total_additional_rows = sum(cp_rows_not_in_stt.values())\n","total_additional_rows_from_fillstart = sum(dict((key, cp_rows_not_in_stt[key]) for key in range(CART_FILL_MO_START,35)).values())\n","total_pre_merge_rows_from_fillstart = sum(dict((key, stt_rows_by_month[key]) for key in range(CART_FILL_MO_START,35)).values())\n","total_post_merge_rows_from_fillstart = sum(dict((key, total_rows_after_cp_merge[key]) for key in range(CART_FILL_MO_START,35)).values())\n","all_months_post_merge_rows = sum(total_rows_after_cp_merge.values())\n","merged_size_vs_start_month = dict((key, all_months_post_merge_rows - stt_rolling_totals_after_cp_merge[key]) for key in stt_rolling_totals_after_cp_merge)\n","# additional_rows_by_month = dict(sorted(cp_rows_not_in_stt.items()))  # if we want a nicely-sorted dict to just print the whole thing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"woCVG2amj_Ey","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"status":"ok","timestamp":1590286077888,"user_tz":240,"elapsed":165883,"user":{"displayName":"Michael Gaidis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhePD6jAHDISTPR4NIxczUMyvKb_tUrKiPQtlZeog=s64","userId":"15986747394900387491"}},"outputId":"c113a4b7-3455-44fc-e4ce-ed418b890ae2"},"source":["def colprintdict(m_start,stt_rows,stt_rows_in_cp,cp_rows_in_stt,cp_rows_not_in_stt,total_rows_stt_cp_merge,stt_before_m,merged_before_m,merged_nrows_ge_m):\n","    idx_names = ['month:','stt (k)','stt in cp (k)','cp in stt (k)','cp not in stt (k)',\n","                 'stt&cp (k)','stt lt.m (k)','stt&cp lt.m (k)','stt&cp ge.m (k)']\n","    idx_width = len(max(idx_names, key = len))\n","    numbers = [list(range(35)),stt_rows,stt_rows_in_cp,cp_rows_in_stt,cp_rows_not_in_stt,total_rows_stt_cp_merge,stt_before_m,merged_before_m,merged_nrows_ge_m]\n","    col_width = 6\n","    for rowdx in range(len(idx_names)):\n","        print_row = f'  {idx_names[rowdx]:>{idx_width}}'\n","        for i in range(m_start,35):\n","            div = 999 * (rowdx>0) + 1  # convert everything except month number to thousands, for tighter printing\n","            print_row += f'  {(numbers[rowdx][i]//div):>{col_width},d}'\n","        print(print_row)\n","\n","print(f'\\nUnique sales_train_test... shops = {stt.shop_id.nunique()}, items = {stt.item_id.nunique()}, item_cat0s = {stt.item_cat0.nunique()}, item_clusters = {stt.item_cluster.nunique()}')\n","print(f'Number of rows in original sales_train_test dataframe: {nrows_stt:,d}, and for month 34 only, n_rows = {stt_month34_nrows:,d}')\n","\n","print(f'\\nNumber of unique \"values correlated with test set\" as computed from months {CART_CORR_MO_START} through 34:')\n","print(f'    n_unique_shops = {cart_prod[\"n_shop_ids\"]}, n_unique_items = {cart_prod[\"n_item_ids\"]}, n_unique_item_cat0s = {cart_prod[\"n_item_cat0s\"]}, n_unique_item_clusters = {cart_prod[\"n_item_clusters\"]}')\n","print(f'Cartesian product size = {cart_prod[\"n_shop_ids\"]} x {cart_prod[\"n_item_ids\"]:,d} = {(cart_prod[\"n_shop_ids\"] * cart_prod[\"n_item_ids\"]):,d}')\n","print(f'Number of rows in sales_train_test from month {CART_FILL_MO_START} through month 34, before any cartesian products:   {total_pre_merge_rows_from_fillstart:,d}')\n","print(f'Number of rows in sales_train_test from month {CART_FILL_MO_START} through month 34, after \"cartesian product\" merge: {total_post_merge_rows_from_fillstart:,d}')\n","if CART_FILL_MO_START > 0:\n","    print(f'Number of rows in sales_train_test if keeping all original stt rows, but merging cartesian product only into months {CART_FILL_MO_START} to 33: {(nrows_stt + total_additional_rows_from_fillstart):,d}\\n')\n","    print(f'Number of rows in sales_train_test if keeping original stt rows and merging cartesian product into all stt months (0 to 33): {all_months_post_merge_rows:,d}\\n')\n","print(f'Number of rows (in thousands), by month, in sales_train_test (stt) data set, and in cartesian-product (cp) set, and overlaps between the two:')\n","colprintdict(0,stt_rows_by_month, stt_rows_in_cp, cp_rows_in_stt, cp_rows_not_in_stt, total_rows_after_cp_merge, stt_rolling_totals_before_cp_merge, stt_rolling_totals_after_cp_merge, merged_size_vs_start_month)\n","print(f'\\n. ')\n","#print(f'\\nTotal number of \"cartesian product\" rows to be inserted in sales_train_test to fill from month {CART_FILL_MO_START} through month 33: {total_additional_rows:,d}')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Unique sales_train_test... shops = 55, items = 22041, item_cat0s = 84, item_clusters = 2146\n","Number of rows in original sales_train_test dataframe: 3,128,468, and for month 34 only, n_rows = 214,200\n","\n","Number of unique \"values correlated with test set\" as computed from months 23 through 34:\n","    n_unique_shops = 52, n_unique_items = 12192, n_unique_item_cat0s = 74, n_unique_item_clusters = 1848\n","Cartesian product size = 52 x 12,192 = 633,984\n","Number of rows in sales_train_test from month 10 through month 34, before any cartesian products:   2,112,571\n","Number of rows in sales_train_test from month 10 through month 34, after \"cartesian product\" merge: 16,261,410\n","Number of rows in sales_train_test if keeping all original stt rows, but merging cartesian product only into months 10 to 33: 17,389,108\n","\n","Number of rows in sales_train_test if keeping original stt rows and merging cartesian product into all stt months (0 to 33): 22,909,743\n","\n","Number of rows (in thousands), by month, in sales_train_test (stt) data set, and in cartesian-product (cp) set, and overlaps between the two:\n","             month:       0       1       2       3       4       5       6       7       8       9      10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31      32      33      34\n","            stt (k)     114     107     120      93      90      99      99     103      95      91      95     142      98      89      91      77      77      81      78      86      73      77      86     130      88      71      69      56      54      54      55      57      50      52     214\n","      stt in cp (k)      56      56      65      53      54      60      63      69      68      69      74     117      83      77      81      70      72      76      74      83      70      76      85     130      88      71      69      56      54      54      55      57      50      52     214\n","      cp in stt (k)      27      27      30      27      28      30      33      35      33      34      36      49      41      39      41      38      40      42      42      44      39      40      45      59      46      41      40      32      32      31      33      33      29      31     214\n","  cp not in stt (k)     606     606     603     606     605     603     600     598     600     599     597     584     592     594     592     595     593     591     591     589     594     593     588     574     587     592     593     601     601     602     600     600     604     602       0\n","         stt&cp (k)     663     662     669     659     660     663     663     668     668     668     672     701     675     672     674     665     665     668     665     673     665     669     674     705     675     664     663     657     656     656     656     657     654     655     214\n","       stt lt.m (k)       0     114     222     342     435     526     625     725     828     924   1,015   1,111   1,253   1,352   1,441   1,533   1,610   1,688   1,769   1,847   1,934   2,007   2,085   2,171   2,302   2,391   2,463   2,532   2,589   2,643   2,698   2,753   2,811   2,861   2,914\n","    stt&cp lt.m (k)       0     663   1,325   1,995   2,654   3,315   3,978   4,642   5,310   5,979   6,648   7,320   8,021   8,697   9,369  10,044  10,709  11,374  12,043  12,709  13,382  14,048  14,717  15,392  16,097  16,773  17,437  18,101  18,758  19,414  20,071  20,727  21,385  22,040  22,695\n","    stt&cp ge.m (k)  22,909  22,246  21,583  20,914  20,254  19,594  18,930  18,267  17,598  16,930  16,261  15,589  14,887  14,212  13,539  12,865  12,200  11,535  10,866  10,200   9,526   8,861   8,192   7,517   6,812   6,136   5,472   4,808   4,151   3,494   2,838   2,182   1,524     869     214\n","\n",". \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oS1-vtg2mHQ2"},"source":["####Based on the above numbers, and the desire to include at least a year of data before test month 34, for now I will choose to add the cartesian product rows only to months 20 - 33.  They are unhelpful in month 34, and to keep down the size of the train/val dataset, I'm guessing that months before 20 are not so relevant for evaluating the test set.</br>\n","\n","To keep things simple for now, I think I will just drop the early months or perhaps I might just prepend them them without cartesian product.  In the future, to assist more with training, I might want to ensure that shop-item pairs in a given month's sales_train data must be present in the previous 1 to 3 months, so we get better training with our time-lag features."]},{"cell_type":"code","metadata":{"id":"dL1ImnWQjNcq","colab_type":"code","colab":{}},"source":["# Here are the numbers as printed from code cells above, that helped me determine to\n","#   go with months 23-34 to determine cartesian product shops & items, and fill the cartesian product only for months 20-33\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 15 <= month <= 33: n cartesian product rows = 52 x 15545 = 808,340\n","#     test_missing: shops =  0 / 42, items = 393 / 5100, item_category_ids = 1 / 62, item_clusters =  8 / 1218, n test rows =  393 x 42 = 16,506 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 17 <= month <= 33: n cartesian product rows = 52 x 14628 = 760,656\n","#     test_missing: shops =  0 / 42, items = 405 / 5100, item_category_ids = 1 / 62, item_clusters =  8 / 1218, n test rows =  405 x 42 = 17,010 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 19 <= month <= 33: n cartesian product rows = 52 x 13472 = 700,544\n","#     test_missing: shops =  0 / 42, items = 430 / 5100, item_category_ids = 1 / 62, item_clusters =  9 / 1218, n test rows =  430 x 42 = 18,060 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 21 <= month <= 33: n cartesian product rows = 52 x 12573 = 653,796\n","#     test_missing: shops =  0 / 42, items = 454 / 5100, item_category_ids = 1 / 62, item_clusters = 10 / 1218, n test rows =  454 x 42 = 19,068 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 23 <= month <= 33: n cartesian product rows = 52 x 11726 = 609,752\n","#     test_missing: shops =  0 / 42, items = 466 / 5100, item_category_ids = 1 / 62, item_clusters = 12 / 1218, n test rows =  466 x 42 = 19,572 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 25 <= month <= 33: n cartesian product rows = 49 x 10718 = 525,182\n","#     test_missing: shops =  0 / 42, items = 493 / 5100, item_category_ids = 1 / 62, item_clusters = 19 / 1218, n test rows =  493 x 42 = 20,706 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 27 <= month <= 33: n cartesian product rows = 48 x 9389  = 450,672\n","#     test_missing: shops =  0 / 42, items = 535 / 5100, item_category_ids = 1 / 62, item_clusters = 28 / 1218, n test rows =  535 x 42 = 22,470 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 29 <= month <= 33: n cartesian product rows = 45 x 8368  = 376,560\n","#     test_missing: shops =  0 / 42, items = 600 / 5100, item_category_ids = 1 / 62, item_clusters = 31 / 1218, n test rows =  600 x 42 = 25,200 / 214,200\n","\n","# For query terms ['shop_id', 'item_id', 'item_cat0', 'item_cluster'], for 23 <= month <= 33: n cartesian product rows = 52 x 11726 = 609,752\n","#     test_missing: shops =  0 / 42, items = 466 / 5100, item_category_ids = 1 / 62, item_clusters = 12 / 1218, n test rows =  466 x 42 = 19,572 / 214,200\n","\n","# Unique sales_train_test... shops = 55, items = 22041, item_cat0s = 84, item_clusters = 2146\n","# Number of rows in original sales_train_test dataframe: 3,128,468, and for month 34 only, n_rows = 214,200\n","\n","# Number of unique \"values correlated with test set\" as computed from months 23 through 34:\n","#     n_unique_shops = 52, n_unique_items = 12192, n_unique_item_cat0s = 74, n_unique_item_clusters = 1848\n","# Cartesian product size = 52 x 12,192 = 633,984\n","# Number of rows in sales_train_test from month 20 through month 34, before any cartesian products:   1,194,091\n","# Number of rows in sales_train_test from month 20 through month 34, after \"cartesian product\" merge: 9,526,935\n","# Number of rows in sales_train_test if keeping all original stt rows, but merging cartesian product only into months 20 to 33: 11,466,424\n","\n","# Number of rows in sales_train_test if keeping original stt rows and merging cartesian product into all stt months (0 to 33): 22,909,743\n","\n","# Number of rows (in thousands), by month, in sales_train_test (stt) data set, and in cartesian-product (cp) set, and overlaps between the two:\n","#                    month       0       1       2       3       4       5       6       7       8       9      10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31      32      33      34\n","#          rows in stt (k)     114     107     120      93      90      99      99     103      95      91      95     142      98      89      91      77      77      81      78      86      73      77      86     130      88      71      69      56      54      54      55      57      50      52     214\n","#       rows stt in cp (k)      56      56      65      53      54      60      63      69      68      69      74     117      83      77      81      70      72      76      74      83      70      76      85     130      88      71      69      56      54      54      55      57      50      52     214\n","#       rows cp in stt (k)      27      27      30      27      28      30      33      35      33      34      36      49      41      39      41      38      40      42      42      44      39      40      45      59      46      41      40      32      32      31      33      33      29      31     214\n","#   rows cp not in stt (k)     606     606     603     606     605     603     600     598     600     599     597     584     592     594     592     595     593     591     591     589     594     593     588     574     587     592     593     601     601     602     600     600     604     602       0\n","#          rows stt&cp (k)     663     662     669     659     660     663     663     668     668     668     672     701     675     672     674     665     665     668     665     673     665     669     674     705     675     664     663     657     656     656     656     657     654     655     214\n","#        rows stt lt.m (k)       0     114     222     342     435     526     625     725     828     924   1,015   1,111   1,253   1,352   1,441   1,533   1,610   1,688   1,769   1,847   1,934   2,007   2,085   2,171   2,302   2,391   2,463   2,532   2,589   2,643   2,698   2,753   2,811   2,861   2,914\n","#     rows stt&cp lt.m (k)       0     663   1,325   1,995   2,654   3,315   3,978   4,642   5,310   5,979   6,648   7,320   8,021   8,697   9,369  10,044  10,709  11,374  12,043  12,709  13,382  14,048  14,717  15,392  16,097  16,773  17,437  18,101  18,758  19,414  20,071  20,727  21,385  22,040  22,695\n","#     rows stt&cp ge.m (k)  22,909  22,246  21,583  20,914  20,254  19,594  18,930  18,267  17,598  16,930  16,261  15,589  14,887  14,212  13,539  12,865  12,200  11,535  10,866  10,200   9,526   8,861   8,192   7,517   6,812   6,136   5,472   4,808   4,151   3,494   2,838   2,182   1,524     869     214\n","\n","# If I want to cartesian-productize the lagged months, then a start month of #20 implies I need to c-p fill down through month 17 if I use 3-month lag features, or to 14 if I use 6-month\n","# The respective dataset number of rows for 14, 17, 20 are: 13.5M, 11.5M, 9.5M"],"execution_count":null,"outputs":[]}]}