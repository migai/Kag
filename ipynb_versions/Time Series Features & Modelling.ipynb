{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Time Series Features & Modelling.ipynb","provenance":[{"file_id":"https://github.com/migai/Kag/blob/master/template_Kaggle_Coursera_Final_Assignment.ipynb","timestamp":1587141076973}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ufy-J0xC2efV","colab_type":"text"},"source":["## First things first\n","* Click **File -> Save a copy in Drive** and click **Open in new tab** in the pop-up window to save your progress in Google Drive.\n","* Click **Runtime -> Change runtime type** and select **GPU** in Hardware accelerator box to enable faster GPU training."]},{"cell_type":"markdown","metadata":{"id":"YPp_Nesy2yxn","colab_type":"text"},"source":["#**Final Project for Coursera's 'How to Win a Data Science Competition'**\n","April, 2020\n","\n","Andreas Theodoulou and Michael Gaidis\n","\n","(Competition Info last updated:  3 years ago)"]},{"cell_type":"markdown","metadata":{"id":"r_Oe76PW3aoN","colab_type":"text"},"source":["##**About this Competition**\n","\n","You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.\n","\n","Evaluation: root mean squared error (RMSE). True target values are clipped into [0,20] range.\n","\n",".\n","\n","##**File descriptions**\n","\n","***sales_train.csv*** - the training set. Daily historical data from January 2013 to October 2015.\n","\n","***test.csv*** - the test set. You need to forecast the sales for these shops and products for November 2015.\n","\n","***sample_submission.csv*** - a sample submission file in the correct format.\n","\n","***items.csv*** - supplemental information about the items/products.\n","\n","***item_categories.csv***  - supplemental information about the items categories.\n","\n","***shops.csv***- supplemental information about the shops.\n","\n",".\n","\n","##**Data fields**\n","\n","***ID*** - an Id that represents a (Shop, Item) tuple within the test set\n","\n","***shop_id*** - unique identifier of a shop\n","\n","***item_id*** - unique identifier of a product\n","\n","***item_category_id*** - unique identifier of item category\n","\n","***item_cnt_day*** - number of products sold. You are predicting a monthly amount of this measure\n","\n","***item_price*** - current price of an item\n","\n","***date*** - date in format dd/mm/yyyy\n","\n","***date_block_num*** - a consecutive month number. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n","\n","***item_name*** - name of item\n","\n","***shop_name*** - name of shop\n","\n","***item_category_name*** - name of item category"]},{"cell_type":"markdown","metadata":{"id":"LyLQLqBcOnLt","colab_type":"text"},"source":["#Load Files\n","Load competition data files and import helpful custom code libraries from shared GitHub repository"]},{"cell_type":"code","metadata":{"id":"dy5i7jl00oX-","colab_type":"code","colab":{}},"source":["# GitHub file location info\n","git_hub_url = \"https://raw.githubusercontent.com/migai/\"\n","repo_name = 'Kag/'\n","branch_name = 'master/'\n","base_url = git_hub_url + repo_name + branch_name\n","\n","# List of the data files (path relative to GitHub branch), to be loaded into pandas DataFrames\n","data_files = [  \"readonly/final_project_data/items.csv\",\n","                \"readonly/final_project_data/item_categories.csv\",\n","                \"readonly/final_project_data/shops.csv\",\n","                \"readonly/final_project_data/sample_submission.csv.gz\",\n","                \"readonly/final_project_data/sales_train.csv.gz\",\n","                \"readonly/final_project_data/test.csv.gz\"  ]\n","\n","# List of helper code files, to be loaded into Colab and available for python import\n","code_files = [  \"kaggle_utils_at_mg.py\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjr80Q4K8bZr","colab_type":"code","outputId":"74068e42-a0f2-4ae8-da7d-3841f8056b99","executionInfo":{"status":"ok","timestamp":1587634148443,"user_tz":-60,"elapsed":10987,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"colab":{"base_uri":"https://localhost:8080/","height":782}},"source":["import pandas as pd\n","import os\n","\n","def xfer_github_to_colab(path):\n","    filename = path.rsplit(\"/\")[-1]\n","    os.system(\"wget \" + base_url + \"{} -O {}\".format(path, filename))\n","    print(base_url + path + \" ---> loaded into ---> \" + filename)\n","    return filename\n","\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False\n","if IN_COLAB:\n","    print(\"Loading Files from GitHub to Colab\\n\")\n","\n","    # Loop to load the above data files into appropriately-named pandas DataFrames\n","    for path_name in data_files:\n","      filename = xfer_github_to_colab(path_name)\n","      data_frame_name = path_name.rsplit(\"/\")[-1].split(\".\")[0]\n","      exec(data_frame_name + \" = pd.read_csv(filename)\")\n","      print(\"Data Frame: \" + data_frame_name)\n","      print(eval(data_frame_name).head(2))\n","      print(\"\\n\")\n","\n","\n","    # to load a code (\".py\") file into Colab, first shred to make sure you aren't using an old version\n","    for path_name in code_files:\n","      filename = path_name.rsplit(\"/\")[-1]\n","      ! shred -u {filename}\n","      filename = xfer_github_to_colab(path_name)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading Files from GitHub to Colab\n","\n","https://raw.githubusercontent.com/migai/Kag/master/readonly/final_project_data/items.csv ---> loaded into ---> items.csv\n","Data Frame: items\n","                                           item_name  item_id  item_category_id\n","0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0                40\n","1  !ABBYY FineReader 12 Professional Edition Full...        1                76\n","\n","\n","https://raw.githubusercontent.com/migai/Kag/master/readonly/final_project_data/item_categories.csv ---> loaded into ---> item_categories.csv\n","Data Frame: item_categories\n","        item_category_name  item_category_id\n","0  PC - Гарнитуры/Наушники                 0\n","1         Аксессуары - PS2                 1\n","\n","\n","https://raw.githubusercontent.com/migai/Kag/master/readonly/final_project_data/shops.csv ---> loaded into ---> shops.csv\n","Data Frame: shops\n","                       shop_name  shop_id\n","0  !Якутск Орджоникидзе, 56 фран        0\n","1  !Якутск ТЦ \"Центральный\" фран        1\n","\n","\n","https://raw.githubusercontent.com/migai/Kag/master/readonly/final_project_data/sample_submission.csv.gz ---> loaded into ---> sample_submission.csv.gz\n","Data Frame: sample_submission\n","   ID  item_cnt_month\n","0   0             0.5\n","1   1             0.5\n","\n","\n","https://raw.githubusercontent.com/migai/Kag/master/readonly/final_project_data/sales_train.csv.gz ---> loaded into ---> sales_train.csv.gz\n","Data Frame: sales_train\n","         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n","0  02.01.2013               0       59    22154       999.0           1.0\n","1  03.01.2013               0       25     2552       899.0           1.0\n","\n","\n","https://raw.githubusercontent.com/migai/Kag/master/readonly/final_project_data/test.csv.gz ---> loaded into ---> test.csv.gz\n","Data Frame: test\n","   ID  shop_id  item_id\n","0   0        5     5037\n","1   1        5     5320\n","\n","\n","https://raw.githubusercontent.com/migai/Kag/master/kaggle_utils_at_mg.py ---> loaded into ---> kaggle_utils_at_mg.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S01TwEVZ0QqZ","colab_type":"code","outputId":"4e8a0920-493f-4a3e-f8cf-45ad1c71c27e","executionInfo":{"status":"ok","timestamp":1587634148446,"user_tz":-60,"elapsed":10973,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# test to check that .py utility file loaded into Colab OK\n","'''\n","import kaggle_utils_at_mg as kag_utils\n","test1 = kag_utils.add_one(2)\n","print(test1)\n","'''"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nimport kaggle_utils_at_mg as kag_utils\\ntest1 = kag_utils.add_one(2)\\nprint(test1)\\n'"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"naC94KtXOnLt","colab_type":"code","outputId":"ca193d71-3082-4bfb-c002-0bc69d4baca2","executionInfo":{"status":"ok","timestamp":1587548728490,"user_tz":-60,"elapsed":22344,"user":{"displayName":"Andreas Theodoulou","photoUrl":"","userId":"10256955413424659339"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["import matplotlib.pyplot as plt\n","import pdb; pdb.set_trace()\n","import numpy as np\n","from itertools import product\n","import time\n","from sklearn.linear_model import LinearRegression\n","#from catboost import CatBoostRegressor\n","import pickle\n","\n","from catboost import CatBoostRegressor "],"execution_count":0,"outputs":[{"output_type":"stream","text":["--Return--\n","> <ipython-input-27-abcee8ea5336>(2)<module>()->None\n","-> import pdb; pdb.set_trace()\n","                                           item_name  item_id  item_category_id\n","0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0                40\n","1  !ABBYY FineReader 12 Professional Edition Full...        1                76\n","2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2                40\n","3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3                40\n","4        ***КОРОБКА (СТЕКЛО)                       D        4                40\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YQ7tffMSSfn7","colab_type":"text"},"source":["# **Data Preparation**\n","\n","*   Make data table monthly from daily (is there any point in using the daily data in more advanced modelling versions? Probably just to create more relevant monthly related features (e.g. mean/std or any other type) rather than keeping the format of the table daily)\n","*   To do: Merge item_category_id as a feature\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MXYTT_-iOOZY","colab_type":"text"},"source":["Make table monthly"]},{"cell_type":"code","metadata":{"id":"2uRVAWaX0qqJ","colab_type":"code","colab":{}},"source":["matrix = []\n","cols = ['date_block_num','shop_id','item_id']\n","for i in range(34):\n","    sales = sales_train[sales_train.date_block_num==i]\n","    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n","    \n","matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n","matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n","matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n","matrix['item_id'] = matrix['item_id'].astype(np.int16)\n","matrix.sort_values(cols,inplace=True)\n","print(\"monthly table is\")\n","matrix.head()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mCoe7RDJ0vbm","colab_type":"code","colab":{}},"source":["ts = time.time()\n","group = sales_train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\n","group.columns = ['item_cnt_month']\n","group.reset_index(inplace=True)\n","\n","matrix = pd.merge(matrix, group, on=cols, how='left')\n","matrix['item_cnt_month'] = (matrix['item_cnt_month']\n","                                .fillna(0)\n","                                .clip(0,20) # NB clip target here\n","                                .astype(np.float16))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXRhZb7Y1Ym6","colab_type":"code","colab":{}},"source":["matrix.tail()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"etV9Z3va7KC1","colab_type":"code","colab":{}},"source":["test['date_block_num'] = 34\n","test['date_block_num'] = test['date_block_num'].astype(np.int8)\n","test['shop_id'] = test['shop_id'].astype(np.int8)\n","test['item_id'] = test['item_id'].astype(np.int16)\n","matrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\n","matrix.fillna(0, inplace=True) # 34 month\n","matrix.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0tjUSchKkvq","colab_type":"code","colab":{}},"source":["#Count of monthly data points for each category\n","#item_id category\n","matrix[matrix['date_block_num'] <= 6].groupby('item_id').agg({'item_id': 'count'}).describe()\n","#shop_id category\n","matrix[matrix['date_block_num'] <= 6].groupby(['shop_id']).agg({'shop_id': 'count'}).describe()\n","#shop_id & item_id category\n","matrix[matrix['date_block_num'] <= 6].groupby(['shop_id', 'item_id']).agg({'shop_id': 'count'}).describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqoxb4sYOjou","colab_type":"code","colab":{}},"source":["sales_train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['count']}).describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZzTfLKxRSHh","colab_type":"code","colab":{}},"source":["group = sales_train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean'],\n","                                                               'item_cnt_day': ['mean']})\n","group.columns = ['item_price_mean_per_item_and_month', 'item_cnt_mean_per_item_and_month']\n","group"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VgzkOq08BH3l","colab_type":"text"},"source":["### **Featue Generation/Engineering**\n","\n","Time series features\n","*   Statistics of previous months (e.g. mean of item_price for a specific item/shop in previous months)\n","*   Trends of previous months - rate of change of the above statistics based features (e.g. rate of change of mean item_price from today to the past 3 months for a specific shop/item)\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"uC9yX2_d_9my","colab_type":"code","colab":{}},"source":["def lag_feature(df, lags, col):\n","    tmp = df[['date_block_num','shop_id','item_id',col]]\n","    for i in lags:\n","        shifted = tmp.copy()\n","        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n","        shifted['date_block_num'] += i\n","        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZzHeIovUrS5","colab_type":"text"},"source":["Stage 1: Statistics based features\n","\n","> 1st step: Compute their Values\n"]},{"cell_type":"code","metadata":{"id":"B9cEnEK1UduX","colab_type":"code","colab":{}},"source":["#mean of item price at specific date_block_num and item_id\n","group = sales_train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean'],\n","                                                               'item_cnt_day': ['mean']})\n","group.columns = ['item_price_mean_per_item_and_month', 'item_cnt_mean_per_item_and_month']\n","group.reset_index(inplace=True)\n","matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n","matrix['item_price_mean_per_item_and_month'] = matrix['item_price_mean_per_item_and_month'].astype(np.float16)\n","matrix['item_cnt_mean_per_item_and_month'] = matrix['item_cnt_mean_per_item_and_month'].astype(np.float16)\n","\n","\n","#mean of item price at specific date_block_num and shop_id\n","group = sales_train.groupby(['date_block_num','shop_id']).agg({'item_price': ['mean'],\n","                                                               'item_cnt_day': ['mean']})\n","group.columns = ['item_price_mean_per_shop_and_month', 'item_cnt_mean_per_shop_and_month']\n","group.reset_index(inplace=True)\n","matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n","matrix['item_price_mean_per_shop_and_month'] = matrix['item_price_mean_per_shop_and_month'].astype(np.float16)\n","matrix['item_cnt_mean_per_shop_and_month'] = matrix['item_cnt_mean_per_shop_and_month'].astype(np.float16)\n","\n","matrix"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"621H7P3rVTNZ","colab_type":"text"},"source":["> 2nd step: Lag them (put them in the same row/month as the one you'll be using them to predict - e.g e.g if going to use 6month ago mean of item_price to predict item_cnt of next month, put 6 month ago mean of item_price in the same row as current month's values, used to predict next month)\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"0M4DkX8SawXs","colab_type":"code","colab":{}},"source":["ts = time.time()\n","\n","lags = [1, 2, 3, 4, 6, 7, 12, 13]\n","\n","features_engineered = ['item_price_mean_per_item_and_month', 'item_cnt_mean_per_item_and_month', 'item_price_mean_per_shop_and_month', 'item_cnt_mean_per_shop_and_month']\n","features_to_lag = features_engineered\n","matrix_tmp = []\n","for i in range(len(features_to_lag)):\n","  matrix_tmp.append(lag_feature(matrix, lags, features_to_lag[i]))\n","for matrix_lagged in matrix_tmp:\n","  import pdb; pdb.set_trace()\n","  matrix = pd.merge(matrix, matrix_lagged, on=['date_block_num','shop_id','item_id'], how='left')\n","\n","\n","fetures_to_drop = features_engineered #features are renamed and added as a new column within the lag_features functions, so remove these one\n","matrix = matrix.drop(fetures_to_drop, axis = 1)\n","matrix = matrix.fillna(0)\n","\n","matrix = matrix.loc[:,~matrix.columns.str.contains('_y')]\n","matrix = matrix.loc[:,~matrix.columns.str.contains('_x')]\n","import pdb; pdb.set_trace()\n","\n","\n","time.time()-ts"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fp1Q5V-I9EJK","colab_type":"code","colab":{}},"source":["#matrix = matrix[matrix.columns.drop(list(matrix.filter(regex='y')))]\n","#df.drop(list(df.filter(regex = '_x')), axis = 1, inplace = True)#\n","matrix.tail()\n","import pdb; pdb.set_trace()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hgmFHyzKX0EM","colab_type":"text"},"source":["2nd Stage: Trend based features\n","\n","\n","> Rate of change of price/item count in the past 1m, 3m, 6m, 12m\n","\n"]},{"cell_type":"code","metadata":{"id":"MvqHzOWVWbwv","colab_type":"code","colab":{}},"source":["ts = time.time()\n","trend_lags = [2, 4, 7, 13]\n","for feature_engineered in features_engineered:\n","  for i in trend_lags:\n","    matrix['trend_' + feature_engineered + '_lag_'+str(i-1)] = \\\n","        (matrix[feature_engineered +'_lag_'+str(i)] - matrix[feature_engineered + '_lag_1']) / matrix[feature_engineered + '_lag_1']\n","print(time.time()-ts)\n","matrix.tail()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RsRgOGrBtAAx","colab_type":"code","colab":{}},"source":["#Is this code really needed? it's really slow as well\n","'''\n","ts = time.time()\n","def select_trend(row):\n","  #for i in trend_lags:\n","  print(i)\n","  if row['trend_' + feature_engineered + '_lag_' + str(i-1)]:\n","    return row['trend_' + feature_engineered + '_lag_' + str(i-1)]\n","  return 0\n","\n","for feature_engineered in features_engineered:\n","      for i in trend_lags:\n","                matrix['trend_' + feature_engineered + '_lag_' + str(i-1)] = matrix.apply(select_trend, axis=1)\n","                matrix['trend_' + feature_engineered + '_lag_' + str(i-1)] = matrix['trend_' + feature_engineered + '_lag_' + str(i-1)].astype(np.float16)\n","                matrix['trend_' + feature_engineered + '_lag_' + str(i-1)].fillna(0, inplace=True)\n","\n","time.time() - ts\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPfWLCbNsnnf","colab_type":"code","colab":{}},"source":["matrix.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a6HJ4nXXctHt","colab_type":"text"},"source":["\n","\n","> Categorical feature for whether mean value of feature_engineered (e.g.price/item cnt of current month) is above mean value of past 12 months of that feature \n","\n"]},{"cell_type":"code","metadata":{"id":"b9Pv2y1QbZlC","colab_type":"code","colab":{}},"source":["#if price_lag_1 > mean(price_lag_1,3,6,12)\n","for feature_engineered in features_engineered:\n","  matrix['above_12m_avg_' + feature_engineered] = matrix[feature_engineered + '_lag_1'] >= matrix[[feature_engineered + '_lag_1', feature_engineered + '_lag_3', feature_engineered + '_lag_6', feature_engineered + '_lag_12']].mean(axis = 1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nViuoUBjR_Mr","colab_type":"code","colab":{}},"source":["matrix.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9OeyeTRZK73R","colab_type":"code","colab":{}},"source":["'''\n","from google.colab import files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#matrix.to_csv('Full-TS-Features-DataSet.csv')\n","files.download('Full-TS-Features-DataSet.csv')\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIeoZgxwn9we","colab_type":"code","colab":{}},"source":["'''\n","matrix = pd.read_csv('Full-TS-Features-DataSet.csv')\n","matrix.head()\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9wdcfzIhSdV","colab_type":"code","colab":{}},"source":["#features_to_remove_post_trend = ['item_price_mean_per_item_and_month', 'item_price_mean_per_shop_and_month'] #for all lags - do not sound like useful features -> their trends should be more useful\n","lags_to_remove_post_trend = ['_4', '_7', '_13'] #for all features - not needed any more - were just needed to calculate 1m (2m-1m), 3m (4m-1m), 6m (7m-1m), 12m (13m-1m) trends\n","'''\n","for feature_to_remove_post_trend in features_to_remove_post_trend:\n","  matrix = matrix.loc[:,~matrix.columns.str.startswith(feature_to_remove_post_trend)]\n","'''\n","for lag_to_remove_post_trend in lags_to_remove_post_trend:\n","  matrix = matrix.loc[:,~matrix.columns.str.endswith(lag_to_remove_post_trend)]\n","\n","\n","matrix.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wQOL4w4XhqSB","colab_type":"code","colab":{}},"source":["import numpy as np\n","matrix = matrix.replace([np.inf, -np.inf], np.nan)\n","matrix.fillna(0, inplace=True)\n","matrix.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLM6IieFK_DM","colab_type":"code","colab":{}},"source":["'''\n","from google.colab import files\n","matrix.to_csv('for-modelling-TS-Features-DataSet.csv')\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jtZ0iBdUCD-Z","colab_type":"text"},"source":["# Modelling\n","\n","\n","\n","*   Train/Val/Test split\n","*   Model specific feature set\n","*   Model Fit & Validate\n","*   Test/Submission Results\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9TJk9bzeCjqF","colab_type":"text"},"source":["Train/Test split"]},{"cell_type":"code","metadata":{"id":"l_RFPPPP9yr6","colab_type":"code","colab":{}},"source":["use_toy_data = False #to be used just for code to run quicker when tests are needed to be made\n","data = matrix\n","if use_toy_data == True:\n","  train_start_index = 28\n","else:\n","  train_start_index = 14 #skip first 13 months - used to caclulate time series features\n","train_final_index = 28 #makes validation set to be 20% of the non-test data (threshold is surely debatable)\n","\n","data = data[data['date_block_num'] >= train_start_index ]  \n","X_train = data[data.date_block_num <= train_final_index].drop(['item_cnt_month', 'ID'], axis=1)\n","y_train = data[data.date_block_num <= train_final_index]['item_cnt_month']\n","X_val = data[(data.date_block_num > train_final_index) & (data.date_block_num <= 33)].drop(['item_cnt_month', 'ID'], axis=1)\n","y_val = data[(data.date_block_num > train_final_index) & (data.date_block_num <= 33)]['item_cnt_month']\n","X_test = data[data.date_block_num == 34].drop(['item_cnt_month', 'ID'], axis=1)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0g1t4mbVAv6","colab_type":"code","colab":{}},"source":["X_train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t1-fHFoFG3wa","colab_type":"code","colab":{}},"source":["y_train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-yaXpG71QxcW","colab_type":"text"},"source":["Model Specific feature set"]},{"cell_type":"code","metadata":{"id":"8a0v1BXjRcGJ","colab_type":"code","colab":{}},"source":["'''\n","#Remove categorical features unless encoded (e.g one-hot encoding) for basically any method other than a tree method (Linear Regresion, Neural Networks etc)\n","LinRegFeaturesToDrop= ['date_block_num', 'shop_id', 'item_id'] \n","X_train_LinReg = X_train.drop(LinRegFeaturesToDrop, axis = 1)\n","X_val_LinReg = X_val.drop(LinRegFeaturesToDrop, axis = 1)\n","X_test_LinReg = X_test.drop(LinRegFeaturesToDrop, axis = 1)\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"izqoiZEgCoy-","colab_type":"text"},"source":["Model Fit & Validate"]},{"cell_type":"code","metadata":{"id":"PKaLcysR6TJO","colab_type":"code","colab":{}},"source":["import sklearn\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_pred_train, y_pred_val =  model.predict(X_train) , model.predict(X_val)\n","train_score, val_score = sklearn.metrics.r2_score(y_train, y_pred_train), sklearn.metrics.r2_score(y_val, y_pred_val)\n","train_rmsle, val_rmse = np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(sklearn.metrics.mean_squared_error(y_val, y_pred_val))\n","print('R^2 train_score is ' + str(train_score))\n","print('R^2 val_score is ' + str(val_score))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sFYjXrmHCxOj","colab_type":"text"},"source":["Test/Submission Results"]},{"cell_type":"code","metadata":{"id":"OxXCPKxw77oB","colab_type":"code","colab":{}},"source":["Y_pred = model.predict(X_val).clip(0, 20)\n","Y_test = model.predict(X_test).clip(0, 20)\n","\n","submission = pd.DataFrame({\n","    \"ID\": test.index, \n","    \"item_cnt_month\": Y_test\n","})\n","submission.to_csv('xgb_submission.csv', index=False)\n","\n","# save predictions for an ensemble\n","pickle.dump(Y_pred, open('linReg_train.pickle', 'wb'))\n","pickle.dump(Y_test, open('linReg_test.pickle', 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2Jc1FVCHXOA","colab_type":"code","colab":{}},"source":["submission.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HprRItOZV8o6","colab_type":"text"},"source":["Catboost"]},{"cell_type":"code","metadata":{"id":"FdwdzVxXVmqd","colab_type":"code","colab":{}},"source":["'''\n","# Prepare Categorical Variables\n","\n","categorical = []\n","for feature_engineered in features_engineered:\n","  categorical.append('above_12m_avg' + feature_engineered)\n","\n","categorical.extend(['date_block_num','shop_id', 'item_id'])\n","\n","def column_index(df, query_cols):\n","    indices = []\n","    for query_col in query_cols:\n","      index=df.columns.get_loc(query_col)\n","      indices.append(index)\n","    return indices\n","categorical_features_pos = column_index(X_train,categorical)\n","\n","model = CatBoostRegressor()\n","model.fit(\n","    X_train, y_train,\n","    #cat_features=categorical_features_pos,\n","    eval_set=(X_val, y_val)\n","#     logging_level='Verbose',  # you can uncomment this for text output\n","    #plot=True\n",")\n","y_pred_train, y_pred_val =  model.predict(X_train) , model.predict(X_val)\n","train_score, val_score = sklearn.metrics.r2_score(y_train, y_pred_train), sklearn.metrics.r2_score(y_val, y_pred_val)\n","train_rmse, val_rmse = np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(sklearn.metrics.mean_squared_error(y_val, y_pred_val))\n","print('R^2 train_score is ' + str(train_score))\n","print('R^2 val_score is ' + str(val_score))\n","\n","Y_pred = model.predict(X_val).clip(0, 20)\n","Y_test = model.predict(X_test).clip(0, 20)\n","\n","submission = pd.DataFrame({\n","    \"ID\": test.index, \n","    \"item_cnt_month\": Y_test\n","})\n","submission.to_csv('xgb_submission.csv', index=False)\n","\n","# save predictions for an ensemble\n","pickle.dump(Y_pred, open('linReg_train.pickle', 'wb'))\n","pickle.dump(Y_test, open('linReg_test.pickle', 'wb'))\n","\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8zOwfReTlVs","colab_type":"code","colab":{}},"source":["from sklearn.ensemble import GradientBoostingRegressor\n","gbt = GradientBoostingRegressor(max_depth = 7)\n","gbt.fit(X_train, y_train)\n","model = gbt\n","\n","y_pred_train, y_pred_val =  model.predict(X_train) , model.predict(X_val)\n","train_score, val_score = sklearn.metrics.r2_score(y_train, y_pred_train), sklearn.metrics.r2_score(y_val, y_pred_val)\n","train_rmse, val_rmse = np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(sklearn.metrics.mean_squared_error(y_val, y_pred_val))\n","print('R^2 train_score is ' + str(train_score))\n","print('R^2 val_score is ' + str(val_score))\n","\n","Y_pred = model.predict(X_val).clip(0, 20)\n","Y_test = model.predict(X_test).clip(0, 20)\n","\n","submission = pd.DataFrame({\n","    \"ID\": test.index, \n","    \"item_cnt_month\": Y_test\n","})\n","submission.to_csv('xgb_submission.csv', index=False)\n","\n","# save predictions for an ensemble\n","pickle.dump(Y_pred, open('gbt_train.pickle', 'wb'))\n","pickle.dump(Y_test, open('gbt_test.pickle', 'wb'))\n","\n","# save the model to disk\n","filename = 'gbt_model.sav'\n","pickle.dump(model, open(filename, 'wb'))\n"," \n","# some time later...\n"," '''\n","# load the model from disk\n","loaded_model = pickle.load(open(filename, 'rb'))\n","result = loaded_model.score(X_test, Y_test)\n","print(result)\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBNksxZEZ3m4","colab_type":"code","colab":{}},"source":["# Plot feature importance\n","feature_importance = gbt.feature_importances_\n","# make importances relative to max importance\n","feature_importance = 100.0 * (feature_importance / feature_importance.max())\n","sorted_idx = np.argsort(feature_importance)\n","pos = np.arange(sorted_idx.shape[0]) + .5\n","plt.figure(figsize=(10,13)) \n","plt.barh(pos, feature_importance[sorted_idx], align='center')\n","plt.yticks(pos, X_train.columns[sorted_idx])\n","plt.xlabel('Relative Importance')\n","plt.title('Variable Importance')\n","plt.tick_params(axis='y', which='major', labelsize = 13)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ql4JBZvDV5ou","colab_type":"text"},"source":["EDA"]},{"cell_type":"code","metadata":{"id":"CM4FzxwQV60I","colab_type":"code","colab":{}},"source":["df1 = data.describe(include = 'all')\n","df1.loc['dtype'] = data.dtypes\n","df1.loc['size'] = len(data)\n","df1.loc['% Null_count'] = data.isnull().mean()\n","df1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AO5bhuL0I8G","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjgWGEs50Lch","colab_type":"text"},"source":["**Data Cleaning**"]},{"cell_type":"code","metadata":{"id":"c9U1Z8bk0Sh0","colab_type":"code","colab":{}},"source":["#impute any potential missing values or deal with outliers"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5dF3-5w-Vi7O","colab_type":"text"},"source":["Feature Engineering"]},{"cell_type":"code","metadata":{"id":"OrRnHaqpVmoQ","colab_type":"code","colab":{}},"source":["# To construct month, year feature from data\n","# count of days in a month\n","# time components of item_price and item_cnt (value at t-1, t-2, t-3, t-6, t-12 maybe)\n","# rate of change of item_cnt (between t-1 and t-2 e.g.), \n","# statistics on item_price and item_cnt - mean, std, range, mode, skew?\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SRUC5iYQ12em","colab_type":"code","colab":{}},"source":["#Create a distinct day, month, year column\n","'''\n","df['date'] = pd.to_datetime(df['date'], format = \"%d.%m.%Y\")\n","df['year'], df['month'], features['day'] = df['date'].dt.year, df['date'].dt.month, df['date'].dt.day\n","df.head()\n","'''\n","#also get day count (days in a month)"],"execution_count":0,"outputs":[]}]}